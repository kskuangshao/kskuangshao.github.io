<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>jvm虚拟机探究</title>
    <link href="/2020/12/09/jvm001/"/>
    <url>/2020/12/09/jvm001/</url>
    
    <content type="html"><![CDATA[<h1 id="为什么学习jvm虚拟机"><a href="#为什么学习jvm虚拟机" class="headerlink" title="为什么学习jvm虚拟机"></a>为什么学习jvm虚拟机</h1><ul><li>生产上运行spark的时候时常出现GC OVERHEAD等报错</li><li>作为对于java语言底层（深层）的了解</li></ul><h1 id="JVM探究"><a href="#JVM探究" class="headerlink" title="JVM探究"></a>JVM探究</h1><ul><li><p>谈谈你对jvm的理解？java8虚拟机和之前的变换更新？</p></li><li><p>什么是oom？什么是栈溢出StackOverFlowError？怎么分析？</p></li><li><p>JVM常用调优参数？</p></li><li><p>内存快照如何抓取，怎么分析Dump文件？</p></li><li><p>谈谈JVM中类加载器你的认识？</p><p>jvm中类加载器 rt-jar、ext(扩展jar包)、用户的application</p></li></ul><h2 id="了解"><a href="#了解" class="headerlink" title="了解"></a>了解</h2><ul><li>jvm的位置</li><li>jvm体系结构</li><li>类加载器</li><li>双亲委派机制</li><li>沙箱安全机制</li><li>Native</li><li>PC寄存器、方法区、栈、堆</li><li>三种JVM</li><li>新生代、老年区、永久区</li><li>堆内存调优</li><li>GC 常用算法</li><li>JMM</li><li>总结</li></ul><h3 id="学习方案"><a href="#学习方案" class="headerlink" title="学习方案"></a>学习方案</h3><ul><li>百度</li><li>思维导图 - 在线思维导图去搜索</li></ul><p><img src="/2020/12/09/jvm001/hexo\kskuangshaoblog\source_posts\images\image-20201119013059487-1607446232587.png" alt="image-20201119013059487"></p><h4 id="1-类加载器"><a href="#1-类加载器" class="headerlink" title="1. 类加载器"></a>1. 类加载器</h4><ul><li>作用：加载class文件</li></ul><p><img src="/2020/12/09/jvm001/hexo\kskuangshaoblog\source_posts\images\image-20201117010051266-1607446247777.png" alt="image-20201117010051266"></p><ol><li>虚拟机自带加载器</li><li>启动类加载器</li><li>扩展类加载器</li><li>应用类加载器</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>jvm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sql03</title>
    <link href="/2020/12/03/sql03/"/>
    <url>/2020/12/03/sql03/</url>
    
    <content type="html"><![CDATA[<h1 id="sql小练习"><a href="#sql小练习" class="headerlink" title="sql小练习"></a>sql小练习</h1><pre><code class="hljs lsl">u01     <span class="hljs-number">2017</span>/<span class="hljs-number">1</span>/<span class="hljs-number">21</span>       <span class="hljs-number">5</span>u02     <span class="hljs-number">2017</span>/<span class="hljs-number">1</span>/<span class="hljs-number">23</span>       <span class="hljs-number">6</span>u03     <span class="hljs-number">2017</span>/<span class="hljs-number">1</span>/<span class="hljs-number">22</span>       <span class="hljs-number">8</span>u04     <span class="hljs-number">2017</span>/<span class="hljs-number">1</span>/<span class="hljs-number">20</span>       <span class="hljs-number">3</span>u01     <span class="hljs-number">2017</span>/<span class="hljs-number">1</span>/<span class="hljs-number">23</span>       <span class="hljs-number">6</span>u01     <span class="hljs-number">2017</span>/<span class="hljs-number">2</span>/<span class="hljs-number">21</span>       <span class="hljs-number">8</span>u02     <span class="hljs-number">2017</span>/<span class="hljs-number">1</span>/<span class="hljs-number">23</span>       <span class="hljs-number">6</span>u01     <span class="hljs-number">2017</span>/<span class="hljs-number">2</span>/<span class="hljs-number">22</span>       <span class="hljs-number">4</span>建表语句create table action(userId <span class="hljs-type">string</span>,visitDate <span class="hljs-type">string</span>,visitCount int) row format delimited fields terminated by <span class="hljs-string">&quot;<span class="hljs-subst">\t</span>&quot;</span>;</code></pre><p>要求使用sql统计出每个用户累计访问次数</p><p><img src="https://img-blog.csdnimg.cn/20200408105906485.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzNzMzMTIz,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-comment">--第三步：窗口内累加</span>  userid,  visitdate,  cnt1,  <span class="hljs-keyword">sum</span>(cnt1) <span class="hljs-keyword">over</span>(<span class="hljs-keyword">partition</span> <span class="hljs-keyword">by</span> userid <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> visitdate) <span class="hljs-keyword">as</span> cnt2 <span class="hljs-comment">--注意这里窗口分区</span><span class="hljs-keyword">from</span>(<span class="hljs-keyword">select</span> <span class="hljs-comment">--第二步：分组求和</span>  userid,  visitdate,  <span class="hljs-keyword">sum</span>(visitcount) <span class="hljs-keyword">as</span> cnt1<span class="hljs-keyword">from</span>(<span class="hljs-keyword">select</span> <span class="hljs-comment">--第一步：把月份提取出来</span>  userid,  <span class="hljs-keyword">date_format</span>(regexp_replace(visitdate,<span class="hljs-string">&#x27;/&#x27;</span>,<span class="hljs-string">&#x27;-&#x27;</span>),<span class="hljs-string">&#x27;yyyyMM&#x27;</span>) <span class="hljs-keyword">as</span>   visitdate,  visitcount<span class="hljs-keyword">from</span> <span class="hljs-keyword">action</span>)t1 <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> userid,visitdate)t2;</code></pre><h2 id="练习2：京东"><a href="#练习2：京东" class="headerlink" title="练习2：京东"></a>练习2：京东</h2><pre><code class="hljs properties"><span class="hljs-attr">有50W个店铺，每个顾客访问任何一个店铺的任何一个商品时都会产生一条访问日志，</span><span class="hljs-attr">访问日志存储的表名为visit，访客的用户id为user_id，被访问的店铺名称为shop</span><span class="hljs-attr">求：</span><span class="hljs-attr">1）每个店铺的UV（访客数）</span><span class="hljs-attr">2）每个店铺访问次数top3的访客信息。输出店铺名称、访客id、访问次数</span><span class="hljs-attr">u1</span><span class="hljs-string">a</span><span class="hljs-attr">u2</span><span class="hljs-string">b</span><span class="hljs-attr">u1</span><span class="hljs-string">b</span><span class="hljs-attr">u1</span><span class="hljs-string">a</span><span class="hljs-attr">u3</span><span class="hljs-string">c</span><span class="hljs-attr">u4</span><span class="hljs-string">b</span><span class="hljs-attr">u1</span><span class="hljs-string">a</span><span class="hljs-attr">u2</span><span class="hljs-string">c</span><span class="hljs-attr">u5</span><span class="hljs-string">b</span><span class="hljs-attr">u4</span><span class="hljs-string">b</span><span class="hljs-attr">u6</span><span class="hljs-string">c</span><span class="hljs-attr">u2</span><span class="hljs-string">c</span><span class="hljs-attr">u1</span><span class="hljs-string">b</span><span class="hljs-attr">u2</span><span class="hljs-string">a</span><span class="hljs-attr">u2</span><span class="hljs-string">a</span><span class="hljs-attr">u3</span><span class="hljs-string">a</span><span class="hljs-attr">u5</span><span class="hljs-string">a</span><span class="hljs-attr">u5</span><span class="hljs-string">a</span><span class="hljs-attr">u5</span><span class="hljs-string">a</span><span class="hljs-attr">建表语句</span><span class="hljs-attr">create</span> <span class="hljs-string">table visit(user_id string,shop string) row format delimited fields terminated by &#x27;\t&#x27;;</span></code></pre><pre><code class="hljs sql"><span class="hljs-keyword">select</span>  shop,  <span class="hljs-keyword">count</span>(*) <span class="hljs-keyword">as</span> <span class="hljs-keyword">num</span> <span class="hljs-keyword">from</span> (<span class="hljs-keyword">select</span>  shop,  user_ida<span class="hljs-keyword">from</span> visit <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> shop,user_id) t1 <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> shop; <span class="hljs-comment">--uv记得去重</span><span class="hljs-keyword">select</span> <span class="hljs-comment">--第三步：拿到前三</span>  shop,  user_id,  cnt  <span class="hljs-keyword">from</span>(<span class="hljs-keyword">select</span> <span class="hljs-comment">--第二层：给每个访客排序，从上往下一次减少</span>  shop,  user_id,  cnt,  row_number() <span class="hljs-keyword">over</span>(<span class="hljs-keyword">partition</span> <span class="hljs-keyword">by</span> shop <span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> cnt <span class="hljs-keyword">desc</span>) <span class="hljs-keyword">as</span> rn  <span class="hljs-keyword">from</span>(<span class="hljs-keyword">select</span> <span class="hljs-comment">--第一层：得到每个访客在每个店铺的次数</span>  user_id,  shop,  <span class="hljs-keyword">count</span>(*) <span class="hljs-keyword">as</span> cnt<span class="hljs-keyword">from</span> visit <span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> user_id,shop)t1)t2 <span class="hljs-keyword">where</span> rn &lt;= <span class="hljs-number">3</span>;</code></pre><h2 id="练习3：蚂蚁森林"><a href="#练习3：蚂蚁森林" class="headerlink" title="练习3：蚂蚁森林"></a>练习3：蚂蚁森林</h2><h2 id="背景说明："><a href="#背景说明：" class="headerlink" title="背景说明："></a>背景说明：</h2><p>以下表记录了用户每天的蚂蚁森林低碳生活领取的记录流水。</p><p>user_low_carbon user_id data_dt low_carbon</p><p>用户 日期 减少碳排放</p><pre><code class="hljs txt">u_0012017/1/110u_0012017/1/2150u_0012017/1/2110u_0012017/1/210u_0012017/1/450u_0012017/1/410u_0012017/1/645u_0012017/1/690u_0022017/1/110u_0022017/1/2150u_0022017/1/270u_0022017/1/330u_0022017/1/380u_0022017/1/4150u_0022017/1/5101u_0022017/1/668u_0032017/1/120u_0032017/1/210u_0032017/1/2150u_0032017/1/3160u_0032017/1/420u_0032017/1/5120u_0032017/1/620u_0032017/1/710u_0032017/1/7110u_0042017/1/1110u_0042017/1/220u_0042017/1/250u_0042017/1/3120u_0042017/1/430u_0042017/1/560u_0042017/1/6120u_0042017/1/710u_0042017/1/7120u_0052017/1/180u_0052017/1/250u_0052017/1/280u_0052017/1/3180u_0052017/1/4180u_0052017/1/410u_0052017/1/580u_0052017/1/6280u_0052017/1/780u_0052017/1/780u_0062017/1/140u_0062017/1/240u_0062017/1/2140u_0062017/1/3210u_0062017/1/310u_0062017/1/440u_0062017/1/540u_0062017/1/620u_0062017/1/750u_0062017/1/7240u_0072017/1/1130u_0072017/1/230u_0072017/1/2330u_0072017/1/330u_0072017/1/4530u_0072017/1/530u_0072017/1/6230u_0072017/1/7130u_0072017/1/730u_0082017/1/1160u_0082017/1/260u_0082017/1/260u_0082017/1/360u_0082017/1/4260u_0082017/1/5360u_0082017/1/6160u_0082017/1/760u_0082017/1/760u_0092017/1/170u_0092017/1/270u_0092017/1/270u_0092017/1/3170u_0092017/1/4270u_0092017/1/570u_0092017/1/670u_0092017/1/770u_0092017/1/770u_0102017/1/190u_0102017/1/290u_0102017/1/290u_0102017/1/390u_0102017/1/490u_0102017/1/480u_0102017/1/590u_0102017/1/590u_0102017/1/6190u_0102017/1/790u_0102017/1/790u_0112017/1/1110u_0112017/1/2100u_0112017/1/2100u_0112017/1/3120u_0112017/1/4100u_0112017/1/5100u_0112017/1/6100u_0112017/1/7130u_0112017/1/7100u_0122017/1/110u_0122017/1/2120u_0122017/1/210u_0122017/1/310u_0122017/1/450u_0122017/1/510u_0122017/1/620u_0122017/1/710u_0122017/1/710u_0132017/1/150u_0132017/1/2150u_0132017/1/250u_0132017/1/3150u_0132017/1/4550u_0132017/1/5350u_0132017/1/650u_0132017/1/720u_0132017/1/760u_0142017/1/1220u_0142017/1/2120u_0142017/1/220u_0142017/1/320u_0142017/1/420u_0142017/1/5250u_0142017/1/6120u_0142017/1/7270u_0142017/1/720u_0152017/1/110u_0152017/1/220u_0152017/1/210u_0152017/1/310u_0152017/1/420u_0152017/1/570u_0152017/1/610u_0152017/1/780u_0152017/1/760</code></pre><p>蚂蚁森林植物换购表，用于记录申领环保植物所需要减少的碳排放量</p><p>plant_carbon plant_id plant_name low_carbon</p><p>植物编号 植物名 换购植物所需要的碳</p><pre><code class="hljs angelscript">p001梭梭树<span class="hljs-number">17</span>p002沙柳<span class="hljs-number">19</span>p003樟子树<span class="hljs-number">146</span>p004胡杨<span class="hljs-number">215</span></code></pre><h2 id="题目"><a href="#题目" class="headerlink" title="题目"></a>题目</h2><ol><li>蚂蚁森林植物申领统计</li></ol><p>问题：假设2017年1月1日开始记录低碳数据（user_low_carbon），假设2017年10月1日之前满足申领条件的用户都申领了一颗 p004-胡杨，剩余的能量全部用来领取“p002-沙柳”。统计在10月1日累计申领“p002-沙柳”排名前10的用户信息；以及他比后一名多领了几颗沙柳。<br>得到的统计结果如下表样式：</p><pre><code class="hljs angelscript">user_id plant_count less_count(比后一名多领了几颗沙柳)u_101<span class="hljs-number">1000</span><span class="hljs-number">100</span>u_088<span class="hljs-number">900</span><span class="hljs-number">400</span>u_103<span class="hljs-number">500</span>...</code></pre><ol start="2"><li>蚂蚁森林低碳用户排名分析</li></ol><p>问题：查询user_low_carbon表中每日流水记录，条件为：</p><ul><li>用户在2017年，连续三天（或以上）的天数里，</li><li>每天减少碳排放（low_carbon）都超过100g的用户低碳流水。</li></ul><p>需要查询返回满足以上条件的user_low_carbon表中的记录流水。</p><p>例如用户u_002符合条件的记录如下，因为2017/1/2~2017/1/5连续四天的碳排放量之和都大于等于100g：</p><pre><code class="hljs apache"><span class="hljs-attribute">seq</span>（key） user_id data_dt low_carbon<span class="hljs-attribute">xxxxx10</span> u_<span class="hljs-number">002</span> <span class="hljs-number">2017</span>/<span class="hljs-number">1</span>/<span class="hljs-number">2</span> <span class="hljs-number">150</span><span class="hljs-attribute">xxxxx11</span> u_<span class="hljs-number">002</span> <span class="hljs-number">2017</span>/<span class="hljs-number">1</span>/<span class="hljs-number">2</span> <span class="hljs-number">70</span><span class="hljs-attribute">xxxxx12</span> u_<span class="hljs-number">002</span> <span class="hljs-number">2017</span>/<span class="hljs-number">1</span>/<span class="hljs-number">3</span> <span class="hljs-number">30</span><span class="hljs-attribute">xxxxx13</span> u_<span class="hljs-number">002</span> <span class="hljs-number">2017</span>/<span class="hljs-number">1</span>/<span class="hljs-number">3</span> <span class="hljs-number">80</span><span class="hljs-attribute">xxxxx14</span> u_<span class="hljs-number">002</span> <span class="hljs-number">2017</span>/<span class="hljs-number">1</span>/<span class="hljs-number">4</span> <span class="hljs-number">150</span><span class="hljs-attribute">xxxxx14</span> u_<span class="hljs-number">002</span> <span class="hljs-number">2017</span>/<span class="hljs-number">1</span>/<span class="hljs-number">5</span> <span class="hljs-number">101</span></code></pre><h3 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h3><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> user_low_carbon(user_id <span class="hljs-keyword">String</span>,data_dt <span class="hljs-keyword">String</span>,low_carbon <span class="hljs-built_in">int</span>) <span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> <span class="hljs-keyword">delimited</span> <span class="hljs-keyword">fields</span> <span class="hljs-keyword">terminated</span> <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span>;<span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> plant_carbon(plant_id <span class="hljs-keyword">string</span>,plant_name <span class="hljs-keyword">String</span>,low_carbon <span class="hljs-built_in">int</span>) <span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> <span class="hljs-keyword">delimited</span> <span class="hljs-keyword">fields</span> <span class="hljs-keyword">terminated</span> <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span>;</code></pre><h3 id="设置本地模式"><a href="#设置本地模式" class="headerlink" title="设置本地模式"></a>设置本地模式</h3><pre><code class="hljs shell">set hive.exec.mode.local.auto=true;</code></pre><h3 id="第一种思路写法"><a href="#第一种思路写法" class="headerlink" title="第一种思路写法"></a>第一种思路写法</h3><pre><code class="hljs sql">hive&gt; desc user_low_carbon;OKuser_id                 stringdata_dt                 stringlow_carbon              inthive&gt; desc plant_carbon;OKplant_id                stringplant_name              stringlow_carbon              int1.取大于2017/1/1 小于2017/10/1每个用户的总排放量<span class="hljs-keyword">select</span>    user_id,    <span class="hljs-keyword">sum</span>(low_carbon) <span class="hljs-keyword">as</span> sum_low_carbon<span class="hljs-keyword">from</span> user_low_carbon<span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> user_id;2.胡杨碳排放<span class="hljs-keyword">select</span>    plant_id,    low_carbon<span class="hljs-keyword">from</span> plant_carbon<span class="hljs-keyword">where</span> plant_id = <span class="hljs-string">&#x27;p004&#x27;</span>;3.沙柳碳排放<span class="hljs-keyword">select</span>    plant_id,    low_carbon<span class="hljs-keyword">from</span> plant_carbon<span class="hljs-keyword">where</span> plant_id = <span class="hljs-string">&#x27;p002&#x27;</span>;4.每个用户沙柳的个数<span class="hljs-keyword">select</span>    user_id,    <span class="hljs-keyword">floor</span>((sum_low_carbon-t2.low_carbon)/t3.low_carbon) <span class="hljs-keyword">as</span> plant_count<span class="hljs-keyword">from</span> (<span class="hljs-keyword">select</span>    user_id,    <span class="hljs-keyword">sum</span>(low_carbon) <span class="hljs-keyword">as</span> sum_low_carbon<span class="hljs-keyword">from</span> user_low_carbon<span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> user_id)t1,(<span class="hljs-keyword">select</span>    plant_id,    low_carbon<span class="hljs-keyword">from</span> plant_carbon<span class="hljs-keyword">where</span> plant_id = <span class="hljs-string">&#x27;p004&#x27;</span>)t2,(<span class="hljs-keyword">select</span>    plant_id,    low_carbon<span class="hljs-keyword">from</span> plant_carbon<span class="hljs-keyword">where</span> plant_id = <span class="hljs-string">&#x27;p002&#x27;</span>)t3;5.上推一格做出一列相减<span class="hljs-keyword">select</span>    user_id,    plant_count,    <span class="hljs-keyword">lead</span>(plant_count,<span class="hljs-number">1</span>,<span class="hljs-string">&#x27;9999-99-99&#x27;</span>) <span class="hljs-keyword">over</span>(<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> plant_count <span class="hljs-keyword">desc</span>) <span class="hljs-keyword">as</span> lead_plant_count<span class="hljs-keyword">from</span> (<span class="hljs-keyword">select</span>    user_id,    <span class="hljs-keyword">floor</span>((sum_low_carbon-t2.low_carbon)/t3.low_carbon) <span class="hljs-keyword">as</span> plant_count<span class="hljs-keyword">from</span> (<span class="hljs-keyword">select</span>    user_id,    <span class="hljs-keyword">sum</span>(low_carbon) <span class="hljs-keyword">as</span> sum_low_carbon<span class="hljs-keyword">from</span> user_low_carbon<span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> user_id)t1,(<span class="hljs-keyword">select</span>    plant_id,    low_carbon<span class="hljs-keyword">from</span> plant_carbon<span class="hljs-keyword">where</span> plant_id = <span class="hljs-string">&#x27;p004&#x27;</span>)t2,(<span class="hljs-keyword">select</span>    plant_id,    low_carbon<span class="hljs-keyword">from</span> plant_carbon<span class="hljs-keyword">where</span> plant_id = <span class="hljs-string">&#x27;p002&#x27;</span>)t3)t4;6.沙柳的个数相减<span class="hljs-keyword">select</span>    user_id,    plant_count,    plant_count - lead_plant_count <span class="hljs-keyword">as</span> plant_count_diff<span class="hljs-keyword">from</span> (<span class="hljs-keyword">select</span>    user_id,    plant_count,    <span class="hljs-keyword">lead</span>(plant_count,<span class="hljs-number">1</span>,<span class="hljs-string">&#x27;9999-99-99&#x27;</span>) <span class="hljs-keyword">over</span>(<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> plant_count <span class="hljs-keyword">desc</span>) <span class="hljs-keyword">as</span> lead_plant_count<span class="hljs-keyword">from</span> (<span class="hljs-keyword">select</span>    user_id,    <span class="hljs-keyword">floor</span>((sum_low_carbon-t2.low_carbon)/t3.low_carbon) <span class="hljs-keyword">as</span> plant_count<span class="hljs-keyword">from</span> (<span class="hljs-keyword">select</span>    user_id,    <span class="hljs-keyword">sum</span>(low_carbon) <span class="hljs-keyword">as</span> sum_low_carbon<span class="hljs-keyword">from</span> user_low_carbon<span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> user_id)t1,(<span class="hljs-keyword">select</span>    plant_id,    low_carbon<span class="hljs-keyword">from</span> plant_carbon<span class="hljs-keyword">where</span> plant_id = <span class="hljs-string">&#x27;p004&#x27;</span>)t2,(<span class="hljs-keyword">select</span>    plant_id,    low_carbon<span class="hljs-keyword">from</span> plant_carbon<span class="hljs-keyword">where</span> plant_id = <span class="hljs-string">&#x27;p002&#x27;</span>)t3)t4)t5<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> plant_count <span class="hljs-keyword">desc</span><span class="hljs-keyword">limit</span> <span class="hljs-number">10</span>;</code></pre><h3 id="第二种方式（改进版）"><a href="#第二种方式（改进版）" class="headerlink" title="第二种方式（改进版）"></a>第二种方式（改进版）</h3><p>第一种方式如果数据量很大，那么效率极低，因为我们不需要把所有的行全拿出来做运算和排序，我们只需要拿出top10的行并对其操作，所以改进如下</p><pre><code class="hljs sql">1.取大于2017/1/1 小于2017/10/1每个用户的总排放量<span class="hljs-keyword">select</span>    user_id,    <span class="hljs-keyword">sum</span>(low_carbon) <span class="hljs-keyword">as</span> sum_low_carbon<span class="hljs-keyword">from</span> user_low_carbon<span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> user_id<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> sum_low_carbon <span class="hljs-keyword">desc</span><span class="hljs-keyword">limit</span> <span class="hljs-number">11</span>;<span class="hljs-comment">--一开始就限制11条，因为用lead上提，所以需要多一行数据用来提上去</span></code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>hive</tag>
      
      <tag>sql</tag>
      
      <tag>practice</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>datalake认识</title>
    <link href="/2020/12/01/datalake/"/>
    <url>/2020/12/01/datalake/</url>
    
    <content type="html"><![CDATA[<h1 id="datalake"><a href="#datalake" class="headerlink" title="datalake"></a>datalake</h1><h2 id="什么是数据湖？"><a href="#什么是数据湖？" class="headerlink" title="什么是数据湖？"></a>什么是数据湖？</h2><p>数据湖是一类存储数据自然格式/原始格式的系统或存储，通常是对象块或者文件，包括原始系统所产生的原始数据拷贝以及为了各类任务而产生的转化数据，包括</p><ol><li>关系型数据库中的结构化数据（行列）</li><li>半结构化数据（csv,日志，xml，json）</li><li>非结构化数据（email，文档，PDF等）</li><li>二进制数据（图像，音频，视频）</li></ol><p>数据湖的定义有很多，但是基本围绕以下几个特性来展开。</p><ol><li>数据湖要有足够的存储能力，存储一个企业、组织中的所有数据</li><li>数据湖可以存储海量的任意类型的数据，结构化，半结构化，非结构化的数据</li><li>数据湖中</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>datalake</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>关于hadoop的基本知识</title>
    <link href="/2020/12/01/hadoop02/"/>
    <url>/2020/12/01/hadoop02/</url>
    
    <content type="html"><![CDATA[<h1 id="关于cdh-hadoop"><a href="#关于cdh-hadoop" class="headerlink" title="关于cdh-hadoop"></a>关于cdh-hadoop</h1><pre><code>apache hadoop软件：1.x 基本不用 6-7年左右的项目了2.x 企业主流 CDH5.X系列3.x 尝试使用 CDH6.X系列</code></pre><p>下载</p><p><a href="http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.16.2.tar.gz">http://archive.cloudera.com/cdh5/cdh/5/hadoop-2.6.0-cdh5.16.2.tar.gz</a></p><p>更新日志</p><p>&lt;<a href="http://archive.cloudera.com/cdh5/cdh/5/">http://archive.cloudera.com/cdh5/cdh/5/</a><br>hadoop-2.6.0-cdh5.16.2-changes.log&gt;</p><h2 id="关于hadoop"><a href="#关于hadoop" class="headerlink" title="关于hadoop"></a>关于hadoop</h2><ol><li>hdfs文件系统提供存储</li><li>MR计算</li><li>yarn资源（内存+vcore）+作业调度</li></ol><h2 id="模式"><a href="#模式" class="headerlink" title="模式"></a>模式</h2><pre><code>local(standalone) Mode 本地模式Pseudo-Distrbuted Mode 伪分布式模式Fully-Distributed Mode 分布式模式 集群模式 生产</code></pre><h2 id="关于nn-dn-snn"><a href="#关于nn-dn-snn" class="headerlink" title="关于nn,dn,snn"></a>关于nn,dn,snn</h2><pre><code class="hljs properties"><span class="hljs-attr">namenode</span>    <span class="hljs-string">名称节点    老大    读写请求先经过它    主节点</span><span class="hljs-attr">datanode</span>    <span class="hljs-string">数据节点    小弟    存储数据检索数据    从节点</span><span class="hljs-attr">secondrynn</span>  <span class="hljs-string">第二名称节点 老二    h+1</span></code></pre><p>大数据组件基本都是主从架构，唯独hbase（读写请求不经过老大master）</p><h1 id="关于hdfs，yarn，mr"><a href="#关于hdfs，yarn，mr" class="headerlink" title="关于hdfs，yarn，mr"></a>关于hdfs，yarn，mr</h1><h2 id="namenode"><a href="#namenode" class="headerlink" title="namenode"></a>namenode</h2><pre><code class="hljs elm">存储：文件系统的命名空间<span class="hljs-title">a</span>.文件名称<span class="hljs-title">b</span>.文件的目录结构<span class="hljs-title">c</span>.文件的属性，权限，创建时间，副本数<span class="hljs-title">d</span>.文件对应被切割为哪些数据块<span class="hljs-comment">--》分布到哪些节点上</span><span class="hljs-title">blockmap</span>当然在nn节点不会持久化，存储这种映射关系，是通过启动集群和运行时，dn会定期发送blockre<span class="hljs-keyword">port</span>给nn，一次nn在内存中动态维护这种映射关系作用：管理系统文件命名空间。维护文件系统树的所有文件和文件夹这些信息以两个文件形式永久保存在磁盘上(镜像文件fsimage,编辑日志文件editlog)<span class="hljs-title">tmp</span>/dfs/name/current</code></pre><h2 id="datanode"><a href="#datanode" class="headerlink" title="datanode"></a>datanode</h2><pre><code class="hljs stylus">存储：数据块，数据块校验，与nn通信：<span class="hljs-selector-tag">a</span>.每隔<span class="hljs-number">3</span>秒发送心跳包给nn，我还活着 dfs<span class="hljs-selector-class">.heardbeat</span>.interval<span class="hljs-selector-tag">b</span>.每隔一定的时间发送一次blockreport dfs<span class="hljs-selector-class">.blockreport</span><span class="hljs-selector-class">.intervalMse</span>    c <span class="hljs-number">2160000ms</span>=<span class="hljs-number">6</span>hdfs<span class="hljs-selector-class">.datanode</span><span class="hljs-selector-class">.directoryscan</span><span class="hljs-selector-class">.interval</span> <span class="hljs-number">2160000ms</span>=<span class="hljs-number">6</span>h</code></pre><h2 id="secondaryNamenode"><a href="#secondaryNamenode" class="headerlink" title="secondaryNamenode"></a>secondaryNamenode</h2><pre><code>存储：fsimage+editlog作用：（拷贝fsimage和edit两个文件到本地）定期合并fsimage+editlo    g文件作为新的fsimage，推送给nn，简称为checkpoint 检查点，简单来说，nn在某一个时间挂了，通过snn的备份文件恢复局限性：1h内的内容会丢失，不能百分之一百恢复数据如何解决局限性问题：HDFS HA高可用部署，两个NN，不要SNN</code></pre><p>​<br>​    模拟场景：<br>​    James Anthony Wade Paul 记录在fsimage1<br>​    </p><pre><code>新增Kobe Carter 记录在edit1checkpoint1:fsimage1+edit1 合并成 fsimage21h later fsimage2 推送给 nnfsimage2Mcgrady Iverson 记录在edit2checkpoint：fsimage2 + edit2 合并成fsimage3总结：简单来说，fsimage镜像文件存放着历史的信息+edit编辑日志文件存放更新的信息 1h 合并成新的fsimage（并更新名称），edit置空，周而复始。</code></pre><h2 id="副本放置策略"><a href="#副本放置策略" class="headerlink" title="副本放置策略"></a>副本放置策略</h2><ol><li>副本一：优先放置上传节点，其次放置本机架的负载较小的节点</li><li>副本二：放置副本一不同机架的节点</li><li>副本三：放置副本二相同机架不同节点</li></ol><h2 id="hdfs读写流程"><a href="#hdfs读写流程" class="headerlink" title="hdfs读写流程"></a>hdfs读写流程</h2><h3 id="hdfs写流程"><a href="#hdfs写流程" class="headerlink" title="hdfs写流程"></a>hdfs写流程</h3><pre><code class="hljs shell">hadoop fs -put xxx.log /</code></pre><ol><li>Client调用FileSystem.create(filePath)方法，与NN进行【rpc】通信，check是否存在权限创建，不ok返回一个错误信息；ok创建一个新的文件，不关联任何的block块，返回一个FSDataOutputStream对象；</li><li>Client调用FSDataOutputStream对象的write（）方法，现将第一个快的第一个副本写到第一个DN，第一个副本写完，传输给第二个DN，第二个副本写完；传输给第三个DN，第三个副本写完。返回一个ackpacket确认包给第二个DN，第二个DN接收到第三个ack packet确认包加上自身ok，返回给第一个ack packet确认包，加上自身ok，第一个同理，最终返回给FSDataOutputStream对象 ,标志着三个副本写完；</li><li>当向文件写入数据完成后，Client调用FSDataOutputStream.close()方法，关闭输出流；</li><li>再调用FileSystem.complete()方法，告诉NN该文件写入成功。</li></ol><h3 id="hdfs读流程"><a href="#hdfs读流程" class="headerlink" title="hdfs读流程"></a>hdfs读流程</h3><pre><code class="hljs shell">hadoop fs -text /xxx.log</code></pre><ol><li>Client调用FileSystem.open(filePath)方法，与NN进行【rpc】通信，返回该文件的部分或者全部的block块的列表，也就是返回FSDatainputStream对象；</li><li>Client端调用FSDatainputStream的read()方法<pre><code>a.与第一个块最近的DN进行read，读取完成后，会check，ok关闭与当前DN的通信，不ok，会记录失败的块+DN信息，下次不会再读取，那么回去该块的第二个DN地址读取。b.然后去第二个块最近的DN上通信读取，check后关闭通信。c.假如block列表读取完成后，文件还未结束，就再次FileSystem会从NN获取该文件的下一个批次的block列表。（感觉解释连续的数据流，对于客户端操作是透明无感知的）</code></pre></li><li>Cient调用FSDatainputStream.close()方法，关闭输入流。</li></ol><h2 id="hdfs回收站"><a href="#hdfs回收站" class="headerlink" title="hdfs回收站"></a>hdfs回收站</h2><pre><code class="hljs xml">​```core-sitem.xml    <span class="hljs-comment">&lt;!--回收站配置如果是0，代表回收站不启用--&gt;</span>    <span class="hljs-comment">&lt;!--分钟单位，10080代表7天--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>       <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.trash.interval<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>       <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>10080<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>​```</code></pre><p>注意：</p><ol><li>切记检查生产环境是否开启回收站，CDH默认是开启的</li><li>若开启回收站，慎用-skipTrash</li><li>回收站默认保留7天</li></ol><h2 id="dfsadmin"><a href="#dfsadmin" class="headerlink" title="dfsadmin"></a>dfsadmin</h2><p>如果NN log显示，进入safe mode，正常手动让其离开安全模式(很少做)。</p><pre><code class="hljs shell">[hadoop@JD hadoop]$ hdfs dfsadmin -safemode enter20/06/29 12:45:53 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableSafe mode is ON[hadoop@JD hadoop]$ hdfs dfsadmin -safemode leave20/06/29 12:49:41 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableSafe mode is OFF</code></pre><p>注意：安全模式不能读写</p><h2 id="hdfs-fsck检查文件块损坏"><a href="#hdfs-fsck检查文件块损坏" class="headerlink" title="hdfs fsck检查文件块损坏"></a>hdfs fsck检查文件块损坏</h2><pre><code class="hljs shell">[hadoop@JD hadoop]$ hdfs fsck /20/06/29 12:53:55 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicableConnecting to namenode via http://JD:50070/fsck?ugi=hadoop&amp;path=%2FFSCK started by hadoop (auth:SIMPLE) from /192.168.0.3 for path / at Mon Jun 29 12:53:56 CST 2020........Status: HEALTHY Total size:  603799 B Total dirs:  33 Total files: 8 Total symlinks:    0 Total blocks (validated):  8 (avg. block size 75474 B) Minimally replicated blocks: 8 (100.0 %) Over-replicated blocks:  0 (0.0 %) Under-replicated blocks: 0 (0.0 %) Mis-replicated blocks:   0 (0.0 %) Default replication factor:  1 Average block replication: 1.0 Corrupt blocks:    0 #!!!损坏的块 Missing replicas:    0 (0.0 %) #！！！丢失的块 Number of data-nodes:    1 Number of racks:   1FSCK ended at Mon Jun 29 12:53:56 CST 2020 in 13 millisecondsThe filesystem under path &#x27;/&#x27; is HEALTHY</code></pre><h2 id="各个dn节点数据均衡"><a href="#各个dn节点数据均衡" class="headerlink" title="各个dn节点数据均衡"></a>各个dn节点数据均衡</h2><p>为什么各个DN的数据量不一样，取决于副本策略。</p><pre><code class="hljs shell">./start-balancer.sh</code></pre><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">脚本的主要执行命令</span><span class="hljs-meta">#</span><span class="bash"> Start balancer daemon.</span>&quot;$HADOOP_PREFIX&quot;/sbin/hadoop-daemon.sh --config $HADOOP_CONF_DIR --script &quot;$bin&quot;/hdfs start balancer $@</code></pre><p>注意：</p><ol><li>所有节点的磁盘used与集群的平均used之差要小于这个阈值</li><li>dfs.datanode.balance.bandwidthPerSec 10m</li><li>可以crontab每天调度start-balancer.sh脚本，每天调度数据平衡 也称为毛刺修正</li></ol><h2 id="一个dn节点多个磁盘的数据均衡"><a href="#一个dn节点多个磁盘的数据均衡" class="headerlink" title="一个dn节点多个磁盘的数据均衡"></a>一个dn节点多个磁盘的数据均衡</h2><pre><code class="hljs shell">./start-balancer.sh -threshold 5</code></pre><p>注意：5代表上下不超过5个</p><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">模拟场景</span>df -h/data01 90%/data02 60%/data03 80%/data04 0%dfs.disk.balancer.enable must be set to true in hdfs-site.xmlhdfs disbalancer -plan JD #生成执行计划的json文件 JD.plan.jsonhdfs disbalancer -execute JD.plan.json #执行hdfs disbalancer -query JD #查询状态</code></pre><h3 id="什么时候执行或调度执行"><a href="#什么时候执行或调度执行" class="headerlink" title="什么时候执行或调度执行"></a>什么时候执行或调度执行</h3><ol><li>加入一块新的磁盘</li><li>监控服务器的磁盘剩余空间小于阈值10%，手动执行</li></ol><pre><code class="hljs xml">dfs.datanode.data.dir    /data01,/data02,/data03,/data04</code></pre><ol start="3"><li>重启生效</li></ol><h2 id="为什么dn生产上多个物理目录"><a href="#为什么dn生产上多个物理目录" class="headerlink" title="为什么dn生产上多个物理目录"></a>为什么dn生产上多个物理目录</h2><pre><code class="hljs shell">/data01 disk1/data02 disk2/data03 disk3</code></pre><ol><li>为了高效率写，高效率读</li><li>提前规划好2-3年数据存储量，避免后期加磁盘维护的工作量</li></ol><h2 id="MR2-X架构设计"><a href="#MR2-X架构设计" class="headerlink" title="MR2.X架构设计"></a>MR2.X架构设计</h2><p>MR on yarn流程，也叫mr提交应用job</p><ol><li>applicaions Manager应用程序管理器</li><li>resource scheduler 资源memeory+cpu调度器</li></ol><pre><code class="hljs xl"><span class="hljs-function"><span class="hljs-title">resourceManager</span> --管理--&gt;</span> nodeManager （rm通过管理dn，起到对资源的管理）Driver（main方法）<span class="hljs-function"><span class="hljs-title">resourceManager</span> --&gt;</span> <span class="hljs-function"><span class="hljs-title">am</span> --&gt;</span> diver(am起到解耦的作用)driver可变，计算框架可插拔container类似于虚拟机，让内部task和外部资源没有耦合性</code></pre><p><img src="/2020/12/01/hadoop02/kskuangshao/Downloads/%E5%9B%BE%E7%89%87%E8%B5%84%E6%96%99/image_1ekajvkodgaj1ioiftk1jpl1nlp9.png" alt="image_1ekajvkodgaj1ioiftk1jpl1nlp9"></p><p><img src="/2020/12/01/hadoop02/kskuangshao/Downloads/%E5%9B%BE%E7%89%87%E8%B5%84%E6%96%99/image_1ekal9ke1mf41bka4j18lar1km.png" alt="image_1ekal9ke1mf41bka4j18lar1km"></p><h3 id="container概念"><a href="#container概念" class="headerlink" title="container概念"></a>container概念</h3><p>将内存和cpu装成一个小房子</p><p>container是属于nm节点上，专门用来运行mr，spark等计算的最小节点；</p><ol><li>用户向Yarn提交应用程序（job，app location）（jar文件，sql），其中包裹ApplicationMaster程序，启动ApplicationMaster的主程序；</li><li>RM为该job分配第一个container，运行job的ApplicationMaster</li><li>App Master首先向Application Manager注册，这样就可以在RM Web界面查询这个job的界面；</li><li>App Master采用轮询的方式（通过rpc协议）向RM申请和领取资源；</li><li>一旦App Master拿到资源，就与对应的NM通信；</li><li>NM为任务设置好运行环境（jar包代码），将任务启动命令写在一个脚本里，并通过脚本启动task；</li><li>各个task通过rpc协议向App Master回报自己的进度，以此让App Master随时掌握各个任务的运行状态，从而task运行失败重启任务；</li><li>App Master向Applications 注销且关闭自己。</li></ol><h3 id="生产如何调优container参数？"><a href="#生产如何调优container参数？" class="headerlink" title="生产如何调优container参数？"></a>生产如何调优container参数？</h3><p>假设128G 16核物理core</p><ol><li>装完centos消耗1G</li><li>系统预留15%-20%的内存，防止linux的oom机制发生（128*20%+1=26G）</li><li>nn，dn本身进程4g，2g，剩余96G</li></ol><pre><code class="hljs shell">yarn.nodemanager.resource.memory-mb=96G<span class="hljs-meta">#</span><span class="bash">container总内存</span>yarn.schedular.minimum-allocation-mb 1024 <span class="hljs-meta">#</span><span class="bash">每个container最小内存</span><span class="hljs-meta">#</span><span class="bash">极限情况下，只有96个container，内存1G</span>yarn.schedular.maximum-allocation-mb 8192<span class="hljs-meta">#</span><span class="bash">每个container最大内存 </span><span class="hljs-meta">#</span><span class="bash">极限情况下，只有1个container，内存96G</span></code></pre><p>注意：container的内存会自动增加，默认1G递增</p><h3 id="container虚拟核vcore"><a href="#container虚拟核vcore" class="headerlink" title="container虚拟核vcore"></a>container虚拟核vcore</h3><ol><li>yarn自己引入的概念，设计的初衷是考虑不同节点的cpu性能不一样，每个cpu的计算能力不一样，比如某个物理cpu是另外一个物理cpu的两倍，这时，通过设置第一个物理cpu的虚拟core来弥补这种差异。（早期）</li><li>物理核:vcore = 1:2 （现在）</li></ol><pre><code class="hljs shell">yarn.nodemanager.resource.cpu-vocres 32yarn.scheduler.minimum-allocation-vcores 1 #极限情况下，只有32个containeryarn.scheduler.maximum-allocation-vcores 32 #极限情况下，只有一个containeryarn.scheduler.maximum-allocation-vcores 4 #根据官方建议，不超过5个，我们设置最大4个<span class="hljs-meta">#</span><span class="bash">最终container：1-4个vcore</span><span class="hljs-meta">#</span><span class="bash">那么极限情况有8个container</span></code></pre><h2 id="调度器"><a href="#调度器" class="headerlink" title="调度器"></a>调度器</h2><pre><code>FIFO 先进先出Capacity 计算（专门设置一个队列来运行小任务）Fair 公平</code></pre><p>apache默认是计算，CDH默认是公平（web ui schedular可查看）</p><p>动态资源池+放置规则 CDH Fair</p><p><a href="https://www.cnblogs.com/itboys/p/11379018.html">https://www.cnblogs.com/itboys/p/11379018.html</a></p><h3 id="map端的task个数是谁来决定的？"><a href="#map端的task个数是谁来决定的？" class="headerlink" title="map端的task个数是谁来决定的？"></a>map端的task个数是谁来决定的？</h3><p>map task个数 和 文件的个数有关（答对了80%）</p><p>和block块有关系</p><h3 id="文件，压缩格式"><a href="#文件，压缩格式" class="headerlink" title="文件，压缩格式"></a>文件，压缩格式</h3><ol><li>文件格式：textFile，orc，parquet，rcfile</li><li>压缩格式：gzip，snappy，lzo</li><li>hive：orc/parquet + bzip2</li><li>Hbase：hfile + snappy</li></ol><h3 id="shuffle属于map还是reduce？"><a href="#shuffle属于map还是reduce？" class="headerlink" title="shuffle属于map还是reduce？"></a>shuffle属于map还是reduce？</h3><ol><li>属于reduce阶段，shuffle为了reduce而做</li><li>map的输出作为reduce的输入的过程就是shuffle（洗牌），这个是mapreduce优化的重点地方</li></ol><h3 id="yarn的常用命令"><a href="#yarn的常用命令" class="headerlink" title="yarn的常用命令"></a>yarn的常用命令</h3><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">查询yarn应用清单</span>yarn application -list|grep xxx <span class="hljs-meta">#</span><span class="bash">删除某个已经提交yarn的应用程序</span>yarn application -kill &lt;application id&gt; <span class="hljs-meta">#</span><span class="bash">查看yarn中应用程序的<span class="hljs-built_in">log</span></span>yarn logs -application id/container id<span class="hljs-meta">#</span><span class="bash">查看app状态</span>yarn applicationattempt -list application_1528080031923_0064<span class="hljs-meta">#</span><span class="bash">查看队列的使用情况</span>yarn queue -status root.users.xxxx<span class="hljs-meta">#</span><span class="bash">转移队列</span>yarn application -movetoqueue application_1528080031923_0067 -queue root.users.xxx</code></pre><h2 id="如何查看端口号"><a href="#如何查看端口号" class="headerlink" title="如何查看端口号"></a>如何查看端口号</h2><ol><li>jps找到pid</li><li>netstat -npl|grep pid查看端口号</li></ol><pre><code class="hljs shell">[hadoop@JD ~]$ jps21761 SecondaryNameNode25825 Jps21442 NameNode21924 ResourceManager23668 RunJar27669 RunJar22150 NodeManager21580 DataNode[hadoop@JD ~]$ netstat -npl|grep 21924(Not all processes could be identified, non-owned process info will not be shown, you would have to be root to see it all.)tcp6       0      0 192.168.0.3:18088       :::*                    LISTEN      21924/javatcp6       0      0 :::8030                 :::*                    LISTEN      21924/javatcp6       0      0 :::8031                 :::*                    LISTEN      21924/javatcp6       0      0 :::8032                 :::*                    LISTEN      21924/javatcp6       0      0 :::8033                 :::*                    LISTEN      21924/java</code></pre><h1 id="现在的大数据"><a href="#现在的大数据" class="headerlink" title="现在的大数据"></a>现在的大数据</h1><ol><li>存储：hdfs文件系统，hive hbase kudu Cassandra</li><li>计算：MR Hivesql Spark Flink</li><li>资源+作业调度：Yarn</li></ol><h1 id="hadoop常见问题"><a href="#hadoop常见问题" class="headerlink" title="hadoop常见问题"></a>hadoop常见问题</h1><h2 id="pom依赖"><a href="#pom依赖" class="headerlink" title="pom依赖"></a>pom依赖</h2><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">repository</span>&gt;</span>    <span class="hljs-comment">&lt;!--Cloudera仓库--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">id</span>&gt;</span>cloudera<span class="hljs-tag">&lt;/<span class="hljs-name">id</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">url</span>&gt;</span>https://repository.cloudera.com/artifactory/cloudera-repos/<span class="hljs-tag">&lt;/<span class="hljs-name">url</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">repository</span>&gt;</span>//在properties标签里添加<span class="hljs-tag">&lt;<span class="hljs-name">hadoop.verion</span>&gt;</span>2.6.2-cdh5.16.2<span class="hljs-tag">&lt;/<span class="hljs-name">hadoop.verion</span>&gt;</span>//在depenece里添加<span class="hljs-comment">&lt;!--hadoop依赖--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">dependency</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">groupId</span>&gt;</span>org.apache.hadoop<span class="hljs-tag">&lt;/<span class="hljs-name">groupId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">artifactId</span>&gt;</span>hadoop-client<span class="hljs-tag">&lt;/<span class="hljs-name">artifactId</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="hljs-tag">&lt;/<span class="hljs-name">version</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">dependency</span>&gt;</span></code></pre><h2 id="datanode没起来"><a href="#datanode没起来" class="headerlink" title="datanode没起来"></a>datanode没起来</h2><pre><code class="hljs gradle">找到tmp文件夹,tmp文件夹下dfs<span class="hljs-regexp">/name（data）/</span>crrent/VERSION#<span class="hljs-regexp">/home/</span>hadoop<span class="hljs-regexp">/tmp/</span>dfs/VERSION里面clusterID修改成和namemode一致的重新启动#clusterID=CID-<span class="hljs-number">0</span>baa1fb4-<span class="hljs-number">6704</span>-<span class="hljs-number">42</span>df-be36-<span class="hljs-number">2845</span>d0790ae6</code></pre><h2 id="windows下报错"><a href="#windows下报错" class="headerlink" title="windows下报错"></a>windows下报错</h2><pre><code class="hljs awk">java.io.IOException: Could not locate executable null\bin\winutils.exe <span class="hljs-keyword">in</span> the Hadoop binaries解决办法：下载winutils.exe(http:<span class="hljs-regexp">//</span>public-repo-<span class="hljs-number">1</span>.hortonworks.com<span class="hljs-regexp">/hdp-win-alpha/</span>winutils.exe)创建一个目录，比如C:\winutils\bin将winutils.exe放入上述创建好的目录下设置HADOOP_HOME=C:\winutils环境变量，并将其放入PATH变量中，例如%HADOOP_HOME%\bin或者直接在程序中加入System.setProperty(<span class="hljs-string">&quot;hadoop.home.dir&quot;</span>, <span class="hljs-string">&quot;full path to the folder with winutils&quot;</span>);java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO<span class="hljs-variable">$Windows</span>.access0(Ljava<span class="hljs-regexp">/lang/</span>String;I)Z解决办法：下载winutils.exe和hadoop.dll(https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/steveloughran/</span>winutils<span class="hljs-regexp">/tree/m</span>aster<span class="hljs-regexp">/hadoop-2.7.1/</span>bin)放这两个在%HADOOP_HOME%\bin下，同时hadoop.dll也放在C:\Windows\System32目录下</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>hadoop</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>spark参数设置</title>
    <link href="/2020/12/01/spark02/"/>
    <url>/2020/12/01/spark02/</url>
    
    <content type="html"><![CDATA[<h1 id="spark-sql参数设置"><a href="#spark-sql参数设置" class="headerlink" title="spark-sql参数设置"></a>spark-sql参数设置</h1><h2 id="脚本参数"><a href="#脚本参数" class="headerlink" title="脚本参数"></a>脚本参数</h2><pre><code class="hljs shell">spark-sql \<span class="hljs-meta">#</span><span class="bash"> 一下是spark参数</span>--master yarn \--deploy-mode client \--executor-cores 4 \ #executor的核心数量--executor-memory 19G \ #executor端的内存--driver-memory 8G \ #driver端的内存--queue root.hypers.cockpit \ #指定队列--conf spark.dynamicAllocation.maxExecutors=24 \ #动态分配 最大executor数量--conf spark.hadoop.hive.cli.print.header=true \ #hive的表头--conf spark.sql.shuffle.partitions=20 \ #sparksql中shuffle的分区数量--conf spark.dynamicAllocation.enabled=true \ #开启动态分配--conf spark.sql.autoBroadcastJoinThreshold=-1 \ #广播变量 -1（禁用广播）<span class="hljs-meta">#</span><span class="bash"> 以下是hive参数</span>--hiveconf hive.exec.dynamic.partition=true \ #动态分区开启--hiveconf hive.exec.dynamic.partition.mode=nonstrict \ #非严格模式--hiveconf hive.exec.max.dynamic.partitions=1000 \ #动态分区最大值--hiveconf hive.exec.max.dynamic.partitions.pernode=1000 \ #每个节点动态分区最大值--hiveconf spark.debug.maxToStringFields=200 \ #读取的字段过多（超过25个）会报错，添加此参数</code></pre><h2 id="参数详细介绍"><a href="#参数详细介绍" class="headerlink" title="参数详细介绍"></a>参数详细介绍</h2><p>hive.exec.dynamic.partition<br>默认值：false</p><p>是否开启动态分区功能，默认false关闭。</p><p>使用动态分区时候，该参数必须设置成true;</p><p>hive.exec.dynamic.partition.mode<br>默认值：strict</p><p>动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。</p><p>一般需要设置为nonstrict</p><p>hive.exec.max.dynamic.partitions.pernode<br>默认值：100</p><p>在每个执行MR的节点上，最大可以创建多少个动态分区。</p><p>该参数需要根据实际的数据来设定。</p><p>比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。</p><p>hive.exec.max.dynamic.partitions<br>默认值：1000</p><p>在所有执行MR的节点上，最大一共可以创建多少个动态分区。</p><p>同上参数解释。</p><p>hive.exec.max.created.files<br>默认值：100000</p><p>整个MR Job中，最大可以创建多少个HDFS文件。</p><p>一般默认值足够了，除非你的数据量非常大，需要创建的文件数大于100000，可根据实际情况加以调整。</p><p>hive.error.on.empty.partition<br>默认值：false</p><p>当有空分区生成时，是否抛出异常。</p><p>一般不需要设置。</p>]]></content>
    
    
    
    <tags>
      
      <tag>spark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>spark-start</title>
    <link href="/2020/11/29/spark01/"/>
    <url>/2020/11/29/spark01/</url>
    
    <content type="html"><![CDATA[<h1 id="spark介绍"><a href="#spark介绍" class="headerlink" title="spark介绍"></a>spark介绍</h1><h2 id="一、spark产生背景"><a href="#一、spark产生背景" class="headerlink" title="一、spark产生背景"></a>一、spark产生背景</h2><p>​            mr的局限性，mr编程模型的缺点</p><pre><code>1. 计算性能不高，Task--&gt;JVM process   2. 交互式、多迭代、实时处理or流处理   3. 编程繁琐   4. 各个框架各自为战（hadoop-&gt;资源调度，hive-&gt;sql来翻译成mr作业，storm实时处理）</code></pre><h2 id="二、目前框架的需求"><a href="#二、目前框架的需求" class="headerlink" title="二、目前框架的需求"></a>二、目前框架的需求</h2><pre><code>1. 批处理、离线处理-&gt;高吞吐量   2. 流处理、实时处理-&gt;时效性   3. 交互式-&gt;低延时   4. 批流一体</code></pre><h2 id="三、spark的特点"><a href="#三、spark的特点" class="headerlink" title="三、spark的特点"></a>三、spark的特点</h2><pre><code>1. transformation、action-&gt;一定遇到action才会执行作业   2. task-&gt;线程级别、非常轻量   3. DAG、pipeline   4. 延迟调度：计算跟着数据走，你的资源不够，延迟触发！   5. 易用：java、python、scala、sql均可，超过80个high-level operator</code></pre><h2 id="四、如何选择spark版本"><a href="#四、如何选择spark版本" class="headerlink" title="四、如何选择spark版本"></a>四、如何选择spark版本</h2><ol><li>cdh5.16.2的spark版本为1.6，太低了–&gt;需要在官网下载2.4.5的spark源码包编译出安装包</li></ol><h2 id="五、spark-2-4-5的版本每个数字的意义"><a href="#五、spark-2-4-5的版本每个数字的意义" class="headerlink" title="五、spark-2.4.5的版本每个数字的意义"></a>五、spark-2.4.5的版本每个数字的意义</h2><pre><code>1. Major Version(may change APIs)</code></pre><p>注意：千万不要在你的接口API层面直接使用底层引擎的API</p><ol start="2"><li>Minor version(add APIs/Featrues)</li><li>Patch version(only bug fix)    </li></ol><p>特点：大数据场景：（必然处理的场景）存储+计算</p><h1 id="Spark编译安装"><a href="#Spark编译安装" class="headerlink" title="Spark编译安装"></a>Spark编译安装</h1><h2 id="spark下载"><a href="#spark下载" class="headerlink" title="spark下载"></a>spark下载</h2><p><a href="https://github.com/apache/spark">https://github.com/apache/spark</a></p><h2 id="编译安装"><a href="#编译安装" class="headerlink" title="编译安装"></a>编译安装</h2><pre><code class="hljs shell">mvn -DskipTests clean package./dev/make-distribution.sh --name 2.6.0-cdh5.16.2 --tgz -Pyarn -Phive -Phive-thriftserver -Pscala-2.12 -Phadoop-2.6 -Dhadoop.version=2.6.0-cdh5.16.2spark-2.4.5-bin-2.6.0-cdh5.16.2.tgz<span class="hljs-meta">#</span><span class="bash">jars 通过这个配置来传递我们需要的jar包，多个之间使用逗号分隔</span></code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>spark</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hue安装部署</title>
    <link href="/2020/11/29/hue/"/>
    <url>/2020/11/29/hue/</url>
    
    <content type="html"><![CDATA[<h1 id="hue安装部署"><a href="#hue安装部署" class="headerlink" title="hue安装部署"></a>hue安装部署</h1><pre><code>    需求：统计某些指标、导数数据：Hive/SparkSQL/Impala/RDBMS实现方式一：自己动手统计    登录到Hive所在机器    编写Hive QL语句，得到结果    结果放到Excel：柱状图、折线图、饼图等等实现方式二：通过类似的数据平台    需求提给平台组    等待平台组去处理    拿到结果，自己展示    ==&gt;数据平台上如果能够提供/开放出来类似于UI的界面在UI界面上输入SQL，拿到结果并直接在平台上进行图形化的展示开源的框架是否有类似的支持的：HUE Zeppelin是在日常的工作中是非常实用的</code></pre><pre><code class="hljs awk">hue的官方网站 https:<span class="hljs-regexp">//g</span>ethue.com/</code></pre><pre><code>前置要求：  Python2.7     MySQL       Java</code></pre><pre><code class="hljs apache"><span class="hljs-attribute">1</span>.安装依赖<span class="hljs-attribute">sudo</span> yum install -y ant asciidoc cyrus-sasl-devel cyrus-sasl-gssapi cyrus-sasl-plain gcc gcc-c++ krb<span class="hljs-number">5</span>-devel libffi-devel libxml<span class="hljs-number">2</span>-devel libxslt-devel make  mysql mysql-devel openldap-devel python-devel sqlite-devel gmp-devel</code></pre><pre><code class="hljs apache"><span class="hljs-attribute">2</span>.下载HUE<span class="hljs-attribute">http</span>://archive.cloudera.com/cdh<span class="hljs-number">5</span>/cdh/<span class="hljs-number">5</span>/     cdh<span class="hljs-number">5</span>.<span class="hljs-number">16</span>.<span class="hljs-number">2</span><span class="hljs-attribute">wget</span> http://archive.cloudera.com/cdh<span class="hljs-number">5</span>/cdh/<span class="hljs-number">5</span>/hue-<span class="hljs-number">3</span>.<span class="hljs-number">9</span>.<span class="hljs-number">0</span>-cdh<span class="hljs-number">5</span>.<span class="hljs-number">16</span>.<span class="hljs-number">2</span>.tar.gz</code></pre><pre><code class="hljs angelscript"><span class="hljs-number">3.</span>解压HUE到~/app下切换到~/app/hue<span class="hljs-number">-3.9</span><span class="hljs-number">.0</span>-cdh5<span class="hljs-number">.16</span><span class="hljs-number">.2</span>make apps</code></pre><pre><code class="hljs routeros">4.HUE配置    <span class="hljs-variable">$HUE_HOME</span>/desktop/conf/hue.ini    [desktop]            ##这个随便写，越长越好<span class="hljs-attribute">secret_key</span>=qwert1234534566<span class="hljs-attribute">http_host</span>=JD<span class="hljs-attribute">http_port</span>=38888<span class="hljs-attribute">time_zone</span>=Asia/Shanghai<span class="hljs-attribute">default_user</span>=hadoop<span class="hljs-attribute">default_hdfs_superuser</span>=hadoop<span class="hljs-attribute">localhost</span>=JD        <span class="hljs-attribute">resourcemanager_host</span>=JD        <span class="hljs-attribute">resourcemanager_port</span>=8032        <span class="hljs-attribute">resourcemanager_api_url</span>=http://JD:8088        <span class="hljs-attribute">proxy_api_url</span>=http://JD:8088        <span class="hljs-attribute">history_server_api_url</span>=http://JD:19888</code></pre><pre><code class="hljs xml">5.HUE整合HDFScore-site.xml<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.proxyuser.hadoop.hosts<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>*<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.proxyuser.hadoop.groups<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>*<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>hdfs-site.xml<span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>修改完Hadoop相关的配置之后，需要重启才生效</code></pre><pre><code class="hljs dts"><span class="hljs-number">6.</span>HUE整合MR/YARN你需要启动  mr-jobhistory-daemon.sh mapred-site.xml<span class="hljs-params">&lt;property&gt;</span><span class="hljs-params">&lt;name&gt;</span>mapreduce.jobhistory.address<span class="hljs-params">&lt;/name&gt;</span><span class="hljs-params">&lt;value&gt;</span>JD:<span class="hljs-number">10020</span><span class="hljs-params">&lt;/value&gt;</span><span class="hljs-params">&lt;/property&gt;</span><span class="hljs-params">&lt;property&gt;</span><span class="hljs-params">&lt;name&gt;</span>mapreduce.jobhistory.webapp.address<span class="hljs-params">&lt;/name&gt;</span><span class="hljs-params">&lt;value&gt;</span>JD:<span class="hljs-number">19888</span><span class="hljs-params">&lt;/value&gt;</span><span class="hljs-params">&lt;/property&gt;</span><span class="hljs-params">&lt;property&gt;</span><span class="hljs-params">&lt;name&gt;</span>mapreduce.jobhistory.done-dir<span class="hljs-params">&lt;/name&gt;</span><span class="hljs-params">&lt;value&gt;</span><span class="hljs-meta-keyword">/history/</span>done<span class="hljs-params">&lt;/value&gt;</span><span class="hljs-params">&lt;/property&gt;</span><span class="hljs-params">&lt;property&gt;</span><span class="hljs-params">&lt;name&gt;</span>mapreduce.jobhistory.intermediate-done-dir<span class="hljs-params">&lt;/name&gt;</span><span class="hljs-params">&lt;value&gt;</span><span class="hljs-meta-keyword">/history/</span>done_intermediate<span class="hljs-params">&lt;/value&gt;</span><span class="hljs-params">&lt;/property&gt;</span></code></pre><pre><code class="hljs routeros">7.HUE整合MySQL访问MySQL的数据搜/librdbms<span class="hljs-attribute">nice_name</span>=<span class="hljs-string">&quot;kskuangshao DB&quot;</span><span class="hljs-attribute">name</span>=hivedb<span class="hljs-attribute">engine</span>=mysql<span class="hljs-attribute">host</span>=JD<span class="hljs-attribute">port</span>=3306<span class="hljs-attribute">user</span>=root<span class="hljs-attribute">password</span>=123456不能多人并发访问mysql的问题：（在mysql里创建hue库。。。。官网有叙述，这里不记录）</code></pre><pre><code class="hljs routeros">8.HUE整合Hive一定要先启动hiveserver2/beeswax<span class="hljs-attribute">hive_server_host</span>=JD<span class="hljs-attribute">hive_server_port</span>=10000<span class="hljs-attribute">hive_conf_dir</span>=/var/local/hive/conf</code></pre><pre><code class="hljs awk"><span class="hljs-number">9</span>.启动HUEhue目录下<span class="hljs-variable">$&#123;HUE_HOME&#125;</span><span class="hljs-regexp">/build/</span>env<span class="hljs-regexp">/bin/</span>supervisor</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>hue</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>maven安装部署</title>
    <link href="/2020/11/29/maven01/"/>
    <url>/2020/11/29/maven01/</url>
    
    <content type="html"><![CDATA[<h1 id="maven安装部署"><a href="#maven安装部署" class="headerlink" title="maven安装部署"></a>maven安装部署</h1><h2 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h2><p>​    我的电脑-&gt;高级系统设置-&gt;环境变量-&gt;①系统变量里新建kv （K=MAVEN_HOME,V=路径）②path里添加%MAVEN_HOME%\bin</p><h2 id="验证环境变量是会否生效"><a href="#验证环境变量是会否生效" class="headerlink" title="验证环境变量是会否生效"></a>验证环境变量是会否生效</h2><pre><code class="hljs armasm"><span class="hljs-keyword">mvn</span> -v</code></pre><h2 id="修改本地maven库-一共三项"><a href="#修改本地maven库-一共三项" class="headerlink" title="修改本地maven库(一共三项)"></a>修改本地maven库(一共三项)</h2><pre><code class="hljs shell">&lt;localRepository&gt;E:\mvn_localRepository&lt;/localRepository&gt; &lt;mirror&gt;&lt;id&gt;nexus-aliyun&lt;/id&gt;&lt;mirrorOf&gt;*&lt;/mirrorOf&gt;&lt;name&gt;Nexus aliyun&lt;/name&gt;&lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt;&lt;/mirror&gt; &lt;mirror&gt;      &lt;id&gt;alimaven&lt;/id&gt;      &lt;name&gt;aliyun maven&lt;/name&gt;      &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public/&lt;/url&gt;      &lt;mirrorOf&gt;central&lt;/mirrorOf&gt;           &lt;/mirror&gt;&lt;profile&gt;    &lt;id&gt;jdk-1.8&lt;/id&gt;    &lt;activation&gt;    &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;    &lt;jdk&gt;1.8&lt;/jdk&gt;    &lt;/activation&gt;    &lt;properties&gt;    &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt;    &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;    &lt;maven.compiler.compilerVersion&gt;1.8&lt;/maven.compiler.compilerVersion&gt;    &lt;/properties&gt;    &lt;/profile&gt; &lt;repositories&gt;  &lt;repository&gt;  &lt;id&gt;cloudera&lt;/id&gt;            &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos/&lt;/url&gt;        &lt;/repository&gt;&lt;/repositories&gt;</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>maven</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hive安装部署</title>
    <link href="/2020/11/29/hive03/"/>
    <url>/2020/11/29/hive03/</url>
    
    <content type="html"><![CDATA[<h1 id="hive安装部署"><a href="#hive安装部署" class="headerlink" title="hive安装部署"></a>hive安装部署</h1><h2 id="hive-site-xml"><a href="#hive-site-xml" class="headerlink" title="hive-site.xml"></a>hive-site.xml</h2><pre><code class="hljs xml"><span class="hljs-meta">&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;no&quot;?&gt;</span><span class="hljs-meta">&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>javax.jdo.option.ConnectionURL<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>jdbc:mysql://JD:3306/hive?createDatabaseIfNotExist=true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>javax.jdo.option.ConnectionDriverName<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>com.mysql.jdbc.Driver<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>javax.jdo.option.ConnectionUserName<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hive<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>javax.jdo.option.ConnectionPassword<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hive<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hive.metastore.warehouse.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/user/hive/warehouse<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">description</span>&gt;</span>location of default database for the warehouse<span class="hljs-tag">&lt;/<span class="hljs-name">description</span>&gt;</span>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>  <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>datanucleus.autoStartMechanism<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>SchemaTable<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>  <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>      <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>       <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hive.server2.thrift.port<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>      <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>10000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>       <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hive.server2.thrift.bind.host<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>       <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>JD<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>     <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></code></pre><h2 id="拷贝jdbc"><a href="#拷贝jdbc" class="headerlink" title="拷贝jdbc"></a>拷贝jdbc</h2><p>拷贝mysql-connect-jdbc.jar到hive/lib目录下</p><h2 id="启动两个服务"><a href="#启动两个服务" class="headerlink" title="启动两个服务"></a>启动两个服务</h2><pre><code class="hljs angelscript"><span class="hljs-number">1.</span>metastorenohup hive --service metastore &gt; ~/log/metastore.log <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span> &amp;</code></pre><pre><code class="hljs apache"><span class="hljs-attribute">2</span>.hiveserver<span class="hljs-number">2</span><span class="hljs-attribute">nohup</span> hiveserver<span class="hljs-number">2</span> &gt; ~/log/hiveserver<span class="hljs-number">2</span>.log <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span> &amp;</code></pre><pre><code class="hljs stan"><span class="hljs-number">3.</span>查看日志<span class="hljs-built_in">tail</span> -F ~/<span class="hljs-built_in">log</span>/hiveserver2.<span class="hljs-built_in">log</span></code></pre><h2 id="修改hdfs-site-xml"><a href="#修改hdfs-site-xml" class="headerlink" title="修改hdfs-site.xml"></a>修改hdfs-site.xml</h2><p>​    加入一条配置信息，表示启用 webhdfs</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.webhdfs.enabled<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>true<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></code></pre><h2 id="修改core-site-xml"><a href="#修改core-site-xml" class="headerlink" title="修改core-site.xml"></a>修改core-site.xml</h2><p>​    加入两条配置信息：表示设置 hadoop 的代理用户1</p><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.proxyuser.hadoop.hosts<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>*<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.proxyuser.hadoop.groups<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span> <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>*<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></code></pre><h2 id="beeline登录hive"><a href="#beeline登录hive" class="headerlink" title="beeline登录hive"></a>beeline登录hive</h2><pre><code class="hljs groovy">beeline!connect <span class="hljs-attr">jdbc:</span><span class="hljs-attr">hive2:</span><span class="hljs-comment">//JD:10000/default</span>usernamepassword</code></pre><h2 id="DBeaver连接hive"><a href="#DBeaver连接hive" class="headerlink" title="DBeaver连接hive"></a>DBeaver连接hive</h2><p>全局搜索（jar包添加到一个制定目录，找不到jar怎么办）<br>cd到hadoop目录下执行：</p><pre><code class="hljs routeros"><span class="hljs-builtin-name">find</span> ./ -name <span class="hljs-string">&quot;hadoop-common*&quot;</span></code></pre><p>cd到hive目录下执行</p><pre><code class="hljs routeros"><span class="hljs-builtin-name">find</span> ./ -name <span class="hljs-string">&#x27;hive-jdbc*&#x27;</span></code></pre><p>然后搞定！</p><p>可以查看一下1w端口</p><pre><code class="hljs 1c">netstat -nlp<span class="hljs-string">|grep 10000 </span></code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>hive</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hadoop伪分布式安装部署</title>
    <link href="/2020/11/29/hadoop01/"/>
    <url>/2020/11/29/hadoop01/</url>
    
    <content type="html"><![CDATA[<h1 id="hadoop伪分布式安装部署"><a href="#hadoop伪分布式安装部署" class="headerlink" title="hadoop伪分布式安装部署"></a>hadoop伪分布式安装部署</h1><h2 id="1-wget下载-这种方式快"><a href="#1-wget下载-这种方式快" class="headerlink" title="1.wget下载(这种方式快)"></a>1.wget下载(这种方式快)</h2><pre><code class="hljs shell">wget http://archive.cloudera.com/cdh5/cdh/5/hive-1.1.0-cdh5.16.2.tar.gz</code></pre><h2 id="2-关于目录"><a href="#2-关于目录" class="headerlink" title="2.关于目录"></a>2.关于目录</h2><h3 id="1-创建文件目录"><a href="#1-创建文件目录" class="headerlink" title="1.创建文件目录"></a>1.创建文件目录</h3><pre><code class="hljs shell">[ks@JD ~]$mkdir app software sourcecode log data tmp lib</code></pre><h3 id="a-解压到家目录-app"><a href="#a-解压到家目录-app" class="headerlink" title="a.解压到家目录/app"></a>a.解压到家目录/app</h3><pre><code class="hljs shell">[ks@JD software]$ tar -xzvf hadoop-2.6.0-cdh5.16.2.tar.gz -C ~/app/</code></pre><h3 id="b-做软连接（方便版本更新）（注意前后）"><a href="#b-做软连接（方便版本更新）（注意前后）" class="headerlink" title="b.做软连接（方便版本更新）（注意前后）"></a>b.做软连接（方便版本更新）（注意前后）</h3><pre><code class="hljs shell">[ks@JD app]$ln -s hive-1.1.0-cdh5.16.2 hive</code></pre><h2 id="3-Java环境"><a href="#3-Java环境" class="headerlink" title="3.Java环境"></a>3.Java环境</h2><pre><code class="hljs shell">/usr/java #位置必须是这样</code></pre><h2 id="4-hadoop环境变量"><a href="#4-hadoop环境变量" class="headerlink" title="4.hadoop环境变量"></a>4.hadoop环境变量</h2><pre><code class="hljs shell">[ks@JD ~]$ vi .bashrcexport HADOOP_HOME=/home/ks/app/hadoopexport HIVE_HOME=/home/ks/app/hiveexport PATH=$&#123;HADOOP_HOME&#125;/bin:$&#123;HADOOP_HOME&#125;/sbin:$&#123;HIVE_HOME&#125;/bin:$PATH[ks@JD ~]$ source .bashrc [ks@JD ~]$ which hdfs[ks@JD ~]$ which hive</code></pre><p><a href="https://hadoop.apache.org去找single/">https://hadoop.apache.org去找single</a> node cluster单节点伪分布式资料</p><h2 id="5-配置ssh信任关系"><a href="#5-配置ssh信任关系" class="headerlink" title="5.配置ssh信任关系"></a>5.配置ssh信任关系</h2><pre><code class="hljs shell">家目录下输入<span class="hljs-meta">  $</span><span class="bash"> ssh-keygen -t rsa -P <span class="hljs-string">&#x27;&#x27;</span> -f ~/.ssh/id_rsa</span><span class="hljs-meta">  $</span><span class="bash"> cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span><span class="hljs-meta">  $</span><span class="bash"> chmod 0600 ~/.ssh/authorized_keys</span></code></pre><h2 id="6-etl-hadoop下配置文件"><a href="#6-etl-hadoop下配置文件" class="headerlink" title="6.etl/hadoop下配置文件"></a>6.etl/hadoop下配置文件</h2><h3 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h3><pre><code class="hljs xml">   <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>       <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>fs.defaultFS<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>       <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>hdfs://focus:9000<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>   <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>   <span class="hljs-comment">&lt;!--hadoop的tmp目录30天清理一次--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>       <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>hadoop.tmp.dir<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>       <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>/home/ks/tmp<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>   <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></code></pre><h3 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h3><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">configuration</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.replication<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>1<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-comment">&lt;!--下面两个参数snn以focus这个localhost启动，不是0.0.0.0启动--&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>focus:9868<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>dfs.namenode.secondary.https-address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>focus:9869<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">configuration</span>&gt;</span></code></pre><h3 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a>mapred-site.xml</h3><pre><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>mapreduce.framework.name<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>    <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>yarn<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></code></pre><h3 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a>yarn-site.xml</h3><pre><code class="hljs xml">    <span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>mapreduce_shuffle<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span><span class="hljs-comment">&lt;!--以防被挖矿--&gt;</span><span class="hljs-tag">&lt;<span class="hljs-name">property</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="hljs-tag">&lt;/<span class="hljs-name">name</span>&gt;</span>        <span class="hljs-tag">&lt;<span class="hljs-name">value</span>&gt;</span>focus:18088<span class="hljs-tag">&lt;/<span class="hljs-name">value</span>&gt;</span>    <span class="hljs-tag">&lt;/<span class="hljs-name">property</span>&gt;</span></code></pre><h4 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a>hadoop-env.sh</h4><pre><code class="hljs elm"><span class="hljs-title">java</span>环境变量ex<span class="hljs-keyword">port</span></code></pre><h2 id="7-格式化目录"><a href="#7-格式化目录" class="headerlink" title="7.格式化目录"></a>7.格式化目录</h2><pre><code class="hljs shell">hdfs namenode -format (看是否出现successfully)</code></pre><h2 id="8-启动"><a href="#8-启动" class="headerlink" title="8.启动"></a>8.启动</h2><pre><code class="hljs shell">start-dfs.shstart-all</code></pre><h2 id="9-查看hdfs"><a href="#9-查看hdfs" class="headerlink" title="9.查看hdfs"></a>9.查看hdfs</h2><pre><code class="hljs shell">hdfs dfs -ls /</code></pre><h2 id="10-网页查看hdfs"><a href="#10-网页查看hdfs" class="headerlink" title="10.网页查看hdfs"></a>10.网页查看hdfs</h2><pre><code class="hljs awk">http:<span class="hljs-regexp">//</span><span class="hljs-number">114.67</span>.<span class="hljs-number">80.217</span>:<span class="hljs-number">50070</span>/</code></pre><h2 id="11-网页查看yarn"><a href="#11-网页查看yarn" class="headerlink" title="11.网页查看yarn"></a>11.网页查看yarn</h2><pre><code class="hljs awk">http:<span class="hljs-regexp">//</span><span class="hljs-number">114.67</span>.<span class="hljs-number">80.217</span>:<span class="hljs-number">18088</span>/</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>hadoop</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>markdown教程</title>
    <link href="/2020/11/23/markdown/"/>
    <url>/2020/11/23/markdown/</url>
    
    <content type="html"><![CDATA[<p><img src="/2020/11/23/markdown/image-20200210154710148.png" alt="image-20200210154710148"></p><h1 id="MarkDown基础"><a href="#MarkDown基础" class="headerlink" title="MarkDown基础"></a>MarkDown基础</h1><p><a href="https://www.bilibili.com/video/av87982836#reply2366896129">基础篇视频讲解链接</a><br><a href="https://www.bilibili.com/video/av88551739/">画图篇视频讲解链接</a></p><h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><pre><code class="hljs markdown"><span class="hljs-section"># 标题名字（井号的个数代表标题的级数）</span></code></pre><h1 id="一级标题使用1个"><a href="#一级标题使用1个" class="headerlink" title="一级标题使用1个#"></a>一级标题使用1个#</h1><h2 id="二级标题使用2个"><a href="#二级标题使用2个" class="headerlink" title="二级标题使用2个#"></a>二级标题使用2个#</h2><h3 id="三级标题使用3个"><a href="#三级标题使用3个" class="headerlink" title="三级标题使用3个#"></a>三级标题使用3个#</h3><h4 id="四级标题使4用个"><a href="#四级标题使4用个" class="headerlink" title="四级标题使4用个#"></a>四级标题使4用个#</h4><h5 id="五级标题使用5个"><a href="#五级标题使用5个" class="headerlink" title="五级标题使用5个#"></a>五级标题使用5个#</h5><h6 id="六级标题使用6个"><a href="#六级标题使用6个" class="headerlink" title="六级标题使用6个#"></a>六级标题使用6个#</h6><p>####### 最多支持六级标题#</p><h2 id="文字"><a href="#文字" class="headerlink" title="文字"></a>文字</h2><h3 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h3><pre><code class="hljs markdown">这就是 ~~删除线~~ (使用波浪号)</code></pre><p>这就是 <del>删除线</del> (使用波浪号)</p><h3 id="斜体"><a href="#斜体" class="headerlink" title="斜体"></a>斜体</h3><pre><code class="hljs markdown">这是用来 <span class="hljs-emphasis">*斜体*</span> 的 <span class="hljs-emphasis">_文本_</span></code></pre><p>这是用来 <em>斜体</em> 的 <em>文本</em></p><h3 id="加粗"><a href="#加粗" class="headerlink" title="加粗"></a>加粗</h3><pre><code class="hljs markdown">这是用来 <span class="hljs-strong">**加粗**</span> 的 <span class="hljs-strong">__文本__</span></code></pre><p>这是用来 <strong>加粗</strong> 的 <strong>文本</strong></p><h3 id="斜体-加粗"><a href="#斜体-加粗" class="headerlink" title="斜体+加粗"></a>斜体+加粗</h3><pre><code class="hljs markdown">这是用来 <span class="hljs-strong">**<span class="hljs-emphasis">*斜体+加粗<span class="hljs-strong">**<span class="hljs-emphasis">* 的 <span class="hljs-strong">__<span class="hljs-emphasis">_文本<span class="hljs-strong">__<span class="hljs-emphasis">_</span></span></span></span></span></span></span></span></code></pre><p>这是用来 <strong><em>斜体+加粗</em></strong> 的 <strong><em>文本</em></strong></p><h3 id="下划线"><a href="#下划线" class="headerlink" title="下划线"></a>下划线</h3><p>下划线是HTML语法</p><p><code>下划线</code> <u>下划线(快捷键<code>command</code>+<code>u</code>，视频中所有的快捷键都是针对Mac系统，其他系统可自行查找)</u></p><h3 id="高亮（需勾选扩展语法）"><a href="#高亮（需勾选扩展语法）" class="headerlink" title="高亮（需勾选扩展语法）"></a>高亮（需勾选扩展语法）</h3><pre><code class="hljs markdown">这是用来 ==斜体+加粗== 的文本</code></pre><p>这是用来 ==斜体+加粗== 的文本</p><h3 id="下标（需勾选扩展语法）"><a href="#下标（需勾选扩展语法）" class="headerlink" title="下标（需勾选扩展语法）"></a>下标（需勾选扩展语法）</h3><pre><code class="hljs markdown">水 H~2~O 双氧水 H~2~O~2~</code></pre><p>水 H<del>2</del>O </p><p>双氧水 H<del>2</del>O<del>2</del></p><h3 id="上标（需勾选扩展语法）"><a href="#上标（需勾选扩展语法）" class="headerlink" title="上标（需勾选扩展语法）"></a>上标（需勾选扩展语法）</h3><pre><code class="hljs markdown">面积 m^2^ 体积 m^3^</code></pre><p>面积 m^2^<br>体积 m^3^</p><h3 id="表情符号"><a href="#表情符号" class="headerlink" title="表情符号"></a>表情符号</h3><p> Emoji 支持表情符号，你可以用系统默认的 Emoji 符号（ Windows 用户不一定支持，自己试下~）。 也可以用图片的表情，输入 <code>:</code> 将会出现智能提示。  </p><h4 id="一些表情例子"><a href="#一些表情例子" class="headerlink" title="一些表情例子"></a>一些表情例子</h4><pre><code class="hljs markdown">:smile: :laughing: :dizzy<span class="hljs-emphasis">_face: :sob: :cold_</span>sweat: :sweat<span class="hljs-emphasis">_smile:  :cry: :triumph: :heart_</span>eyes: :relaxed: :sunglasses: :weary::+1: :-1: :100: :clap: :bell: :gift: :question: :bomb: :heart: :coffee: :cyclone: :bow: :kiss: :pray: :sweat<span class="hljs-emphasis">_drops: :hankey: :exclamation: :anger:</span><span class="hljs-emphasis"></span></code></pre><p>:smile: :laughing: :dizzy_face: :sob: :cold_sweat: :sweat_smile:  :cry: :triumph: :heart_eyes: :relaxed: :sunglasses: :weary: :+1: :-1: :100: :clap: :bell: :gift: :question: :bomb: :heart: :coffee: :cyclone: :bow: :kiss: :pray: :sweat_drops: :hankey: :exclamation: :anger:</p><p>(  Mac: <code>control</code>+<code>command</code>+<code>space</code>点选)</p><h3 id="表格"><a href="#表格" class="headerlink" title="表格"></a>表格</h3><p>使用 <code>|</code> 来分隔不同的单元格，使用 <code>-</code> 来分隔表头和其他行：</p><pre><code class="hljs markdown">name | price--- | ---fried chicken | 19cola|5</code></pre><blockquote><p>为了使 Markdown 更清晰，<code>|</code> 和 <code>-</code> 两侧需要至少有一个空格（最左侧和最右侧的 <code>|</code> 外就不需要了）。</p></blockquote><table><thead><tr><th>name</th><th>price</th></tr></thead><tbody><tr><td>fried chicken</td><td>19</td></tr><tr><td>cola</td><td>5</td></tr></tbody></table><p>为了美观，可以使用空格对齐不同行的单元格，并在左右两侧都使用 <code>|</code> 来标记单元格边界，在表头下方的分隔线标记中加入 <code>:</code>，即可标记下方单元格内容的对齐方式：</p><pre><code class="hljs markdown">|    name       | price || :------------ | :---: || fried chicken | 19    || cola          |  32   |</code></pre><table><thead><tr><th align="left">name</th><th align="center">price</th></tr></thead><tbody><tr><td align="left">fried chicken</td><td align="center">19</td></tr><tr><td align="left">cola</td><td align="center">32</td></tr></tbody></table><p>使用快捷键<code>command</code>+<code>opt</code>+<code>T</code>更方便(段落→表格→插入表格，即可查看快捷键)</p><h2 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h2><pre><code class="hljs markdown">&gt;“后悔创业”</code></pre><blockquote><p>“后悔创业”</p></blockquote><pre><code class="hljs markdown">&gt;也可以在引用中&gt;&gt;使用嵌套的引用</code></pre><blockquote><p>也可以在引用中</p><blockquote><p>使用嵌套的引用</p></blockquote></blockquote><h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><h3 id="无序列表–符号-空格"><a href="#无序列表–符号-空格" class="headerlink" title="无序列表–符号 空格"></a>无序列表–符号 空格</h3><pre><code class="hljs markdown"><span class="hljs-bullet">*</span> 可以使用 <span class="hljs-code">`*`</span> 作为标记<span class="hljs-bullet">+</span> 也可以使用 <span class="hljs-code">`+`</span><span class="hljs-bullet">-</span> 或者 <span class="hljs-code">`-`</span></code></pre><ul><li>可以使用 <code>*</code> 作为标记</li></ul><ul><li>也可以使用 <code>+</code></li></ul><ul><li>或者 <code>-</code></li></ul><h3 id="有序列表–数字-空格"><a href="#有序列表–数字-空格" class="headerlink" title="有序列表–数字 . 空格"></a>有序列表–数字 <code>.</code> 空格</h3><pre><code class="hljs markdown"><span class="hljs-bullet">1.</span> 有序列表以数字和 <span class="hljs-code">`.`</span> 开始；<span class="hljs-bullet">3.</span> 数字的序列并不会影响生成的列表序列；<span class="hljs-bullet">4.</span> 但仍然推荐按照自然顺序（1.2.3...）编写。</code></pre><ol><li><p>有序列表以数字和 <code>.</code> 开始；</p></li><li><p>数字的序列并不会影响生成的列表序列；</p></li><li><p>但仍然推荐按照自然顺序（1.2.3…）编写。</p><pre><code class="hljs markdown">可以使用：数字\. 来取消显示为列表（用反斜杠进行转义）</code></pre></li></ol><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h2><h3 id="代码块"><a href="#代码块" class="headerlink" title="代码块"></a>代码块</h3><pre><code class="hljs markdown">​<span class="hljs-code">```语言名称</span></code></pre><pre><code class="hljs java"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">(String[] args)</span> </span>&#123;   &#125;</code></pre><h3 id="行内代码"><a href="#行内代码" class="headerlink" title="行内代码"></a>行内代码</h3><pre><code class="hljs markdown">也可以通过 <span class="hljs-code">``，插入行内代码（`</span> 是 <span class="hljs-code">`Tab`</span> 键上边、数字 <span class="hljs-code">`1`</span> 键左侧的那个按键）：例如 <span class="hljs-code">`Markdown`</span></code></pre><p><code>Markdown</code></p><h3 id="转换规则"><a href="#转换规则" class="headerlink" title="转换规则"></a>转换规则</h3><p>代码块中的文本（包括 Markdown 语法）都会显示为原始内容</p><h2 id="分隔线"><a href="#分隔线" class="headerlink" title="分隔线"></a>分隔线</h2><p>可以在一行中使用三个或更多的 <code>*</code>、<code>-</code> 或 <code>_</code> 来添加分隔线（``）：</p><pre><code class="hljs markdown"><span class="hljs-strong">**<span class="hljs-emphasis">*</span></span><span class="hljs-strong"><span class="hljs-emphasis">------</span></span><span class="hljs-strong"><span class="hljs-emphasis"><span class="hljs-strong">__<span class="hljs-emphasis">_</span></span></span></span></code></pre><hr><hr><hr><h2 id="跳转"><a href="#跳转" class="headerlink" title="跳转"></a>跳转</h2><h3 id="外部跳转–超链接"><a href="#外部跳转–超链接" class="headerlink" title="外部跳转–超链接"></a>外部跳转–超链接</h3><p>格式为 <code>[link text](link)</code>。</p><pre><code class="hljs markdown">[<span class="hljs-string">帮助文档</span>](<span class="hljs-link">https://support.typora.io/Links/#faq</span>)</code></pre><p><a href="https://support.typora.io/Links/#faq">帮助文档</a></p><h3 id="内部跳转–本文件内跳（Typora支持）"><a href="#内部跳转–本文件内跳（Typora支持）" class="headerlink" title="内部跳转–本文件内跳（Typora支持）"></a>内部跳转–本文件内跳（Typora支持）</h3><p>格式为 <code>[link text](#要去的目的地--标题）</code>。</p><pre><code class="hljs markdown">[<span class="hljs-string">我想跳转</span>](<span class="hljs-link">#饼图（Pie）</span>)</code></pre><blockquote><p>Open Links in Typora</p><p>You can use <code>command+click</code> (macOS), or <code>ctrl+click</code> (Linux/Windows) on links in Typora to jump to target headings, or open them in Typora, or open in related apps.</p></blockquote><p><a href="#%E9%A5%BC%E5%9B%BE%EF%BC%88Pie%EF%BC%89">我想跳转</a></p><h3 id="自动链接"><a href="#自动链接" class="headerlink" title="自动链接"></a>自动链接</h3><p>使用 <code>&lt;&gt;</code> 包括的 URL 或邮箱地址会被自动转换为超链接：</p><pre><code class="hljs markdown"><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">https:</span>//<span class="hljs-attr">www.baidu.com</span>&gt;</span></span><span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">123@email.com</span>&gt;</span></span></code></pre><p><a href="https://www.baidu.com/">https://www.baidu.com</a></p><p><a href="mailto:123@email.com">123@email.com</a></p><h2 id="图片"><a href="#图片" class="headerlink" title="图片"></a>图片</h2><pre><code class="hljs markdown">![<span class="hljs-string">自己起的图片名字</span>](<span class="hljs-link">图片地址或者图片本地存储的路径</span>)</code></pre><h3 id="网上的图片"><a href="#网上的图片" class="headerlink" title="网上的图片"></a>网上的图片</h3><pre><code class="hljs markdown">![<span class="hljs-string">friedChicken</span>](<span class="hljs-link">https://ss0.bdstatic.com/94oJfD_bAAcT8t7mm9GUKT-xh_/timg?image&amp;quality=100&amp;size=b4000_4000&amp;sec=1580814517&amp;di=2630beac440e5dab0e44c7286a3b2b61&amp;src=http://imgsrc.baidu.com/forum/w=580/sign=12c730c4ff03738dde4a0c2a831ab073/9497794f9258d1091818e6d6d858ccbf6d814d1b.jpg</span>)</code></pre><p><img src="https://ss0.bdstatic.com/94oJfD_bAAcT8t7mm9GUKT-xh_/timg?image&quality=100&size=b4000_4000&sec=1580814517&di=2630beac440e5dab0e44c7286a3b2b61&src=http://imgsrc.baidu.com/forum/w=580/sign=12c730c4ff03738dde4a0c2a831ab073/9497794f9258d1091818e6d6d858ccbf6d814d1b.jpg" alt="炸鸡"></p><h3 id="本地图片"><a href="#本地图片" class="headerlink" title="本地图片"></a>本地图片</h3><pre><code class="hljs markdown">![<span class="hljs-string">friedChicken</span>](<span class="hljs-link">friedChicken.jpg</span>)在同一个文件夹里（用相对路径）或者直接拷贝</code></pre><p><img src="/2020/11/23/markdown/friedChicken.jpg" alt="friedChicken"></p><p><img src="/2020/11/23/markdown/cola.jpg" alt="cola"></p><h2 id="利用Markdown画图（需勾选扩展语法）"><a href="#利用Markdown画图（需勾选扩展语法）" class="headerlink" title="利用Markdown画图（需勾选扩展语法）"></a>利用Markdown画图（需勾选扩展语法）</h2><p><img src="/2020/11/23/markdown/image-20200211211500416.png" alt="image-20200211211500416"></p><p>markdown画图也是轻量级的，功能并不全。</p><p>Mermaid 是一个用于画流程图、状态图、时序图、甘特图的库，使用 JS 进行本地渲染，广泛集成于许多 Markdown 编辑器中。Mermaid 作为一个使用 JS 渲染的库，生成的不是一个“图片”，而是一段 HTML 代码。</p><p>（不同的编辑器渲染的可能不一样）</p><h3 id="流程图-graph"><a href="#流程图-graph" class="headerlink" title="流程图(graph)"></a>流程图(graph)</h3><h4 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h4><pre><code class="hljs markdown">graph 方向描述<span class="hljs-code">    图表中的其他语句...</span></code></pre><p>关键字graph表示一个流程图的开始，同时需要指定该图的方向。</p><p>其中“方向描述”为：</p><table><thead><tr><th align="left">用词</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">TB</td><td align="left">从上到下</td></tr><tr><td align="left">BT</td><td align="left">从下到上</td></tr><tr><td align="left">RL</td><td align="left">从右到左</td></tr><tr><td align="left">LR</td><td align="left">从左到右</td></tr></tbody></table><blockquote><p>T = TOP，B = BOTTOM，L = LEFT，R = RIGHT，D = DOWN</p></blockquote><p>最常用的布局方向是TB、LR。</p><pre><code class="hljs markdown">graph TB;  A--&gt;B  B--&gt;C  C--&gt;A</code></pre><pre><code class="hljs mermaid">graph TB;  A--&gt;B  B--&gt;C  C--&gt;A</code></pre><pre><code class="hljs markdown">graph LR;  A--&gt;B  B--&gt;C  C--&gt;A</code></pre><pre><code class="hljs mermaid">graph LR;  A--&gt;B  B--&gt;C  C--&gt;A</code></pre><h4 id="流程图常用符号及含义"><a href="#流程图常用符号及含义" class="headerlink" title="流程图常用符号及含义"></a>流程图常用符号及含义</h4><h5 id="节点形状"><a href="#节点形状" class="headerlink" title="节点形状"></a>节点形状</h5><table><thead><tr><th align="left">表述</th><th align="left">说明</th><th>含义</th></tr></thead><tbody><tr><td align="left">id[文字]</td><td align="left">矩形节点</td><td>表示过程，也就是整个流程中的一个环节</td></tr><tr><td align="left">id(文字)</td><td align="left">圆角矩形节点</td><td>表示开始和结束</td></tr><tr><td align="left">id((文字))</td><td align="left">圆形节点</td><td>表示连接。为避免流程过长或有交叉，可将流程切开。成对</td></tr><tr><td align="left">id{文字}</td><td align="left">菱形节点</td><td>表示判断、决策</td></tr><tr><td align="left">id&gt;文字]</td><td align="left">右向旗帜状节点</td><td></td></tr></tbody></table><p><strong>单向箭头线段</strong>：表示流程进行方向</p><blockquote><p>id即为节点的唯一标识，A~F 是当前节点名字，类似于变量名，画图时便于引用</p><p>括号内是节点中要显示的文字，默认节点的名字和显示的文字都为A</p></blockquote><pre><code class="hljs markdown">graph TB  A  B(圆角矩形节点)  C[矩形节点]  D((圆形节点))  E&#123;菱形节点&#125;  F&gt;右向旗帜状节点]</code></pre><pre><code class="hljs mermaid">graph TB  A  B(圆角矩形节点)  C[矩形节点]  D((圆形节点))  E&#123;菱形节点&#125;  F&gt;右向旗帜状节点]</code></pre><pre><code class="hljs markdown">graph TB<span class="hljs-code">    begin(出门)--&gt; buy[买炸鸡]</span><span class="hljs-code">    buy --&gt; IsRemaining&#123;&quot;还有没有炸鸡？&quot;&#125;</span><span class="hljs-code">    IsRemaining --&gt;|有|happy[买完炸鸡开心]--&gt; goBack(回家)</span><span class="hljs-code">    IsRemaining --没有--&gt; sad[&quot;伤心&quot;]--&gt; goBack</span><span class="hljs-code">    </span></code></pre><pre><code class="hljs mermaid">graph TB    begin(出门)--&gt; buy[买炸鸡]    buy --&gt; IsRemaining&#123;&quot;还有没有炸鸡？&quot;&#125;    IsRemaining --&gt;|有|happy[买完炸鸡开心]--&gt; goBack(回家)    IsRemaining --没有--&gt; sad[&quot;伤心&quot;]--&gt; goBack</code></pre><h5 id="连线"><a href="#连线" class="headerlink" title="连线"></a>连线</h5><pre><code class="hljs markdown">graph TB  A1--&gt;B1  A2---B2  A3--text---B3  A4--text--&gt;B4  A5-.-B5  A6-.-&gt;B6  A7-.text.-B7  A8-.text.-&gt;B8  A9===B9  A10==&gt;B10  A11==text===B11  A12==text==&gt;B12</code></pre><pre><code class="hljs mermaid">graph TB  A1--&gt;B1  A2---B2  A3--text---B3  A4--text--&gt;B4  A5-.-B5  A6-.-&gt;B6  A7-.text.-B7  A8-.text.-&gt;B8  A9&#x3D;&#x3D;&#x3D;B9  A10&#x3D;&#x3D;&gt;B10  A11&#x3D;&#x3D;text&#x3D;&#x3D;&#x3D;B11  A12&#x3D;&#x3D;text&#x3D;&#x3D;&gt;B12</code></pre><pre><code class="hljs mermaid">graph TB A ---B</code></pre><h5 id="子图表"><a href="#子图表" class="headerlink" title="子图表"></a>子图表</h5><p>使用以下语法添加子图表</p><pre><code class="hljs markdown">subgraph 子图表名称<span class="hljs-code">    子图表中的描述语句...</span><span class="hljs-code">end</span></code></pre><pre><code class="hljs markdown">graph TB<span class="hljs-code">  subgraph 买炸鸡前</span><span class="hljs-code">    begin(出门)--&gt; buy[出门买炸鸡]</span><span class="hljs-code">    end</span><span class="hljs-code">    buy --&gt; IsRemaining&#123;&quot;还有没有炸鸡？&quot;&#125;</span><span class="hljs-code">    IsRemaining --没有--&gt; sad[&quot;伤心&quot;]--&gt; goBack(回家)</span><span class="hljs-code">    IsRemaining --&gt;|有|happy[买完炸鸡开心]--&gt; goBack</span></code></pre><pre><code class="hljs mermaid">graph TB  subgraph 买炸鸡前    begin(出门)--&gt; buy[出门买炸鸡]    end    buy --&gt; IsRemaining&#123;&quot;还有没有炸鸡？&quot;&#125;    IsRemaining --没有--&gt; sad[&quot;伤心&quot;]--&gt; goBack(回家)    IsRemaining --&gt;|有|happy[买完炸鸡开心]--&gt; goBack</code></pre><h3 id="序列图-sequence-diagram"><a href="#序列图-sequence-diagram" class="headerlink" title="序列图(sequence diagram)"></a>序列图(sequence diagram)</h3><h4 id="概述-1"><a href="#概述-1" class="headerlink" title="概述"></a>概述</h4><pre><code class="hljs markdown">sequenceDiagram <span class="hljs-code">[参与者1][消息线][参与者2]:消息体</span><span class="hljs-code">    ...</span></code></pre><blockquote><p><code>sequenceDiagram</code> 为每幅时序图的固定开头</p></blockquote><pre><code class="hljs markdown">sequenceDiagram<span class="hljs-code">Title: 买炸鸡</span><span class="hljs-code">    救救-&gt;&gt;炸鸡店小哥: 还有炸鸡吗？</span><span class="hljs-code">    炸鸡店小哥--&gt;&gt;救救: 没有，要现炸</span><span class="hljs-code"></span><span class="hljs-code"></span></code></pre><pre><code class="hljs mermaid">sequenceDiagramTitle: 买炸鸡    救救-&gt;&gt;炸鸡店小哥: 还有炸鸡吗？    炸鸡店小哥--&gt;&gt;救救: 没有，要现炸</code></pre><h4 id="参与者（participant）"><a href="#参与者（participant）" class="headerlink" title="参与者（participant）"></a>参与者（participant）</h4><p>传统时序图概念中参与者有角色和类对象之分，但这里我们不做此区分，用参与者表示一切参与交互的事物，可以是人、类对象、系统等形式。中间竖直的线段从上至下表示时间的流逝。</p><pre><code class="hljs markdown">sequenceDiagram<span class="hljs-code">    participant 参与者 1</span><span class="hljs-code">    participant 参与者 2</span><span class="hljs-code">    ...</span><span class="hljs-code">    participant 简称 as 参与者 3 #该语法可以在接下来的描述中使用简称来代替参与者 3</span></code></pre><blockquote><p><code>participant &lt;参与者名称&gt;</code> 声明参与者，语句次序即为参与者横向排列次序。</p></blockquote><h4 id="消息线"><a href="#消息线" class="headerlink" title="消息线"></a>消息线</h4><table><thead><tr><th align="left">类型</th><th align="left">描述</th></tr></thead><tbody><tr><td align="left">-&gt;</td><td align="left">无箭头的实线</td></tr><tr><td align="left">–&gt;</td><td align="left">无箭头的虚线</td></tr><tr><td align="left">-&gt;&gt;</td><td align="left">有箭头的实线（主动发出消息）</td></tr><tr><td align="left">–-&gt;&gt;</td><td align="left">有箭头的虚线（响应）</td></tr><tr><td align="left">-x</td><td align="left">末端为叉的实线（表示异步）</td></tr><tr><td align="left">–x</td><td align="left">末端为叉的虚线（表示异步）</td></tr></tbody></table><h4 id="处理中-激活框"><a href="#处理中-激活框" class="headerlink" title="处理中-激活框"></a>处理中-激活框</h4><p>从消息接收方的时间线上标记一小段时间，表示对消息进行处理的时间间隔。</p><p>在消息线末尾增加 <code>+</code> ，则消息接收者进入当前消息的“处理中”状态；<br>在消息线末尾增加 <code>-</code> ，则消息接收者离开当前消息的“处理中”状态。</p><pre><code class="hljs markdown">sequenceDiagram<span class="hljs-code">    participant 99 as 救救</span><span class="hljs-code">    participant seller as 炸鸡店小哥</span><span class="hljs-code">    99 -&gt;&gt; seller: 还有炸鸡吗？</span><span class="hljs-code">    seller --&gt;&gt; 99: 没有，要现炸。</span><span class="hljs-code">    99 -x +seller:给我炸！</span><span class="hljs-code">    seller --&gt;&gt; -99: 您的炸鸡好了！</span></code></pre><pre><code class="hljs mermaid">sequenceDiagram    participant 99 as 救救    participant seller as 炸鸡店小哥    99 -&gt;&gt; seller: 还有炸鸡吗？    seller --&gt;&gt; 99: 没有，要现炸。    99 -x +seller:给我炸！    seller --&gt;&gt; -99: 您的炸鸡好了！</code></pre><h4 id="注解（note）"><a href="#注解（note）" class="headerlink" title="注解（note）"></a>注解（note）</h4><p>语法如下</p><pre><code class="hljs markdown">Note 位置表述 参与者: 标注文字</code></pre><p>其中位置表述可以为</p><table><thead><tr><th align="left">表述</th><th align="left">含义</th></tr></thead><tbody><tr><td align="left">right of</td><td align="left">右侧</td></tr><tr><td align="left">left of</td><td align="left">左侧</td></tr><tr><td align="left">over</td><td align="left">在当中，可以横跨多个参与者</td></tr></tbody></table><pre><code class="hljs markdown">sequenceDiagram<span class="hljs-code">    participant 99 as 救救</span><span class="hljs-code">    participant seller as 炸鸡店小哥</span><span class="hljs-code">    Note over 99,seller : 热爱炸鸡</span><span class="hljs-code">    Note left of 99 : 女</span><span class="hljs-code">    Note right of seller : 男</span><span class="hljs-code">    99 -&gt;&gt; seller: 还有炸鸡吗？</span><span class="hljs-code">    seller --&gt;&gt; 99: 没有，要现炸。</span><span class="hljs-code">    99 -x +seller : 给我炸！</span><span class="hljs-code">    seller --&gt;&gt; -99: 您的炸鸡好了！</span><span class="hljs-code"></span><span class="hljs-code"></span></code></pre><pre><code class="hljs mermaid">sequenceDiagram    participant 99 as 救救    participant seller as 炸鸡店小哥    Note over 99,seller : 热爱炸鸡    Note left of 99 : 女    Note right of seller : 男    99 -&gt;&gt; seller: 还有炸鸡吗？    seller --&gt;&gt; 99: 没有，要现炸。    99 -x +seller : 给我炸！    seller --&gt;&gt; -99: 您的炸鸡好了！</code></pre><h4 id="循环（loop）"><a href="#循环（loop）" class="headerlink" title="循环（loop）"></a>循环（loop）</h4><p>在条件满足时，重复发出消息序列。（相当于编程语言中的 while 语句。）</p><pre><code class="hljs markdown">sequenceDiagram<span class="hljs-code">    participant 99 as 救救</span><span class="hljs-code">    participant seller as 炸鸡店小哥</span><span class="hljs-code">   </span><span class="hljs-code">    99 -&gt;&gt; seller: 还有炸鸡吗？</span><span class="hljs-code">    seller --&gt;&gt; 99: 没有，要现炸。</span><span class="hljs-code">    99 -&gt;&gt; +seller:给我炸！</span><span class="hljs-code">    loop 三分钟一次</span><span class="hljs-code">        99 -&gt;&gt; seller : 我的炸鸡好了吗？</span><span class="hljs-code">        seller --&gt;&gt; 99 : 正在炸</span><span class="hljs-code">    end</span><span class="hljs-code">    seller --&gt;&gt; -99: 您的炸鸡好了！</span></code></pre><pre><code class="hljs mermaid">sequenceDiagram    participant 99 as 救救    participant seller as 炸鸡店小哥       99 -&gt;&gt; seller: 还有炸鸡吗？    seller --&gt;&gt; 99: 没有，要现炸。    99 -&gt;&gt; +seller:给我炸！    loop 三分钟一次        99 -&gt;&gt; seller : 我的炸鸡好了吗？        seller --&gt;&gt; 99 : 正在炸    end    seller --&gt;&gt; -99: 您的炸鸡好了！</code></pre><h4 id="选择（alt）"><a href="#选择（alt）" class="headerlink" title="选择（alt）"></a>选择（alt）</h4><p>在多个条件中作出判断，每个条件将对应不同的消息序列。（相当于 if 及 else if 语句。）</p><pre><code class="hljs markdown">sequenceDiagram    <span class="hljs-code">    participant 99 as 救救</span><span class="hljs-code">    participant seller as 炸鸡店小哥</span><span class="hljs-code">    99 -&gt;&gt; seller : 现在就多少只炸好的炸鸡？</span><span class="hljs-code">    seller --&gt;&gt; 99 : 可卖的炸鸡数</span><span class="hljs-code">    </span><span class="hljs-code">    alt 可卖的炸鸡数 &gt; 3</span><span class="hljs-code">        99 -&gt;&gt; seller : 买三只！</span><span class="hljs-code">    else 1 &lt; 可卖的炸鸡数 &lt; 3</span><span class="hljs-code">        99 -&gt;&gt; seller : 有多少买多少</span><span class="hljs-code">    else 可卖的炸鸡数 &lt; 1</span><span class="hljs-code">        99 -&gt;&gt; seller : 那我明天再来</span><span class="hljs-code">    end</span><span class="hljs-code"></span><span class="hljs-code">    seller --&gt;&gt; 99 : 欢迎下次光临</span></code></pre><pre><code class="hljs mermaid">sequenceDiagram        participant 99 as 救救    participant seller as 炸鸡店小哥    99 -&gt;&gt; seller : 现在就多少只炸好的炸鸡？    seller --&gt;&gt; 99 : 可卖的炸鸡数        alt 可卖的炸鸡数 &gt; 3        99 -&gt;&gt; seller : 买三只！    else 1 &lt; 可卖的炸鸡数 &lt; 3        99 -&gt;&gt; seller : 有多少买多少    else 可卖的炸鸡数 &lt; 1        99 -&gt;&gt; seller : 那我明天再来    end    seller --&gt;&gt; 99 : 欢迎下次光临</code></pre><h4 id="可选（opt）"><a href="#可选（opt）" class="headerlink" title="可选（opt）"></a>可选（opt）</h4><p>在某条件满足时执行消息序列，否则不执行。相当于单个分支的 if 语句。</p><pre><code class="hljs markdown">sequenceDiagram<span class="hljs-code">    participant 99 as 救救</span><span class="hljs-code">    participant seller as 炸鸡店小哥</span><span class="hljs-code">    99 -&gt;&gt; seller : 买炸鸡</span><span class="hljs-code">    opt 全都卖完了</span><span class="hljs-code">        seller --&gt;&gt; 99 : 下次再来</span><span class="hljs-code">    end</span></code></pre><pre><code class="hljs mermaid">sequenceDiagram    participant 99 as 救救    participant seller as 炸鸡店小哥    99 -&gt;&gt; seller : 买炸鸡    opt 全都卖完了        seller --&gt;&gt; 99 : 下次再来    end</code></pre><h4 id="并行（Par）"><a href="#并行（Par）" class="headerlink" title="并行（Par）"></a>并行（Par）</h4><p>将消息序列分成多个片段，这些片段并行执行。</p><pre><code class="hljs markdown">sequenceDiagram   participant 99 as 救救   participant seller as 炸鸡店小哥   <span class="hljs-code">    99 -&gt;&gt; seller : 一个炸鸡，一杯可乐！</span><span class="hljs-code"></span><span class="hljs-code">    par 并行执行</span><span class="hljs-code">        seller -&gt;&gt; seller : 装可乐</span><span class="hljs-code">    and</span><span class="hljs-code">        seller -&gt;&gt; seller : 炸炸鸡</span><span class="hljs-code">    end</span><span class="hljs-code"></span><span class="hljs-code">    seller --&gt;&gt; 99 : 您的炸鸡好了！</span></code></pre><pre><code class="hljs mermaid">sequenceDiagram   participant 99 as 救救   participant seller as 炸鸡店小哥       99 -&gt;&gt; seller : 一个炸鸡，一杯可乐！    par 并行执行        seller -&gt;&gt; seller : 装可乐    and        seller -&gt;&gt; seller : 炸炸鸡    end    seller --&gt;&gt; 99 : 您的炸鸡好了！</code></pre><h3 id="饼图（Pie）"><a href="#饼图（Pie）" class="headerlink" title="饼图（Pie）"></a>饼图（Pie）</h3><pre><code class="hljs markdown">pie<span class="hljs-code">    title Pie Chart</span><span class="hljs-code">    &quot;Dogs&quot; : 386</span><span class="hljs-code">    &quot;Cats&quot; : 85</span><span class="hljs-code">    &quot;Rats&quot; : 150 </span></code></pre><pre><code class="hljs mermaid">pie    title Pie Chart    &quot;Dogs&quot; : 386    &quot;Cats&quot; : 85    &quot;Rats&quot; : 150     &quot;panda&quot; : 200</code></pre><blockquote><p><a href="http://support.typora.io/Draw-Diagrams-With-Markdown/">Typora支持mermaid的官方链接</a></p></blockquote><h3 id="甘特图（gantt）"><a href="#甘特图（gantt）" class="headerlink" title="甘特图（gantt）"></a>甘特图（gantt）</h3><pre><code class="hljs markdown"> title 标题dateFormat 日期格式section 部分名任务名:参数一, 参数二, 参数三, 参数四，参数五 //参数一：crit（是否重要，红框框） 或者 不填 //参数二：done（已完成）、active（正在进行） 或者 不填(表示为待完成状态) //参数三：取小名 或者 不填 //参数四：任务开始时间 //参数五：任务结束时间</code></pre><blockquote><p><a href="https://mermaid-js.github.io/mermaid/#/gantt">官方教程</a></p></blockquote><pre><code class="hljs routeros">gantt       dateFormat  YYYY-MM-DD       title Adding GANTT diagram functionality <span class="hljs-keyword">to</span> mermaid       section A section       Completed task            :done,    des1, 2014-01-06,2014-01-08       Active task               :active,  des2, 2014-01-09, 3d       Future task               :         des3, after des2, 5d       Future task2              :         des4, after des3, 5d       section Critical tasks       Completed task <span class="hljs-keyword">in</span> the critical line :crit, done, 2014-01-06,24h       Implement parser <span class="hljs-keyword">and</span> jison          :crit, done, after des1, 2d       Create tests <span class="hljs-keyword">for</span> parser             :crit, active, 3d       Future task <span class="hljs-keyword">in</span> critical line        :crit, 5d       Create tests <span class="hljs-keyword">for</span> renderer           :2d       <span class="hljs-builtin-name">Add</span> <span class="hljs-keyword">to</span> mermaid                      :1d       section Documentation       Describe gantt syntax               :active, a1, after des1, 3d       <span class="hljs-builtin-name">Add</span> gantt diagram <span class="hljs-keyword">to</span> demo<span class="hljs-built_in"> page </span>     :after a1  , 20h       <span class="hljs-builtin-name">Add</span> another diagram <span class="hljs-keyword">to</span> demo<span class="hljs-built_in"> page </span>   :doc1, after a1  , 48h       section Last section       Describe gantt syntax               :after doc1, 3d       <span class="hljs-builtin-name">Add</span> gantt diagram <span class="hljs-keyword">to</span> demo<span class="hljs-built_in"> page </span>     :20h       <span class="hljs-builtin-name">Add</span> another diagram <span class="hljs-keyword">to</span> demo<span class="hljs-built_in"> page </span>   :48h</code></pre><pre><code class="hljs mermaid">gantt       dateFormat  YYYY-MM-DD       title Adding GANTT diagram functionality to mermaid       section A section       Completed task            :done,    des1, 2014-01-06,2014-01-08       Active task               :active,  des2, 2014-01-09, 3d       Future task               :         des3, after des2, 5d       Future task2              :         des4, after des3, 5d       section Critical tasks       Completed task in the critical line :crit, done, 2014-01-06,24h       Implement parser and jison          :crit, done, after des1, 2d       Create tests for parser             :crit, active, 3d       Future task in critical line        :crit, 5d       Create tests for renderer           :2d       Add to mermaid                      :1d       section Documentation       Describe gantt syntax               :active, a1, after des1, 3d       Add gantt diagram to demo page      :after a1  , 20h       Add another diagram to demo page    :doc1, after a1  , 48h       section Last section       Describe gantt syntax               :after doc1, 3d       Add gantt diagram to demo page      :20h       Add another diagram to demo page    :48h</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>markdown</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>新虚拟机、服务器搭建、常用命令</title>
    <link href="/2020/11/22/linux01/"/>
    <url>/2020/11/22/linux01/</url>
    
    <content type="html"><![CDATA[<h1 id="新创建虚拟机准备工作"><a href="#新创建虚拟机准备工作" class="headerlink" title="新创建虚拟机准备工作"></a>新创建虚拟机准备工作</h1><h2 id="创建用户目录"><a href="#创建用户目录" class="headerlink" title="创建用户目录"></a>创建用户目录</h2><pre><code class="hljs shell">[hadoop@JD ~]$ mkdir app software sourcecode log tmp data lib[hadoop@JD ~]$ lltotal 0drwxrwxr-x 2 ks ks 6 Nov 27 21:33 app #解压的文件 软连接drwxrwxr-x 2 ks ks 6 Nov 27 21:33 data #数据drwxrwxr-x 2 ks ks 6 Nov 27 21:33 lib #第三方jardrwxrwxr-x 2 ks ks 6 Nov 27 21:33 log #日志文件夹drwxrwxr-x 2 ks ks 6 Nov 27 21:33 software #压缩包drwxrwxr-x 2 ks ks 6 Nov 27 21:33 sourcecode #源代码drwxrwxr-x 2 ks ks 6 Nov 27 21:33 tmp #临时文件夹？？lunix本身自带tmp目录，为什么要自己创建目录呢？？生产上的大坑。</code></pre><h2 id="卸载自带的openjdk"><a href="#卸载自带的openjdk" class="headerlink" title="卸载自带的openjdk"></a>卸载自带的openjdk</h2><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">查看java版本</span>[root@hadoop001 software]# java -versionjava version &quot;1.7.0_51&quot;OpenJDK Runtime Environment (rhel-2.4.5.5.el7-x86_64 u51-b31)OpenJDK 64-Bit Server VM (build 24.51-b03, mixed mode)<span class="hljs-meta">#</span><span class="bash">查看rpm安装的java包</span>[root@hadoop001 software]# rpm -qa|grep javapython-javapackages-3.4.1-5.el7.noarchjavapackages-tools-3.4.1-5.el7.noarchjava-1.7.0-openjdk-headless-1.7.0.51-2.4.5.5.el7.x86_64tzdata-java-2014b-1.el7.noarchjava-1.7.0-openjdk-1.7.0.51-2.4.5.5.el7.x86_64<span class="hljs-meta">#</span><span class="bash">卸载java，注意：.noarch</span>[root@hadoop001 software]# rpm -e --nodeps java-1.7.0-openjdk-headless-1.7.0.51-2.4.5.5.el7.x86_64</code></pre><h2 id="centos下载地址"><a href="#centos下载地址" class="headerlink" title="centos下载地址"></a>centos下载地址</h2><p>&lt;<a href="https://man.linuxde.net/download/CentOS/">CentOS下载，CentOS系统下载_Linux下载 (linuxde.net)</a>&gt;</p><h2 id="查看本机ip地址"><a href="#查看本机ip地址" class="headerlink" title="查看本机ip地址"></a>查看本机ip地址</h2><pre><code class="hljs shell">ifconfig</code></pre><h2 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h2><pre><code class="hljs shell">systemctl stop firewalldsystemctl disable firewalld<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#不是root用户+sudo</span></span></code></pre><h2 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h2><p>修改两个地方</p><ul><li>添加当前ip 主机名</li></ul><pre><code class="hljs shell">vim /etc/hosts</code></pre><ul><li>添加主机名</li></ul><pre><code class="hljs shell">vim /etc/hostname</code></pre><h2 id="添加用户名用户组"><a href="#添加用户名用户组" class="headerlink" title="添加用户名用户组"></a>添加用户名用户组</h2><pre><code class="hljs shell">[root@JD ~]# useradd rain[root@JD ~]# id rainuid=1001(rain) gid=1001(rain) 组=1001(rain)拓展useradd -g testgroup testuser-g 所属组-d 家目录-s 所用的shell 用户和组都是raingroupadd hadoop</code></pre><h2 id="赋予用户组权限"><a href="#赋予用户组权限" class="headerlink" title="赋予用户组权限"></a>赋予用户组权限</h2><p>三种方式，推荐第一种方式</p><pre><code class="hljs shell">vim /etc/passwdrain:x:1001:1001::/home/rain:/bin/bash<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#把id修改成0</span></span></code></pre><pre><code class="hljs shell">vim /etc/suduoers<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#Allows people in group wheel to run all commands</span></span><span class="hljs-meta">%</span><span class="bash">wheel  ALL=(ALL)  ALL</span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#把前面的注释去掉</span></span></code></pre><pre><code class="hljs shell">vim /etc/sudoers<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment"># Allow root to run any commands anywhere</span></span>root  ALL=(ALL)   ALL<span class="hljs-meta">%</span><span class="bash">hadoop  ALL=(ALL)   ALL</span><span class="hljs-meta">#</span><span class="bash">root下添加一行.注意这里%hadoop代表的意思</span></code></pre><pre><code class="hljs shell">xxx is not in the sudoers file.  This incident will be reported解决方法:编辑sudoers文件有两种办法，一种是以root帐号执行visudo，另一种是root帐号执行vi /etc/sudoers.其实两者都是修改/etc/sudoers。 假设你的用户名是“superman”，属于“supergroup”用户组。为了让用户superman能够执行sudo命，你可以在sudoers文件中加上一下四行的任意一行。    superman            ALL=（ALL）                ALL     %supergroup            ALL=（ALL）                ALL    superman               ALL=（ALL）                 NOPASSWD：ALL(出于方便，推荐使用此设置)     %supergroup            ALL=（ALL）                NOPASSWD：ALL解释说明：第一行：允许用户superman执行sudo命令（需要输入密码）。 第二行：允许用户组supergroup里面的用户执行sudo命令（需要输入密码）。第三行：允许用户superman执行sudo命令，并且在执行的时候不输入密码。第四行：允许用户组supergroup里面的用户执行sudo命令，并且在执行的时候不输入密码。 当然如果你理解上面的原理后，可以直接输入如下命令解决此问题su -echo &#x27;xxx ALL=(ALL) ALL&#x27; &gt;&gt; /etc/sudoers  (其中xxx代表用户名)</code></pre><pre><code class="hljs shell">chmod g+r path/file 加读权限 当前目录chmod -R g+r path/file 加读权限 当前目录以及子目录<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#g-r 减读权限</span></span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#g+w 加写权限</span></span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#g-w</span></span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#g+x 加执行权限</span></span><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#g-x</span></span></code></pre><h2 id="查看用户名和用户组"><a href="#查看用户名和用户组" class="headerlink" title="查看用户名和用户组"></a>查看用户名和用户组</h2><pre><code class="hljs shell">cat /etc/passwdcat /etc/group</code></pre><h2 id="永久性删除用户账号"><a href="#永久性删除用户账号" class="headerlink" title="永久性删除用户账号"></a>永久性删除用户账号</h2><p>没有测试过</p><pre><code class="hljs shell">userdel testuser  groupdel testgroup  usermod –G testgroup testuser</code></pre><h2 id="权限问题"><a href="#权限问题" class="headerlink" title="权限问题"></a>权限问题</h2><ul><li>权限问题经常出现</li></ul><pre><code class="hljs shell">错误：Permission denied</code></pre><ul><li>解决</li></ul><pre><code class="hljs shell">chmod -R 777 文件夹/文件路径chown -R 用户：用户组 文件夹/文件路径</code></pre><h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><p>查看文件大小</p><pre><code class="hljs shell">du -sh xxx.log</code></pre><p>模糊搜索</p><pre><code class="hljs shell">find / -name &#x27;*hadoop*&#x27;</code></pre><p>内存大小</p><pre><code class="hljs shell">top</code></pre><pre><code class="hljs shell">free -m</code></pre><p>系统状态</p><pre><code class="hljs shell">ps -ef</code></pre><p>历史记录</p><pre><code class="hljs shell">history</code></pre><h1 id="ERROR如何定位"><a href="#ERROR如何定位" class="headerlink" title="ERROR如何定位"></a>ERROR如何定位</h1><pre><code class="hljs routeros">a.文件内容小，下载到windows，工具打开搜索ERRORb.文件内容大</code></pre><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#ERROR前10行</span></span>cat xxx.log|grep -A 10 ERROR<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#ERROR后10行 </span></span>cat xxx.log|grep -B 10 ERROR<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#ERROR前后各10行（***）</span></span>cat xxx.log|grep -C 10 ERROR</code></pre><h1 id="实时查看文件"><a href="#实时查看文件" class="headerlink" title="实时查看文件"></a>实时查看文件</h1><pre><code class="hljs shell">tail -f ks.logtail -F ks.log<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#-F = -f + retry,在生产上flume也要用-F</span></span></code></pre><h1 id="环境变量"><a href="#环境变量" class="headerlink" title="环境变量"></a>环境变量</h1><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#全局</span></span>vim /etc/profile<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#个人，优先bashrc，远程ssh去连接时，bashrc自动加载生效</span></span>vim ~/.bash_profilevim ~/.bashrc<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#记得生效</span></span>source xxx</code></pre><h1 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h1><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">删除会提示</span>rm xxx.log<span class="hljs-meta">#</span><span class="bash">直接删除</span>rm -r xxx.log<span class="hljs-meta">#</span><span class="bash">直接删除文件夹</span>rm -rf xxx<span class="hljs-meta">#</span><span class="bash"><span class="hljs-comment">#静止使用</span></span>rm -rf /跑路</code></pre><h1 id="注意可能会出现如下情况"><a href="#注意可能会出现如下情况" class="headerlink" title="注意可能会出现如下情况"></a>注意可能会出现如下情况</h1><pre><code class="hljs shell">vim /etc/passwd</code></pre><h2 id="无法切换到此用户"><a href="#无法切换到此用户" class="headerlink" title="无法切换到此用户"></a>无法切换到此用户</h2><pre><code class="hljs shell">rain:x:1002:1001::/home/rain:/sbin/nologinrain:x:1002:1001::/home/rain:/bin/false</code></pre><h2 id="可以切换到此用户"><a href="#可以切换到此用户" class="headerlink" title="可以切换到此用户"></a>可以切换到此用户</h2><pre><code class="hljs shell">rain:x:1002:1001::/home/rain:/bin/bash<span class="hljs-meta">#</span><span class="bash">若切换不过去，改为/bin/bash</span></code></pre><h1 id="关于文件的权限"><a href="#关于文件的权限" class="headerlink" title="关于文件的权限"></a>关于文件的权限</h1><pre><code class="hljs yaml"><span class="hljs-string">第一个字母：d文件夹</span> <span class="hljs-string">-文件</span> <span class="hljs-string">l连接</span><span class="hljs-string">r：读</span> <span class="hljs-number">4</span><span class="hljs-string">w：写</span> <span class="hljs-number">2</span><span class="hljs-string">x：执行</span> <span class="hljs-number">1</span><span class="hljs-string">rwx：第一组：代表文件或者文件夹的用户</span><span class="hljs-string">rwx：第二组：代表文件或文件夹的用户组</span><span class="hljs-string">r-x：第三组：代表其他组的所属用户</span><span class="hljs-string">chmod</span> <span class="hljs-number">777</span> <span class="hljs-comment">#任意用户用户组 读写执行 权限</span></code></pre><h1 id="swp文件"><a href="#swp文件" class="headerlink" title="swp文件"></a>swp文件</h1><pre><code class="hljs shell">编辑失败会产生swp文件，删除后再编辑</code></pre><h1 id="清空文件内容"><a href="#清空文件内容" class="headerlink" title="清空文件内容"></a>清空文件内容</h1><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">完美</span>cat /dev/null &gt; xxx.log<span class="hljs-meta">#</span><span class="bash">不建议</span>echo &#x27;&#x27; &gt; xxx.log<span class="hljs-meta">#</span><span class="bash">vim模式</span>gg+dG</code></pre><h1 id="vim模式"><a href="#vim模式" class="headerlink" title="vim模式"></a>vim模式</h1><h2 id="命令行常见的快捷键"><a href="#命令行常见的快捷键" class="headerlink" title="命令行常见的快捷键"></a>命令行常见的快捷键</h2><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">删除当前行</span>dd<span class="hljs-meta">#</span><span class="bash">删除光标一下的所有行</span>dG<span class="hljs-meta">#</span><span class="bash">删除光标一下的n行</span>ndd<span class="hljs-meta">#</span><span class="bash">跳转第一行的第一个字母</span>gg<span class="hljs-meta">#</span><span class="bash">跳转到最后一行的第一个字母</span>G<span class="hljs-meta">#</span><span class="bash">跳转到行尾</span>shift+$</code></pre><h1 id="系统命令（硬盘，内存，负载）"><a href="#系统命令（硬盘，内存，负载）" class="headerlink" title="系统命令（硬盘，内存，负载）"></a>系统命令（硬盘，内存，负载）</h1><h2 id="查看硬盘"><a href="#查看硬盘" class="headerlink" title="查看硬盘"></a>查看硬盘</h2><pre><code class="hljs shell">df -h文件系统        容量  已用  可用 已用% 挂载点/dev/vda1        40G  6.5G   34G   17% //dev/vdb1        40G  6.5G   34G   data01数据盘 //dev/vdb2        40G  6.5G   34G   data02数据盘 //dev/vdb3        40G  6.5G   34G   data03数据盘 //dev/vdb4        40G  6.5G   34G   data04数据盘 /devtmpfs        7.8G     0  7.8G    0% /devtmpfs           7.8G   16K  7.8G    1% /dev/shmtmpfs           7.8G   26M  7.8G    1% /runtmpfs           7.8G     0  7.8G    0% /sys/fs/cgrouptmpfs           1.6G     0  1.6G    0% /run/user/</code></pre><h2 id="查看内存"><a href="#查看内存" class="headerlink" title="查看内存"></a>查看内存</h2><pre><code class="hljs shell">free -gfree -m</code></pre><pre><code class="hljs shell">              total        used        free      shared  buff/cache   availableMem:             15           3          11           0           0          11Swap:             0           0           0</code></pre><h1 id="查看系统负载"><a href="#查看系统负载" class="headerlink" title="查看系统负载"></a>查看系统负载</h1><pre><code class="hljs livecodeserver">uptime<span class="hljs-built_in">load</span> <span class="hljs-built_in">average</span>：<span class="hljs-number">0.00</span>, <span class="hljs-number">0.01</span>, <span class="hljs-number">0.05</span>              <span class="hljs-number">1</span><span class="hljs-built_in">min</span>  <span class="hljs-number">5</span><span class="hljs-built_in">min</span>  <span class="hljs-number">15</span><span class="hljs-built_in">min</span>              这三个值不要超过<span class="hljs-number">10</span>，否则认为此物理服务器有问题如果有个别进程很高，去<span class="hljs-keyword">command</span>查看下命令看看它时做什么的然后去看它的<span class="hljs-built_in">load</span> <span class="hljs-built_in">average</span>：都是<span class="hljs-number">100</span> ，那么就有问题了，服务夯住了，代码级别，硬件级别（内存条坏了），最后一招万能的重启（硬件问题起不来）</code></pre><pre><code class="hljs angelscript">toptop - <span class="hljs-number">16</span>:<span class="hljs-number">44</span>:<span class="hljs-number">02</span> up <span class="hljs-number">4</span> days, <span class="hljs-number">19</span>:<span class="hljs-number">01</span>,  <span class="hljs-number">1</span> user,  load average: <span class="hljs-number">0.00</span>, <span class="hljs-number">0.01</span>, <span class="hljs-number">0.05</span>Tasks: <span class="hljs-number">116</span> total,   <span class="hljs-number">1</span> running, <span class="hljs-number">115</span> sleeping,   <span class="hljs-number">0</span> stopped,   <span class="hljs-number">0</span> zombie%Cpu(s):  <span class="hljs-number">0.2</span> us,  <span class="hljs-number">0.2</span> sy,  <span class="hljs-number">0.0</span> ni, <span class="hljs-number">99.7</span> id,  <span class="hljs-number">0.0</span> wa,  <span class="hljs-number">0.0</span> hi,  <span class="hljs-number">0.0</span> si,  <span class="hljs-number">0.0</span> stKiB Mem : <span class="hljs-number">16268348</span> total, <span class="hljs-number">11779256</span> free,  <span class="hljs-number">3524652</span> used,   <span class="hljs-number">964440</span> buff/cacheKiB Swap:        <span class="hljs-number">0</span> total,        <span class="hljs-number">0</span> free,        <span class="hljs-number">0</span> used. <span class="hljs-number">12484732</span> avail Mem  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND <span class="hljs-number">1164</span> root      <span class="hljs-number">20</span>   <span class="hljs-number">0</span>  <span class="hljs-number">585292</span>  <span class="hljs-number">30780</span>   <span class="hljs-number">8488</span> S   <span class="hljs-number">0.3</span>  <span class="hljs-number">0.2</span>  <span class="hljs-number">18</span>:<span class="hljs-number">03.34</span> jdog-kunlu+ <span class="hljs-number">1561</span> root      <span class="hljs-number">20</span>   <span class="hljs-number">0</span>  <span class="hljs-number">921640</span>  <span class="hljs-number">18672</span>   <span class="hljs-number">6204</span> S   <span class="hljs-number">0.3</span>  <span class="hljs-number">0.1</span>  <span class="hljs-number">27</span>:<span class="hljs-number">34.59</span> MonitorPlu+<span class="hljs-number">20073</span> hadoop    <span class="hljs-number">20</span>   <span class="hljs-number">0</span>  <span class="hljs-number">161952</span>   <span class="hljs-number">2212</span>   <span class="hljs-number">1560</span> R   <span class="hljs-number">0.3</span>  <span class="hljs-number">0.0</span>   <span class="hljs-number">0</span>:<span class="hljs-number">00.03</span> top<span class="hljs-number">21481</span> hadoop    <span class="hljs-number">20</span>   <span class="hljs-number">0</span> <span class="hljs-number">3018228</span> <span class="hljs-number">488508</span>  <span class="hljs-number">19396</span> S   <span class="hljs-number">0.3</span>  <span class="hljs-number">3.0</span>   <span class="hljs-number">5</span>:<span class="hljs-number">05.84</span> java<span class="hljs-number">21655</span> hadoop    <span class="hljs-number">20</span>   <span class="hljs-number">0</span> <span class="hljs-number">2868732</span> <span class="hljs-number">321296</span>  <span class="hljs-number">19332</span> S   <span class="hljs-number">0.3</span>  <span class="hljs-number">2.0</span>   <span class="hljs-number">2</span>:<span class="hljs-number">34.08</span> java    <span class="hljs-number">1</span> root      <span class="hljs-number">20</span>   <span class="hljs-number">0</span>  <span class="hljs-number">191104</span>   <span class="hljs-number">3940</span>   <span class="hljs-number">2508</span> S   <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span>   <span class="hljs-number">0</span>:<span class="hljs-number">50.59</span> systemd    <span class="hljs-number">2</span> root      <span class="hljs-number">20</span>   <span class="hljs-number">0</span>       <span class="hljs-number">0</span>      <span class="hljs-number">0</span>      <span class="hljs-number">0</span> S   <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span>   <span class="hljs-number">0</span>:<span class="hljs-number">00.00</span> kthreadd    <span class="hljs-number">3</span> root      <span class="hljs-number">20</span>   <span class="hljs-number">0</span>       <span class="hljs-number">0</span>      <span class="hljs-number">0</span>      <span class="hljs-number">0</span> S   <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span>   <span class="hljs-number">0</span>:<span class="hljs-number">00.07</span> ksoftirqd/<span class="hljs-number">0</span>    <span class="hljs-number">5</span> root       <span class="hljs-number">0</span> <span class="hljs-number">-20</span>       <span class="hljs-number">0</span>      <span class="hljs-number">0</span>      <span class="hljs-number">0</span> S   <span class="hljs-number">0.0</span>  <span class="hljs-number">0.0</span>   <span class="hljs-number">0</span>:<span class="hljs-number">00.00</span> kworker/<span class="hljs-number">0</span>:+</code></pre><h1 id="查看进程"><a href="#查看进程" class="headerlink" title="查看进程"></a>查看进程</h1><h2 id="不过滤"><a href="#不过滤" class="headerlink" title="不过滤"></a>不过滤</h2><pre><code class="hljs shell">ps -ef|grep ssh[hadoop@JD ~]$ ps -ef|grep sshroot       772     1  0 6月25 ?       00:00:01 /usr/sbin/sshd -Droot     16280   772  0 16:14 ?        00:00:00 sshd: hadoop [priv]hadoop   16282 16280  0 16:14 ?        00:00:00 sshd: hadoop@pts/0hadoop   22006 16283  0 16:55 pts/0    00:00:00 grep --color=auto ssh</code></pre><h2 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h2><pre><code class="hljs shell">[hadoop@JD ~]$ ps -ef|grep ssh|grep -v greproot       772     1  0 6月25 ?       00:00:01 /usr/sbin/sshd -Droot     16280   772  0 16:14 ?        00:00:00 sshd: hadoop [priv]hadoop   16282 16280  0 16:14 ?        00:00:00 sshd: hadoop@pts/0</code></pre><h1 id="进程端口号"><a href="#进程端口号" class="headerlink" title="进程端口号"></a>进程端口号</h1><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">先找pid，再通过pid找port</span>netstat -nlp｜grep 772netstat -nlp｜grep ssh</code></pre><h1 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h1><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">centos6.x 7.x</span>service httpd start<span class="hljs-meta">#</span><span class="bash">centos7.x</span>systemctl start httpd xxx xxx xxx</code></pre><h2 id="connect-refused"><a href="#connect-refused" class="headerlink" title="connect refused"></a>connect refused</h2><pre><code class="hljs shell">ping iptelnet ip port</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>jvm虚拟机探究</title>
    <link href="/2020/11/19/jvm01/"/>
    <url>/2020/11/19/jvm01/</url>
    
    <content type="html"><![CDATA[<h1 id="为什么学习jvm虚拟机"><a href="#为什么学习jvm虚拟机" class="headerlink" title="为什么学习jvm虚拟机"></a>为什么学习jvm虚拟机</h1><ul><li>生产上运行spark的时候时常出现GC OVERHEAD等报错</li><li>作为对于java语言底层（深层）的了解</li></ul><h1 id="JVM探究"><a href="#JVM探究" class="headerlink" title="JVM探究"></a>JVM探究</h1><ul><li><p>谈谈你对jvm的理解？java8虚拟机和之前的变换更新？</p></li><li><p>什么是oom？什么是栈溢出StackOverFlowError？怎么分析？</p></li><li><p>JVM常用调优参数？</p></li><li><p>内存快照如何抓取，怎么分析Dump文件？</p></li><li><p>谈谈JVM中类加载器你的认识？</p><p>jvm中类加载器 rt-jar、ext(扩展jar包)、用户的application</p></li></ul><h2 id="了解"><a href="#了解" class="headerlink" title="了解"></a>了解</h2><ul><li>jvm的位置</li><li>jvm体系结构</li><li>类加载器</li><li>双亲委派机制</li><li>沙箱安全机制</li><li>Native</li><li>PC寄存器、方法区、栈、堆</li><li>三种JVM</li><li>新生代、老年区、永久区</li><li>堆内存调优</li><li>GC 常用算法</li><li>JMM</li><li>总结</li></ul><h3 id="学习方案"><a href="#学习方案" class="headerlink" title="学习方案"></a>学习方案</h3><ul><li>百度</li><li>思维导图 - 在线思维导图去搜索</li></ul><p><img src="images/image-20201119013059487.png" alt="image-20201119013059487"></p><h4 id="1-类加载器"><a href="#1-类加载器" class="headerlink" title="1. 类加载器"></a>1. 类加载器</h4><ul><li>作用：加载class文件</li></ul><p><img src="/2020/11/19/jvm01/hexo\kskuangshaoblog\source_posts\images\image-20201117010051266.png" alt="image-20201117010051266"></p><ol><li>虚拟机自带加载器</li><li>启动类加载器</li><li>扩展类加载器</li><li>应用类加载器</li></ol>]]></content>
    
    
    
    <tags>
      
      <tag>jvm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>生产关于hive，sparksql的问题总结</title>
    <link href="/2020/11/19/hive02/"/>
    <url>/2020/11/19/hive02/</url>
    
    <content type="html"><![CDATA[<h1 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h1><h2 id="DDL数据库定义语言"><a href="#DDL数据库定义语言" class="headerlink" title="DDL数据库定义语言"></a>DDL数据库定义语言</h2><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span>、<span class="hljs-keyword">ALTER</span>、<span class="hljs-keyword">DROP</span>、<span class="hljs-keyword">TRUNCATE</span>、<span class="hljs-keyword">COMMENT</span>、<span class="hljs-keyword">RENAME</span></code></pre><h2 id="DML数据操纵语言"><a href="#DML数据操纵语言" class="headerlink" title="DML数据操纵语言"></a>DML数据操纵语言</h2><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span>、<span class="hljs-keyword">INSERT</span>、<span class="hljs-keyword">UPDATE</span>、<span class="hljs-keyword">DELETE</span>、<span class="hljs-keyword">MERGE</span>、<span class="hljs-keyword">CALL</span>、<span class="hljs-keyword">EXPLAIN</span> PLAN<span class="hljs-keyword">LOCK</span> <span class="hljs-keyword">TABLE</span></code></pre><h2 id="DCL数据库控制语言"><a href="#DCL数据库控制语言" class="headerlink" title="DCL数据库控制语言"></a>DCL数据库控制语言</h2><pre><code class="hljs sql"><span class="hljs-keyword">GRANT</span>、<span class="hljs-keyword">REVOKE</span></code></pre><h2 id="TCL事务控制语言"><a href="#TCL事务控制语言" class="headerlink" title="TCL事务控制语言"></a>TCL事务控制语言</h2><pre><code class="hljs sql"><span class="hljs-keyword">SAVEPOINT</span>设置保存点、<span class="hljs-keyword">ROLLBACK</span>回滚、<span class="hljs-keyword">SET</span> TRANSCATION</code></pre><h1 id="DDL"><a href="#DDL" class="headerlink" title="DDL"></a>DDL</h1><h2 id="组合分隔符的解决方案"><a href="#组合分隔符的解决方案" class="headerlink" title="组合分隔符的解决方案"></a>组合分隔符的解决方案</h2><ul><li>建表</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> test0001(<span class="hljs-keyword">id</span> <span class="hljs-keyword">string</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">string</span>) <span class="hljs-keyword">ROW</span> <span class="hljs-keyword">FORMAT</span> SERDE <span class="hljs-string">&#x27;org.apache.hadoop.hive.contrib.serde2.MultiDelimitSerDe&#x27;</span> <span class="hljs-keyword">WITH</span> SERDEPROPERTIES (<span class="hljs-string">&quot;field.delim&quot;</span>=<span class="hljs-string">&quot;\&quot;</span>\;\&quot;&quot;);</code></pre><ul><li>添加jar包</li></ul><pre><code class="hljs sql">add jar /usr/local/hive/lib/hive-contrib-1.2.0.jar;</code></pre><ul><li>插入数据</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> test0001 <span class="hljs-keyword">values</span>(<span class="hljs-string">&#x27;1&#x27;</span>,<span class="hljs-string">&#x27;ks&#x27;</span>);</code></pre><ul><li>查询结果</li></ul><pre><code class="hljs shell">1&quot;;&quot;ks</code></pre><h2 id="多表关联查询建表"><a href="#多表关联查询建表" class="headerlink" title="多表关联查询建表"></a>多表关联查询建表</h2><ul><li>方式一（不推荐）</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> Test7<span class="hljs-keyword">as</span> <span class="hljs-keyword">with</span> a <span class="hljs-keyword">as</span> (<span class="hljs-keyword">select</span> <span class="hljs-keyword">id</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">from</span> player),b <span class="hljs-keyword">as</span> (<span class="hljs-keyword">select</span> <span class="hljs-keyword">name</span>,<span class="hljs-keyword">position</span> <span class="hljs-keyword">from</span> <span class="hljs-keyword">position</span>)<span class="hljs-keyword">select</span> a.id,b.name <span class="hljs-keyword">from</span> a,b <span class="hljs-keyword">where</span> a.name=b.name;</code></pre><ul><li>方拾二（推荐）</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> Test8<span class="hljs-keyword">as</span> <span class="hljs-keyword">with</span>a <span class="hljs-keyword">as</span> (<span class="hljs-keyword">select</span> <span class="hljs-keyword">id</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">from</span> player),b <span class="hljs-keyword">as</span> (<span class="hljs-keyword">select</span> <span class="hljs-keyword">name</span>,<span class="hljs-keyword">position</span> <span class="hljs-keyword">from</span> player)<span class="hljs-keyword">select</span> a.id,b.name,b.position <span class="hljs-keyword">from</span> a<span class="hljs-keyword">left</span> <span class="hljs-keyword">join</span> b <span class="hljs-keyword">where</span> a.name=b.name;</code></pre><h3 id="spark-sql-查询建表报错"><a href="#spark-sql-查询建表报错" class="headerlink" title="spark-sql 查询建表报错"></a>spark-sql 查询建表报错</h3><pre><code class="hljs pgsql">Caused <span class="hljs-keyword">by</span>: org.apache.spark.<span class="hljs-keyword">sql</span>.catalyst.<span class="hljs-keyword">parser</span>.ParseException: Datatype <span class="hljs-type">void</span> <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> supported原因：Spark不支持Hive表中的<span class="hljs-type">void</span>字段类型，代码中临时<span class="hljs-keyword">create</span>的Hive表中，如果<span class="hljs-keyword">from</span>的源表中某字段为全空值，则<span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span>时该临时表的这个字段类型就会变成<span class="hljs-type">void</span>。</code></pre><pre><code class="hljs angelscript">解决方法：如果是上面这种情况，可以用Hive跑任务或者修改该Hive表的字段类型不为<span class="hljs-built_in">void</span>，或将<span class="hljs-literal">null</span>转换为<span class="hljs-built_in">string</span>等。</code></pre><h1 id="DML"><a href="#DML" class="headerlink" title="DML"></a>DML</h1><h2 id="输入数据并动态分区"><a href="#输入数据并动态分区" class="headerlink" title="输入数据并动态分区"></a>输入数据并动态分区</h2><pre><code class="hljs sql"><span class="hljs-comment">--案例：比方说一个订单表，按照品牌（pt_brand_x）分区</span><span class="hljs-keyword">insert</span> overwrite <span class="hljs-keyword">table</span> app.sbl_order <span class="hljs-keyword">partition</span>(pt_brand_x) <span class="hljs-comment">--动态分区</span><span class="hljs-keyword">select</span> order_id,       order_price,       pt_biz_date,       pt_brand_x <span class="hljs-comment">--动态分区字段放最后</span><span class="hljs-keyword">from</span> <span class="hljs-keyword">order</span>;</code></pre><h2 id="常用的函数"><a href="#常用的函数" class="headerlink" title="常用的函数"></a>常用的函数</h2><pre><code class="hljs sql"><span class="hljs-keyword">SELECT</span> pt_brand_x     <span class="hljs-keyword">AS</span> pt_brand_x, integration_id <span class="hljs-keyword">AS</span> integration_id, position_name  <span class="hljs-keyword">AS</span> position_name, row_wid        <span class="hljs-keyword">AS</span> row_wid, emp_last_name  <span class="hljs-keyword">AS</span> emp_last_name, <span class="hljs-keyword">CASE</span> <span class="hljs-comment">--position_name 长度小于10</span> <span class="hljs-keyword">WHEN</span> <span class="hljs-keyword">length</span>(position_name) &lt; <span class="hljs-number">10</span> <span class="hljs-keyword">THEN</span> position_name <span class="hljs-comment">--instr函数代替了like方式，返回字符串在字段中的位置，没有为0 </span> <span class="hljs-comment">--神经病，精神病，病 ,查 神 返回1 2 0 </span> <span class="hljs-comment">--也可以放到where里&gt;0查看字段里是否存在这个字</span> <span class="hljs-keyword">WHEN</span> <span class="hljs-keyword">instr</span>(<span class="hljs-keyword">upper</span>(position_name), <span class="hljs-string">&#x27;LANCOME&#x27;</span>) &gt; <span class="hljs-number">0</span> <span class="hljs-keyword">THEN</span> position_name <span class="hljs-keyword">WHEN</span> position_name = <span class="hljs-string">&#x27;LAN_CN_Position&#x27;</span> <span class="hljs-keyword">THEN</span> position_name <span class="hljs-comment">--从第4个位置开始保留到最后</span> <span class="hljs-keyword">ELSE</span> <span class="hljs-keyword">substr</span>(position_name, <span class="hljs-number">4</span>) <span class="hljs-keyword">END</span>        <span class="hljs-keyword">AS</span> new_ba_code<span class="hljs-keyword">FROM</span> dws.mirror_dim_sbl_w_position_d<span class="hljs-keyword">WHERE</span> <span class="hljs-number">1</span> = <span class="hljs-number">1</span>;</code></pre><h1 id="sparksql问题"><a href="#sparksql问题" class="headerlink" title="sparksql问题"></a>sparksql问题</h1><h2 id="GC-overhead"><a href="#GC-overhead" class="headerlink" title="GC overhead"></a>GC overhead</h2><h3 id="原因"><a href="#原因" class="headerlink" title="原因"></a>原因</h3><pre><code class="hljs"><span class="hljs-attribute">java.lang.OutOfMemoryError</span>: GC overhead limit exceeded 这种情况发生的原因是, 程序基本上耗尽了所有的可用内存, GC也清理不了。JVM抛出 java.lang.OutOfMemoryError: GC overhead limit exceeded 错误就是发出了这样的信号: 执行垃圾收集的时间比例太大, 有效的运算量太小. 默认情况下, 如果GC花费的时间超过 98%, 并且GC回收的内存少于 2%, JVM就会抛出这个错误。</code></pre><h2 id="解决方式"><a href="#解决方式" class="headerlink" title="解决方式"></a>解决方式</h2><h4 id="创建分区表，限制分区插入"><a href="#创建分区表，限制分区插入" class="headerlink" title="创建分区表，限制分区插入"></a>创建分区表，限制分区插入</h4><pre><code class="hljs powershell">关于数据量大插入慢的问题：可以使用分区表，按照品牌分区，如果一次吧所有品牌插入出现<span class="hljs-built_in">GC</span> overhead，其他报错等问题，可以通过限制品牌分批插入。</code></pre><h4 id="发生到executor之后"><a href="#发生到executor之后" class="headerlink" title="发生到executor之后"></a>发生到executor之后</h4><ul><li>参数</li></ul><pre><code class="hljs shell">spark-sql \--master yarn \--deploy-mode client \--executor-cores 1 \--executor-memory 8G \--driver-memory 8G \--queue root.hypers.adhoc \--conf spark.yarn.executor.memoryoverhead=2048m \--conf spark.storage.memoryFraction=0.4 \--conf spark.hadoop.hive.cli.print.header=true \--conf spark.sql.shuffle.partitions=500 \--conf spark.dynamicAllocation.enabled=true \--conf spark.sql.autoBroadcastJoinThreshold=-1 \--conf spark.dynamicAllocation.maxExecutors=80 \--conf spark.driver.maxResultSize=4g \--hiveconf hive.exec.dynamic.partition=true \--hiveconf hive.exec.dynamic.partition.mode=nonstrict \--hiveconf hive.exec.max.dynamic.partitions=10000 \--hiveconf hive.exec.max.dynamic.partitions.pernode=10000 \--hiveconf spark.debug.maxToStringFields=200 \-f lrl.sql</code></pre><ul><li>现象</li></ul><pre><code class="hljs angelscript">--此阶段executor端--(<span class="hljs-number">7029</span>/<span class="hljs-number">7037</span>)代表task（未完成/已完成）的数量<span class="hljs-number">20</span>/<span class="hljs-number">11</span>/<span class="hljs-number">11</span> <span class="hljs-number">23</span>:<span class="hljs-number">55</span>:<span class="hljs-number">22</span> INFO scheduler.TaskSetManager: Finished task <span class="hljs-number">7000.0</span> <span class="hljs-keyword">in</span> stage <span class="hljs-number">0.0</span> (TID <span class="hljs-number">7000</span>) <span class="hljs-keyword">in</span> <span class="hljs-number">13864</span> ms on worker32.loreal.com (executor <span class="hljs-number">5</span>) (<span class="hljs-number">7029</span>/<span class="hljs-number">7037</span>)--个人理解如果在executor端出现gc，应该是executor-memory的问题如果发生在<span class="hljs-number">20</span>/<span class="hljs-number">11</span>/<span class="hljs-number">11</span> <span class="hljs-number">23</span>:<span class="hljs-number">55</span>:<span class="hljs-number">47</span> INFO spark.ContextCleaner: Cleaned accumulator <span class="hljs-number">11</span><span class="hljs-number">20</span>/<span class="hljs-number">11</span>/<span class="hljs-number">11</span> <span class="hljs-number">23</span>:<span class="hljs-number">59</span>:<span class="hljs-number">08</span> INFO spark.ExecutorAllocationManager: Request to remove executorIds: <span class="hljs-number">45</span>, <span class="hljs-number">30</span>, <span class="hljs-number">39</span>, <span class="hljs-number">51</span>, <span class="hljs-number">2</span>, <span class="hljs-number">5</span>, <span class="hljs-number">48</span>, <span class="hljs-number">33</span>, <span class="hljs-number">27</span>, <span class="hljs-number">12</span>, <span class="hljs-number">8</span>, <span class="hljs-number">15</span>, <span class="hljs-number">42</span>, <span class="hljs-number">36</span>, <span class="hljs-number">21</span>, <span class="hljs-number">18</span>, <span class="hljs-number">24</span>, <span class="hljs-number">41</span>, <span class="hljs-number">35</span>, <span class="hljs-number">7</span>, <span class="hljs-number">17</span>, <span class="hljs-number">1</span>, <span class="hljs-number">44</span>, <span class="hljs-number">50</span>, <span class="hljs-number">23</span>, <span class="hljs-number">38</span>, <span class="hljs-number">47</span>, <span class="hljs-number">26</span>, <span class="hljs-number">4</span>, <span class="hljs-number">11</span>, <span class="hljs-number">32</span>, <span class="hljs-number">1</span>之后则是driver-memory的问题</code></pre><ul><li>尝试通过提高driver端的内存</li></ul><pre><code class="hljs shell">--conf driver-memory 10G</code></pre><ul><li>driver堆外内存</li></ul><pre><code class="hljs shell">--spark.driver.memoryOverhead=2048m</code></pre><ul><li>executor-core的数量太多，导致多个core之间争夺GC时间以及资源，最后大部分时间都花到了gc上</li></ul><pre><code class="hljs ada"><span class="hljs-comment">--executor-cores 1</span></code></pre><h4 id="关于一些资料的总结"><a href="#关于一些资料的总结" class="headerlink" title="关于一些资料的总结"></a>关于一些资料的总结</h4><pre><code class="hljs apache"><span class="hljs-attribute">executor</span>-cores cores越多，能快速的执行分配给自己的task 建议<span class="hljs-number">2</span>-<span class="hljs-number">4</span>个<span class="hljs-attribute">driver</span>-memory默认<span class="hljs-number">1</span>g，如果使用collect算子，那么会将rdd算子全部拉到driver上执行，确保driver内存足够大，否则oom<span class="hljs-attribute">spark</span>.default.parallelism = num-executors*executor-cores*<span class="hljs-number">2</span>-<span class="hljs-number">3</span> 并行度<span class="hljs-attribute">spark</span>.storage.memoryFraction executor中用于持久化的比例，默认<span class="hljs-number">0</span>.<span class="hljs-number">6</span><span class="hljs-attribute">spark</span>.shuffle.memoryFraction 用来进行shuffle(read)操作的内存比例，默认<span class="hljs-number">0</span>.<span class="hljs-number">2</span></code></pre><h4 id="sparksql出现的问题，hdfs-dfs-distcp方式拷贝hdfs的表元数据"><a href="#sparksql出现的问题，hdfs-dfs-distcp方式拷贝hdfs的表元数据" class="headerlink" title="sparksql出现的问题，hdfs dfs -distcp方式拷贝hdfs的表元数据"></a>sparksql出现的问题，hdfs dfs -distcp方式拷贝hdfs的表元数据</h4><pre><code class="hljs shell">Caused by: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://nameservice1/DATA/DWS/mirror_dim_arvato_sys_tier_type/pt_brand_code=1-ATDHL/pt_sum_date=20201120003925<span class="hljs-meta">#</span><span class="bash">我们这里查一下此表的路径</span><span class="hljs-meta">#</span><span class="bash">拷贝之后的分区路径：</span>drwxrwx--x+  - hive hive          0 2020-11-24 22:36 hdfs://nameservice1/DATA/DWS/mirror_dim_arvato_sys_tier_type/pt_brand_code=1-ATDHL/pt_sum_date=20201124003823<span class="hljs-meta">#</span><span class="bash">拷贝之前的分区路径：</span>drwxrwx--x+  - hive hive          0 2020-12-01 00:42 hdfs://nameservice1/DATA/DWS/dim_arvato_sys_tier_type/pt_brand_code=1-ATDHL/pt_sum_date=20201201003742<span class="hljs-meta">#</span><span class="bash">因为distcp全量，发现此表的分区的值已经变了，难怪sparksql报错</span><span class="hljs-meta">#</span><span class="bash">解决方式1：忽略损坏分区</span><span class="hljs-meta">#</span><span class="bash">sparksql需要添加参数：</span>set spark.sql.hive.verifyPartitionPath=true;hive则不用<span class="hljs-meta">#</span><span class="bash">思考下为什么，有没有更好的方式解决；</span></code></pre><h1 id="distcp"><a href="#distcp" class="headerlink" title="distcp"></a>distcp</h1><p>&lt;<a href="http://hadoop.apache.org/docs/r1.0.4/cn/distcp.html">DistCp (apache.org)</a>&gt;</p><p>distcp用于大规模的大数据集群内部和集群之间的拷贝工具，把文件和目录的列表作为map端输入，每个任务完成列表中部分文件的拷贝</p><h1 id="count-vs-count-字段"><a href="#count-vs-count-字段" class="headerlink" title="count(*) vs count(字段)"></a>count(*) vs count(字段)</h1><p>count(*) 有null</p><p>count(字段)无null</p>]]></content>
    
    
    
    <tags>
      
      <tag>hive</tag>
      
      <tag>生产</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>tez</title>
    <link href="/2020/10/28/tez/"/>
    <url>/2020/10/28/tez/</url>
    
    <content type="html"><![CDATA[<h1 id="tez官网"><a href="#tez官网" class="headerlink" title="tez官网"></a>tez官网</h1><pre><code class="hljs sql">http://tez.apache.org/</code></pre><h1 id="什么是Tez？"><a href="#什么是Tez？" class="headerlink" title="什么是Tez？"></a>什么是Tez？</h1><p>tez是一个基于内存的计算引擎，通过允许像 Apache Hive 和 Apache Pig 这样的项目运行复杂的 DAG 任务，Tez 可用于处理数据。</p><ul><li>优点：快，节点少</li><li>缺点：对内存要求高</li></ul><h1 id="Tez安装部署"><a href="#Tez安装部署" class="headerlink" title="Tez安装部署"></a>Tez安装部署</h1><ol><li>查看官网选择和hadoop匹配的tez版本</li></ol><pre><code class="hljs applescript">hadoop <span class="hljs-built_in">version</span></code></pre><ol start="2"><li>下载</li></ol><pre><code class="hljs awk">http:<span class="hljs-regexp">//</span>www.apache.org<span class="hljs-regexp">/dyn/</span>closer.lua<span class="hljs-regexp">/tez/</span><span class="hljs-number">0.8</span>.<span class="hljs-number">5</span>/</code></pre><ol start="3"><li>解压</li></ol><ul><li>注意：解压到hive的节点上</li></ul><ol start="4"><li>下载的tez包（ apache-tez-0.8.5-bin.tar.gz） 上传到hdfs上</li></ol><ul><li>除了hive节点，其他节点也需要tez计算</li></ul><p>5. </p>]]></content>
    
    
    
    <tags>
      
      <tag>hive</tag>
      
      <tag>tez</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sql函数</title>
    <link href="/2020/10/28/sql01/"/>
    <url>/2020/10/28/sql01/</url>
    
    <content type="html"><![CDATA[<h1 id="总结常用sql函数"><a href="#总结常用sql函数" class="headerlink" title="总结常用sql函数"></a>总结常用sql函数</h1><h2 id="1-unix-timestamp-amp-from-unixtime"><a href="#1-unix-timestamp-amp-from-unixtime" class="headerlink" title="1.unix_timestamp &amp; from_unixtime()"></a>1.unix_timestamp &amp; from_unixtime()</h2><ul><li>unix_timestamp</li></ul><pre><code class="hljs sql">spark-sql&gt; select unix_timestamp(&#x27;2018-12-05 01:10:00&#x27;,&#x27;yyyy-MM-dd HH:mm:ss&#x27;);1543943400</code></pre> <pre><code class="hljs sql">spark-sql&gt; select unix_timestamp(&#x27;2018-12-05&#x27;,&#x27;yyyy-MM-dd&#x27;);1543939200</code></pre><ul><li>from_unixtime()</li></ul><pre><code class="hljs sql">spark-sql&gt; select from_unixtime(1543943400,&#x27;yyyy-MM-dd&#x27;);2018-12-05</code></pre><h2 id="2-cast-name-as-string-类型转换"><a href="#2-cast-name-as-string-类型转换" class="headerlink" title="2. cast(name as string) 类型转换"></a>2. cast(name as string) 类型转换</h2><ul><li>cnt int –&gt; cnt string</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-keyword">cast</span>(cnt <span class="hljs-keyword">as</span> <span class="hljs-keyword">string</span>) <span class="hljs-keyword">from</span> player;</code></pre><h2 id="3-if-name-’ks’-x-y"><a href="#3-if-name-’ks’-x-y" class="headerlink" title="3. if(name=’ks’,x,y)"></a>3. if(name=’ks’,x,y)</h2><ul><li>如果name字段是ks，返回x，否则返回y</li></ul><h2 id="4-hive中map类型的字段使用"><a href="#4-hive中map类型的字段使用" class="headerlink" title="4. hive中map类型的字段使用"></a>4. hive中map类型的字段使用</h2><ul><li>创建表</li><li>注意集合，key的分隔符</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> player_info (groupname <span class="hljs-keyword">string</span>,info <span class="hljs-keyword">map</span>&lt;<span class="hljs-keyword">string</span>,<span class="hljs-keyword">string</span>&gt;)<span class="hljs-keyword">ROW</span> <span class="hljs-keyword">FORMAT</span> <span class="hljs-keyword">DELIMITED</span>                                          <span class="hljs-keyword">FIELDS</span> <span class="hljs-keyword">TERMINATED</span> <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;\t&#x27;</span>                                COLLECTION ITEMS <span class="hljs-keyword">TERMINATED</span> <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;,&#x27;</span>                       <span class="hljs-keyword">MAP</span> <span class="hljs-keyword">KEYS</span> <span class="hljs-keyword">TERMINATED</span> <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;:&#x27;</span>;</code></pre><ul><li>文本数据准备</li><li>player_info.txt</li></ul><pre><code class="hljs css"><span class="hljs-selector-tag">win_team</span><span class="hljs-selector-tag">name</span><span class="hljs-selector-pseudo">:ks</span>,<span class="hljs-selector-tag">age</span><span class="hljs-selector-pseudo">:18</span>,<span class="hljs-selector-tag">position</span><span class="hljs-selector-pseudo">:carry</span><span class="hljs-selector-tag">win_team</span><span class="hljs-selector-tag">name</span><span class="hljs-selector-pseudo">:ajshon</span>,<span class="hljs-selector-tag">age</span><span class="hljs-selector-pseudo">:19</span>,<span class="hljs-selector-tag">position</span><span class="hljs-selector-pseudo">:mid</span><span class="hljs-selector-tag">lose_team</span><span class="hljs-selector-tag">name</span><span class="hljs-selector-pseudo">:rain</span>,<span class="hljs-selector-tag">age</span><span class="hljs-selector-pseudo">:28</span>,<span class="hljs-selector-tag">position</span><span class="hljs-selector-pseudo">:top</span></code></pre><ul><li>导入数据到表</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">load</span> <span class="hljs-keyword">data</span> <span class="hljs-keyword">local</span> inpath <span class="hljs-string">&#x27;/home/hadoop/data/player_info.txt&#x27;</span> <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> player_info;</code></pre><ul><li>查询</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> info[<span class="hljs-string">&#x27;name&#x27;</span>] <span class="hljs-keyword">from</span> player_info;</code></pre><ul><li>结果</li></ul><pre><code class="hljs apache"><span class="hljs-attribute">Driver</span>.java:<span class="hljs-number">376</span>, took <span class="hljs-number">0</span>.<span class="hljs-number">719682</span> s<span class="hljs-attribute">ks</span><span class="hljs-attribute">ajshon</span><span class="hljs-attribute">rain</span></code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>sql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>sql语句</title>
    <link href="/2020/10/28/sql02/"/>
    <url>/2020/10/28/sql02/</url>
    
    <content type="html"><![CDATA[<h1 id="总结常用sql语句"><a href="#总结常用sql语句" class="headerlink" title="总结常用sql语句"></a>总结常用sql语句</h1><h2 id><a href="#" class="headerlink" title></a></h2><p>建表语句</p><ul><li>多表结构相同</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">tables</span> <span class="hljs-keyword">as</span><span class="hljs-keyword">select</span> <span class="hljs-keyword">id</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">from</span> player1<span class="hljs-keyword">union</span> <span class="hljs-keyword">all</span><span class="hljs-keyword">select</span> <span class="hljs-keyword">id</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">from</span> player2;</code></pre><ul><li>多表结构不相同</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> tables2<span class="hljs-keyword">as</span> <span class="hljs-keyword">with</span>a <span class="hljs-keyword">as</span> (<span class="hljs-keyword">select</span> <span class="hljs-keyword">id</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">from</span> player1),b <span class="hljs-keyword">as</span> (<span class="hljs-keyword">select</span> <span class="hljs-keyword">id</span>,age <span class="hljs-keyword">from</span> player2)<span class="hljs-keyword">select</span> a.id,a.name,b.age <span class="hljs-keyword">from</span> a,b <span class="hljs-keyword">where</span> a.id=b.id;</code></pre><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> tables3<span class="hljs-keyword">as</span> <span class="hljs-keyword">with</span>a <span class="hljs-keyword">as</span> (<span class="hljs-keyword">select</span> <span class="hljs-keyword">id</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">from</span> player1),b <span class="hljs-keyword">as</span> (<span class="hljs-keyword">select</span> <span class="hljs-keyword">id</span>,age <span class="hljs-keyword">from</span> player2)<span class="hljs-keyword">select</span> a.id,a.name,b.age <span class="hljs-keyword">from</span> a<span class="hljs-keyword">inner</span> <span class="hljs-keyword">join</span>b <span class="hljs-keyword">on</span> a.id=b.id;</code></pre><h2 id="元数据-和-建表语句-分开"><a href="#元数据-和-建表语句-分开" class="headerlink" title="元数据 和 建表语句 分开"></a>元数据 和 建表语句 分开</h2><h3 id="方式一（hdfs）"><a href="#方式一（hdfs）" class="headerlink" title="方式一（hdfs）"></a>方式一（hdfs）</h3><ul><li>元数据test.txt上传hdfs</li></ul><pre><code class="hljs awk">hdfs dfs -put test.txt <span class="hljs-regexp">/hive/</span>test/</code></pre><ul><li>建表指定位置</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> player4(<span class="hljs-keyword">id</span> <span class="hljs-built_in">int</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">string</span>) <span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> <span class="hljs-keyword">delimited</span> <span class="hljs-keyword">fields</span> <span class="hljs-keyword">terminated</span> <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span> location <span class="hljs-string">&#x27;/hive/test&#x27;</span>;</code></pre><h3 id="方式二（load方式，本地、hdfs）"><a href="#方式二（load方式，本地、hdfs）" class="headerlink" title="方式二（load方式，本地、hdfs）"></a>方式二（load方式，本地、hdfs）</h3><ul><li>建表</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> player4(<span class="hljs-keyword">id</span> <span class="hljs-built_in">int</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">string</span>) <span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> <span class="hljs-keyword">delimited</span> <span class="hljs-keyword">fields</span> <span class="hljs-keyword">terminated</span> <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span></code></pre><ul><li>元数据load到表中(“[ ]”代表可选)</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">load</span> <span class="hljs-keyword">data</span> [<span class="hljs-keyword">local</span>] inpath <span class="hljs-string">&#x27;/home/hadoop/data/test.txt&#x27;</span> <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> player4</code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>sql</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hive数据类型、语法、分区表等概念</title>
    <link href="/2020/10/26/hive01/"/>
    <url>/2020/10/26/hive01/</url>
    
    <content type="html"><![CDATA[<h1 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h1><table><thead><tr><th>Hive数据类型</th><th>java数据类型</th><th>长度</th><th>例子</th></tr></thead><tbody><tr><td>TinyInt</td><td>byte</td><td>1byte有符号整数</td><td>20</td></tr><tr><td>SmallInt</td><td>short</td><td>2byte有符号整数</td><td>20</td></tr><tr><td>Int</td><td>int</td><td>4byte有符号整数</td><td>20</td></tr><tr><td>BigInt</td><td>long</td><td>8byte有符号整数</td><td>20</td></tr><tr><td>Boolean</td><td>boolean</td><td>布尔类型</td><td>true，false</td></tr><tr><td>Float</td><td>float</td><td>单精度浮点数</td><td>3.14159</td></tr><tr><td>Double</td><td>double</td><td>双精度浮点数</td><td>3.14159</td></tr><tr><td>String</td><td>string</td><td>字符</td><td>‘now is time’</td></tr><tr><td>Timestamp</td><td></td><td>时间类型</td><td></td></tr><tr><td>binary</td><td></td><td>字节数组</td><td></td></tr></tbody></table><ul><li>hive中的string相当于数据库的varchar，理论上能存2G的字符串</li><li>小转大，不能大转小</li><li>string、float可以隐式转换成double</li><li>tinyint、smallint、int可以转换为float</li><li>boolean类型不能转换为其他类型</li><li>强制类型转换，可以使用CAST(1 AS INT)把字符串’1’转换成整数1，㘝强制类型转换失败，返回NULL</li></ul><h1 id="DDL数据定义"><a href="#DDL数据定义" class="headerlink" title="DDL数据定义"></a>DDL数据定义</h1><h2 id="库的增删改查"><a href="#库的增删改查" class="headerlink" title="库的增删改查"></a>库的增删改查</h2><h3 id="1-创建数据库"><a href="#1-创建数据库" class="headerlink" title="1. 创建数据库"></a>1. 创建数据库</h3><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">database</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">exists</span> mydb;</code></pre><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">database</span> mydb location <span class="hljs-string">&#x27;/db_hive2.db&#x27;</span>;</code></pre><h3 id="2-删除数据库"><a href="#2-删除数据库" class="headerlink" title="2. 删除数据库"></a>2. 删除数据库</h3><pre><code class="hljs sql"><span class="hljs-keyword">drop</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">exists</span> mydb;</code></pre><ul><li>删除不为空的database</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">drop</span> <span class="hljs-keyword">database</span> mydb <span class="hljs-keyword">cascade</span>;</code></pre><h3 id="3-查看数据库"><a href="#3-查看数据库" class="headerlink" title="3. 查看数据库"></a>3. 查看数据库</h3><ul><li>模糊查询</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">show</span> <span class="hljs-keyword">databases</span> <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;db_hive*&#x27;</span>;</code></pre><ul><li>查看数据库详细信息</li></ul><pre><code class="hljs pgsql"><span class="hljs-keyword">desc</span> <span class="hljs-keyword">database</span> extended db_hive;</code></pre><h3 id="4-修改数据库"><a href="#4-修改数据库" class="headerlink" title="4. 修改数据库"></a>4. 修改数据库</h3><ul><li>注意：元数据信息不能更改（数据库名，数据库所在位置）</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">database</span> db_hive <span class="hljs-keyword">set</span> dbproperties(<span class="hljs-string">&#x27;createtime&#x27;</span>=<span class="hljs-string">&#x27;20200808&#x27;</span>)</code></pre><h2 id="表的增删改查"><a href="#表的增删改查" class="headerlink" title="表的增删改查"></a>表的增删改查</h2><h3 id="1-建表语句"><a href="#1-建表语句" class="headerlink" title="1. 建表语句"></a>1. 建表语句</h3><ul><li>分区分的是文件夹，分桶分的是文件（对应partitioned by、clustered by）</li><li>‘[ ]’表示可选，’|’表示二选一</li><li>指定分隔符</li></ul><pre><code class="hljs sql">row format delimited fields terminated by &#x27;/t&#x27;</code></pre><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> [<span class="hljs-keyword">TEMPORARY</span>] [<span class="hljs-keyword">EXTERNAL</span>] <span class="hljs-keyword">TABLE</span> [<span class="hljs-keyword">IF</span> <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span>] [db_name.]table_name  [(col_name data_type [<span class="hljs-keyword">COMMENT</span> col_comment], ... [constraint_specification])]  [<span class="hljs-keyword">COMMENT</span> table_comment]  [PARTITIONED <span class="hljs-keyword">BY</span> (col_name data_type [<span class="hljs-keyword">COMMENT</span> col_comment], ...)]  [CLUSTERED <span class="hljs-keyword">BY</span> (col_name, col_name, ...) [SORTED <span class="hljs-keyword">BY</span> (col_name [<span class="hljs-keyword">ASC</span>|<span class="hljs-keyword">DESC</span>], ...)] <span class="hljs-keyword">INTO</span> num_buckets BUCKETS]  [SKEWED <span class="hljs-keyword">BY</span> (col_name, col_name, ...)     <span class="hljs-keyword">ON</span> ((col_value, col_value, ...), (col_value, col_value, ...), ...)     [<span class="hljs-keyword">STORED</span> <span class="hljs-keyword">AS</span> DIRECTORIES]  [   [<span class="hljs-keyword">ROW</span> <span class="hljs-keyword">FORMAT</span> row_format]    [<span class="hljs-keyword">STORED</span> <span class="hljs-keyword">AS</span> file_format]     | <span class="hljs-keyword">STORED</span> <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;storage.handler.class.name&#x27;</span> [<span class="hljs-keyword">WITH</span> SERDEPROPERTIES (...)]  ]  [LOCATION hdfs_path]</code></pre><pre><code class="hljs sql"><span class="hljs-keyword">CREATE</span> [<span class="hljs-keyword">TEMPORARY</span>] [<span class="hljs-keyword">EXTERNAL</span>] <span class="hljs-keyword">TABLE</span> [<span class="hljs-keyword">IF</span> <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span>] [db_name.]table_name    <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> TEMPORARY available in Hive 0.14.0 and later)</span>  [(col_name data_type [<span class="hljs-keyword">COMMENT</span> col_comment], ... [constraint_specification])]  [<span class="hljs-keyword">COMMENT</span> table_comment]  [PARTITIONED <span class="hljs-keyword">BY</span> (col_name data_type [<span class="hljs-keyword">COMMENT</span> col_comment], ...)]  [CLUSTERED <span class="hljs-keyword">BY</span> (col_name, col_name, ...) [SORTED <span class="hljs-keyword">BY</span> (col_name [<span class="hljs-keyword">ASC</span>|<span class="hljs-keyword">DESC</span>], ...)] <span class="hljs-keyword">INTO</span> num_buckets BUCKETS]  [SKEWED <span class="hljs-keyword">BY</span> (col_name, col_name, ...)                  <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.10.0 and later)]</span>     <span class="hljs-keyword">ON</span> ((col_value, col_value, ...), (col_value, col_value, ...), ...)     [<span class="hljs-keyword">STORED</span> <span class="hljs-keyword">AS</span> DIRECTORIES]  [   [<span class="hljs-keyword">ROW</span> <span class="hljs-keyword">FORMAT</span> row_format]    [<span class="hljs-keyword">STORED</span> <span class="hljs-keyword">AS</span> file_format]     | <span class="hljs-keyword">STORED</span> <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;storage.handler.class.name&#x27;</span> [<span class="hljs-keyword">WITH</span> SERDEPROPERTIES (...)]  <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.6.0 and later)</span>  ]  [LOCATION hdfs_path]  [TBLPROPERTIES (property_name=property_value, ...)]   <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.6.0 and later)</span>   [<span class="hljs-keyword">AS</span> select_statement];   <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.5.0 and later; not supported for external tables)</span>   <span class="hljs-keyword">CREATE</span> [<span class="hljs-keyword">TEMPORARY</span>] [<span class="hljs-keyword">EXTERNAL</span>] <span class="hljs-keyword">TABLE</span> [<span class="hljs-keyword">IF</span> <span class="hljs-keyword">NOT</span> <span class="hljs-keyword">EXISTS</span>] [db_name.]table_name  <span class="hljs-keyword">LIKE</span> existing_table_or_view_name  [LOCATION hdfs_path]; data_type  : primitive_type  | array_type  | map_type  | struct_type  | union_type  <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.7.0 and later)</span> primitive_type  : TINYINT  | SMALLINT  | INT  | BIGINT  | BOOLEAN  | FLOAT  | DOUBLE  | DOUBLE PRECISION <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 2.2.0 and later)</span>  | STRING  | BINARY      <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.8.0 and later)</span>  | TIMESTAMP   <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.8.0 and later)</span>  | DECIMAL     <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.11.0 and later)</span>  | DECIMAL(precision, scale)  <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.13.0 and later)</span>  | DATE        <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.12.0 and later)</span>  | VARCHAR     <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.12.0 and later)</span>  | CHAR        <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.13.0 and later)</span> array_type  : ARRAY &lt; data_type &gt; map_type  : MAP &lt; primitive_type, data_type &gt; struct_type  : STRUCT &lt; col_name : data_type [COMMENT col_comment], ...&gt; union_type   : UNIONTYPE &lt; data_type, data_type, ... &gt;  -- (Note: Available in Hive 0.7.0 and later) row_format  : DELIMITED [FIELDS TERMINATED BY char [ESCAPED BY char]] [COLLECTION ITEMS TERMINATED BY char]        [MAP KEYS TERMINATED BY char] [LINES TERMINATED BY char]        [NULL DEFINED AS char]   <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.13 and later)</span>  | SERDE serde_name [<span class="hljs-keyword">WITH</span> SERDEPROPERTIES (property_name=property_value, property_name=property_value, ...)] file_format:  : SEQUENCEFILE  | TEXTFILE    <span class="hljs-comment">-- (Default, depending on hive.default.fileformat configuration)</span>  | RCFILE      <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.6.0 and later)</span>  | ORC         <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.11.0 and later)</span>  | PARQUET     <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.13.0 and later)</span>  | AVRO        <span class="hljs-comment">-- (<span class="hljs-doctag">Note:</span> Available in Hive 0.14.0 and later)</span>  | INPUTFORMAT input_format_classname OUTPUTFORMAT output_format_classname constraint_specification:  : [, PRIMARY <span class="hljs-keyword">KEY</span> (col_name, ...) <span class="hljs-keyword">DISABLE</span> <span class="hljs-keyword">NOVALIDATE</span> ]    [, <span class="hljs-keyword">CONSTRAINT</span> constraint_name <span class="hljs-keyword">FOREIGN</span> <span class="hljs-keyword">KEY</span> (col_name, ...) <span class="hljs-keyword">REFERENCES</span> table_name(col_name, ...) <span class="hljs-keyword">DISABLE</span> <span class="hljs-keyword">NOVALIDATE</span></code></pre><h3 id="2-修改表"><a href="#2-修改表" class="headerlink" title="2. 修改表"></a>2. 修改表</h3><ul><li>重命名表</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> student4 <span class="hljs-keyword">rename</span> <span class="hljs-keyword">to</span> student;</code></pre><ul><li>增删改分区</li></ul><p>见如下分区表</p><ul><li>增加、修改、替换列信息</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> student4 <span class="hljs-keyword">add</span> <span class="hljs-keyword">columns</span>(<span class="hljs-keyword">name</span> <span class="hljs-keyword">string</span>);</code></pre><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> student4 <span class="hljs-keyword">change</span> <span class="hljs-keyword">column</span> <span class="hljs-keyword">name</span> <span class="hljs-keyword">names</span> <span class="hljs-keyword">string</span>;</code></pre><pre><code class="hljs sql"><span class="hljs-comment">--替换所有列</span><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> student4 <span class="hljs-keyword">replace</span> <span class="hljs-keyword">columns</span>(did <span class="hljs-built_in">int</span>);</code></pre><h2 id="内部表和外部表区别"><a href="#内部表和外部表区别" class="headerlink" title="内部表和外部表区别"></a>内部表和外部表区别</h2><ol><li>删除表内部表的元数据也会删除，外部表则不会</li><li>建表语句不同，外部表有external关键字</li></ol><ul><li><p>内部表也叫管理表</p></li><li><p>内部表转外部表（大写！）</p></li></ul><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> student2 <span class="hljs-keyword">set</span> tblproperties(<span class="hljs-string">&#x27;EXTERNAL&#x27;</span>=<span class="hljs-string">&#x27;TURE&#x27;</span>);</code></pre><ul><li>然后查询一下</li></ul><pre><code class="hljs sql">desc formatted student2;</code></pre><h2 id="分区表"><a href="#分区表" class="headerlink" title="分区表"></a>分区表</h2><p>hive的分区表就是分目录，把一个大的数据集根据业务需要分割成小的数据集，在查询的时候通过WHERE子句中的表达选择所需要的的指定分区，这样查询效率高。谓词下推</p><ul><li>谓词下推：先过滤成小数据集，再查询，效率高。</li><li>分区字段也是表中的一个字段，只不过比较特殊。（不能使用表属性名作为分区字段名，自行体会）</li></ul><h3 id="一级分区"><a href="#一级分区" class="headerlink" title="一级分区"></a>一级分区</h3><ol><li>增加分区</li></ol><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> student <span class="hljs-keyword">add</span> <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span>=<span class="hljs-string">&#x27;202008&#x27;</span>) <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span>=<span class="hljs-string">&#x27;202009&#x27;</span>);</code></pre><ol start="2"><li>删除分区</li></ol><ul><li>注意这里是’ , ‘</li></ul><pre><code class="hljs sql">alte table student <span class="hljs-keyword">drop</span> <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span>=<span class="hljs-string">&#x27;202008&#x27;</span>) ,<span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span>=<span class="hljs-string">&#x27;202009&#x27;</span>);</code></pre><ol start="3"><li>查看分区表有多少个分区</li></ol><pre><code class="hljs sql"><span class="hljs-keyword">show</span> <span class="hljs-keyword">partitions</span> student;</code></pre><ol start="4"><li>查看分区表的结构</li></ol><pre><code class="hljs sql">desc formatted student;</code></pre><h3 id="二级分区"><a href="#二级分区" class="headerlink" title="二级分区"></a>二级分区</h3><ol><li>建表</li></ol><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> student2(<span class="hljs-keyword">id</span> <span class="hljs-built_in">int</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">string</span>) partitioned <span class="hljs-keyword">by</span> (<span class="hljs-keyword">month</span> <span class="hljs-keyword">string</span>,<span class="hljs-keyword">day</span> <span class="hljs-keyword">string</span>) <span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> <span class="hljs-keyword">delimited</span> <span class="hljs-keyword">fields</span> <span class="hljs-keyword">terminated</span> <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span>;</code></pre><ol start="2"><li>导入本地数据</li></ol><pre><code class="hljs sql"><span class="hljs-keyword">load</span> <span class="hljs-keyword">data</span> <span class="hljs-keyword">local</span> inpath <span class="hljs-string">&#x27;/home/hadoop/data/student2.txt&#x27;</span> <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> student2 <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span>=<span class="hljs-string">&#x27;2019-07&#x27;</span>,<span class="hljs-keyword">day</span>=<span class="hljs-string">&#x27;01&#x27;</span>);</code></pre><ol start="3"><li>查询</li></ol><pre><code class="hljs sql"><span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> student2 <span class="hljs-keyword">where</span> <span class="hljs-keyword">month</span> = <span class="hljs-string">&#x27;2019-07&#x27;</span> <span class="hljs-keyword">and</span> <span class="hljs-keyword">day</span> = <span class="hljs-string">&#x27;01&#x27;</span>;</code></pre><pre><code> 4. 如果手动创建了一个分区文件夹，并上传文件，是不能直接查分区的，需要修复或者添加分区</code></pre><ul><li>修复指令（很多分区都没有添加）</li></ul><pre><code class="hljs sql">msck <span class="hljs-keyword">repair</span> <span class="hljs-keyword">table</span> student2;</code></pre><ul><li>添加分区（推荐）</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">alter</span> <span class="hljs-keyword">table</span> student2 <span class="hljs-keyword">add</span> <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span> = <span class="hljs-string">&#x27;2019-11&#x27;</span>,<span class="hljs-keyword">day</span> = <span class="hljs-string">&#x27;01&#x27;</span>)</code></pre><h1 id="DML数据操作"><a href="#DML数据操作" class="headerlink" title="DML数据操作"></a>DML数据操作</h1><h2 id="数据导入"><a href="#数据导入" class="headerlink" title="数据导入"></a>数据导入</h2><h3 id="1-向表中装载数据"><a href="#1-向表中装载数据" class="headerlink" title="1. 向表中装载数据"></a>1. 向表中装载数据</h3><pre><code class="hljs sql"><span class="hljs-keyword">load</span> <span class="hljs-keyword">data</span> [<span class="hljs-keyword">local</span>] inpath <span class="hljs-string">&#x27;xxx/xxx/xxx.txt&#x27;</span> overwrite|<span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> student [<span class="hljs-keyword">partition</span>(<span class="hljs-keyword">day</span>=<span class="hljs-string">&#x27;01&#x27;</span>,<span class="hljs-keyword">month</span>=<span class="hljs-string">&#x27;201708&#x27;</span>]</code></pre><ul><li>local：本地或者hdfs</li></ul><h3 id="2-插入数据"><a href="#2-插入数据" class="headerlink" title="2. 插入数据"></a>2. 插入数据</h3><ul><li>基本插入</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> <span class="hljs-keyword">table</span> student <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span>=<span class="hljs-string">&#x27;201702&#x27;</span>) <span class="hljs-keyword">values</span>(<span class="hljs-number">1</span>,<span class="hljs-string">&#x27;ks&#x27;</span>)</code></pre><ul><li>覆盖插入</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">insert</span> overwrite <span class="hljs-keyword">table</span> student <span class="hljs-keyword">partition</span>(<span class="hljs-keyword">month</span>=<span class="hljs-string">&#x27;20170208&#x27;</span>) <span class="hljs-keyword">select</span> <span class="hljs-keyword">id</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">from</span> student <span class="hljs-keyword">where</span> <span class="hljs-keyword">month</span>=<span class="hljs-string">&#x27;201702&#x27;</span></code></pre><h3 id="3-创建表并加载数据"><a href="#3-创建表并加载数据" class="headerlink" title="3.创建表并加载数据"></a>3.创建表并加载数据</h3><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">exists</span> student <span class="hljs-keyword">as</span> <span class="hljs-keyword">select</span> <span class="hljs-keyword">id</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">from</span> student</code></pre><h3 id="3-导出数据"><a href="#3-导出数据" class="headerlink" title="3.导出数据"></a>3.导出数据</h3><h4 id="insert导出"><a href="#insert导出" class="headerlink" title="insert导出"></a>insert导出</h4><h5 id="1-将结果导出到本地"><a href="#1-将结果导出到本地" class="headerlink" title="1.将结果导出到本地"></a>1.将结果导出到本地</h5><pre><code class="hljs sql"><span class="hljs-keyword">insert</span> overwrite <span class="hljs-keyword">local</span> <span class="hljs-keyword">directory</span> <span class="hljs-string">&#x27;/opt/module/datas/export/student&#x27;</span> <span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> student;</code></pre><h5 id="2-将查询结果格式化导出到本地-hdfs上"><a href="#2-将查询结果格式化导出到本地-hdfs上" class="headerlink" title="2. 将查询结果格式化导出到本地/hdfs上"></a>2. 将查询结果格式化导出到本地/hdfs上</h5><pre><code class="hljs sql"><span class="hljs-keyword">insert</span> overwrite [<span class="hljs-keyword">local</span>] <span class="hljs-keyword">directory</span> <span class="hljs-string">&#x27;/opt/module/datas/export/student1&#x27;</span> <span class="hljs-keyword">ROW</span> <span class="hljs-keyword">FORMAT</span> <span class="hljs-keyword">DELIMITED</span> <span class="hljs-keyword">FIELDS</span> <span class="hljs-keyword">TERMINATED</span> <span class="hljs-keyword">BY</span> <span class="hljs-string">&#x27;\t&#x27;</span> <span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> student;</code></pre><h4 id="hadoop导出"><a href="#hadoop导出" class="headerlink" title="hadoop导出"></a>hadoop导出</h4><pre><code class="hljs shell">hdfs dfs -get /user/hive/warehouse/student/month=20201125 /opt/module/datas/export/student3.txt</code></pre><ul><li>导出并合并</li></ul><pre><code class="hljs shell">hdfs dfs -getmerge /xxx /xxx/xxx.txt</code></pre><h4 id="sqoop导出"><a href="#sqoop导出" class="headerlink" title="sqoop导出"></a>sqoop导出</h4><ul><li>用于hive、mysql之间的导入导出</li></ul><h4 id="export导出"><a href="#export导出" class="headerlink" title="export导出"></a>export导出</h4><pre><code class="hljs shell">export table default.student to &#x27;/user/hive/warehouse/export/student&#x27;;</code></pre><h3 id="4-清空表"><a href="#4-清空表" class="headerlink" title="4. 清空表"></a>4. 清空表</h3><ul><li>注意：只能清空管理表，不能清空外部表</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">truncate</span> <span class="hljs-keyword">table</span> default.student;</code></pre><h3 id="5-查询"><a href="#5-查询" class="headerlink" title="5. 查询"></a>5. 查询</h3><ul><li>匹配多个单词</li><li>匹配一个单词</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-keyword">name</span> <span class="hljs-keyword">from</span> student <span class="hljs-keyword">where</span> <span class="hljs-keyword">name</span> <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;k%&#x27;</span>;</code></pre><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-keyword">name</span> <span class="hljs-keyword">from</span> student <span class="hljs-keyword">where</span> <span class="hljs-keyword">name</span> <span class="hljs-keyword">like</span> <span class="hljs-string">&#x27;k_&#x27;</span>;</code></pre><ul><li>正则（包含2的）</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> emp <span class="hljs-keyword">where</span> sal <span class="hljs-keyword">RLIKE</span> <span class="hljs-string">&#x27;[2]&#x27;</span>;</code></pre><h4 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h4><ul><li>and/or/not</li></ul><h3 id="6-分组"><a href="#6-分组" class="headerlink" title="6. 分组"></a>6. 分组</h3><h4 id="group-by"><a href="#group-by" class="headerlink" title="group by"></a>group by</h4><h4 id="having"><a href="#having" class="headerlink" title="having"></a>having</h4><ul><li>配合group by 使用</li></ul><h4 id="join"><a href="#join" class="headerlink" title="join"></a>join</h4><ul><li>支持等值连接,不支持非等值连接</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> a.name,b.age,c.sex<span class="hljs-keyword">from</span> student a<span class="hljs-keyword">join</span> person b<span class="hljs-keyword">on</span> a.id = b.id<span class="hljs-keyword">join</span> emp c<span class="hljs-keyword">on</span> a.id = c.id;</code></pre><h4 id="笛卡尔积"><a href="#笛卡尔积" class="headerlink" title="笛卡尔积"></a>笛卡尔积</h4><ul><li>省略连接条件</li><li>连接条件无效</li><li>表中所有行相互连接</li></ul><h3 id="7-排序"><a href="#7-排序" class="headerlink" title="7. 排序"></a>7. 排序</h3><h4 id="order-by"><a href="#order-by" class="headerlink" title="order by"></a>order by</h4><ul><li>全局排序，只有一个reducer</li><li>放到句尾</li></ul><h4 id="sort-by"><a href="#sort-by" class="headerlink" title="sort by"></a>sort by</h4><ul><li>局部排序，reducer内排序</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">set</span> mapreduce.job.reduces=<span class="hljs-number">3</span>;</code></pre><h4 id="distribute-by"><a href="#distribute-by" class="headerlink" title="distribute by"></a>distribute by</h4><ul><li>类似于mr中的partition进行分区，结合sort by使用</li></ul><pre><code class="hljs sql"><span class="hljs-comment">--按照部门分区，工资排序</span><span class="hljs-keyword">insert</span> overwrite <span class="hljs-keyword">directory</span> <span class="hljs-string">&#x27;/opt/module/datas/dis-by&#x27;</span><span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> emp <span class="hljs-keyword">distribute</span> <span class="hljs-keyword">by</span> deptno <span class="hljs-keyword">sort</span> <span class="hljs-keyword">by</span> sal;</code></pre><h4 id="cluster-by"><a href="#cluster-by" class="headerlink" title="cluster by"></a>cluster by</h4><ul><li>distribute by + sort by 并且分区字段和排序字段相同</li><li>只能升序</li><li>防止数据倾斜</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul><li><p>order by只有一个reducer</p></li><li><p>distribute by + sort by 指定一个分区字段，在分区内排序，可以防止数据倾斜</p></li><li><p>cluster by 同上，但是不能降序</p></li><li><p>建表语句里有ed，查询里没有ed</p></li></ul><h1 id="分桶表"><a href="#分桶表" class="headerlink" title="分桶表"></a>分桶表</h1><ul><li>分区表放到不同的文件夹，分桶表放到不同的文件</li></ul><h2 id="创建分桶表"><a href="#创建分桶表" class="headerlink" title="创建分桶表"></a>创建分桶表</h2><pre><code class="hljs sql"><span class="hljs-keyword">create</span> <span class="hljs-keyword">table</span> stu_buck(<span class="hljs-keyword">id</span> <span class="hljs-built_in">int</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">string</span>)clustered <span class="hljs-keyword">by</span>(<span class="hljs-keyword">id</span>) <span class="hljs-comment">--分桶关键字</span><span class="hljs-keyword">into</span> <span class="hljs-number">4</span> buckets <span class="hljs-comment">--几个桶</span><span class="hljs-keyword">row</span> <span class="hljs-keyword">format</span> <span class="hljs-keyword">delimited</span> <span class="hljs-keyword">fields</span> <span class="hljs-keyword">terminated</span> <span class="hljs-keyword">by</span> <span class="hljs-string">&#x27;\t&#x27;</span>;</code></pre><ul><li>load data进去，hdfs上的文件不会拆开</li></ul><h4 id="需要设置属性"><a href="#需要设置属性" class="headerlink" title="需要设置属性"></a>需要设置属性</h4><pre><code class="hljs sql"><span class="hljs-keyword">set</span> hive.enforce.bucketing=<span class="hljs-literal">true</span>; <span class="hljs-comment">--开启分桶</span><span class="hljs-keyword">set</span> mapreduce.job.reduces=<span class="hljs-number">-1</span>; <span class="hljs-comment">--根据桶数自动设置reducer个数</span><span class="hljs-keyword">insert</span> <span class="hljs-keyword">into</span> stu_buck <span class="hljs-keyword">select</span> <span class="hljs-keyword">id</span>,<span class="hljs-keyword">name</span> <span class="hljs-keyword">from</span> stu;</code></pre><h4 id="分桶抽样查询"><a href="#分桶抽样查询" class="headerlink" title="分桶抽样查询"></a>分桶抽样查询</h4><ul><li>tablesample(bucket x out of y) </li><li>x从哪个桶开始抽</li><li>y必须是x的倍数或者因子</li><li>举个例子 16个桶 x,y = 1,4 ,抽的是1,5,9,13</li><li>x&lt;y</li><li>z桶个数 ，（x,y）  第一个桶 x，第二个桶 x+y ,第三个桶x+2y。。。 一共z/y个桶</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> * <span class="hljs-keyword">from</span> stu_buck <span class="hljs-keyword">tablesample</span>(<span class="hljs-keyword">bucket</span> <span class="hljs-number">1</span> <span class="hljs-keyword">out</span> <span class="hljs-keyword">of</span> <span class="hljs-number">4</span> <span class="hljs-keyword">on</span> <span class="hljs-keyword">id</span>);</code></pre><h1 id="常用函数"><a href="#常用函数" class="headerlink" title="常用函数"></a>常用函数</h1><h2 id="空字段赋值"><a href="#空字段赋值" class="headerlink" title="空字段赋值"></a>空字段赋值</h2><ul><li>可以用值代替，可以用列</li></ul><pre><code class="hljs sql">nvl(comm,-1) <span class="hljs-comment">--如果奖金为空，-1代替</span></code></pre><pre><code class="hljs sql">nvl(comm,nvl(sal,0)) <span class="hljs-comment">--如果奖金为空，用工资，如果工资为空，为0</span></code></pre><h2 id="时间"><a href="#时间" class="headerlink" title="时间"></a>时间</h2><pre><code class="hljs sql"><span class="hljs-keyword">select</span> data_format(<span class="hljs-string">&#x27;2020-5-23&#x27;</span>,<span class="hljs-string">&#x27;yyyy-MM-dd HH:mm:ss&#x27;</span>);</code></pre><ul><li>2020/05/20这种格式的时间处理</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> regexp_replace(<span class="hljs-string">&#x27;2020/5/20&#x27;</span>,<span class="hljs-string">&#x27;/&#x27;</span>,<span class="hljs-string">&#x27;-&#x27;</span>);</code></pre><ul><li>时间相加、减</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> data_add(<span class="hljs-string">&#x27;2020-5-23&#x27;</span>,<span class="hljs-number">3</span>);</code></pre><pre><code class="hljs sql"><span class="hljs-keyword">select</span> data_add(<span class="hljs-string">&#x27;2020-5-23,-5&#x27;</span>);<span class="hljs-comment">--指定天数减5天</span></code></pre><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-keyword">datediff</span>(<span class="hljs-string">&#x27;2020-6-22&#x27;</span>,<span class="hljs-string">&#x27;2020-6-20&#x27;</span>);<span class="hljs-comment">--前减后</span></code></pre><h2 id="窗口函数"><a href="#窗口函数" class="headerlink" title="窗口函数"></a>窗口函数</h2><ul><li>oracle，mysql5.8+，hive支持</li></ul><pre><code class="hljs sql">OVER() 指定分析函数的数据窗口打下，随着行变化而变化</code></pre><pre><code class="hljs pgsql"><span class="hljs-keyword">CURRENT</span> <span class="hljs-keyword">ROW</span> 当前行n <span class="hljs-keyword">PRECEDING</span> 往前n行n <span class="hljs-keyword">FOLLOWING</span> 往后n行<span class="hljs-keyword">UNBOUNDED</span> ：<span class="hljs-keyword">UNBOUNDED</span> <span class="hljs-keyword">PRECEDING</span>表示从前面的起点，<span class="hljs-keyword">UNBOUNDED</span> <span class="hljs-keyword">FOLLOWING</span>到后面的终点</code></pre><pre><code class="hljs reasonml"><span class="hljs-constructor">LAG(<span class="hljs-params">col</span>,<span class="hljs-params">n</span>)</span>： 往前第n行数据<span class="hljs-constructor">LEAD(<span class="hljs-params">col</span>,<span class="hljs-params">n</span>)</span>： 往后第n行数据<span class="hljs-constructor">NTILE(<span class="hljs-params">n</span>)</span>：把有序分区中的行分发到指定数据组中，各个组有编号，编号从<span class="hljs-number">1</span>开始，对于每一行，NTILE返回此行所属的组的编号。（注意：n必须为<span class="hljs-built_in">int</span>类型）</code></pre><h3 id="rank"><a href="#rank" class="headerlink" title="rank"></a>rank</h3><p>RANK() 排序相同会重复 ， 总数不会变<br>DENSE_RAND()排序会重复， 总数会变<br>ROW_NUMBER()会根据顺序计算</p><ul><li>需求</li></ul><ol><li>查询2017年4月份购买过的顾客及总人数</li><li>查询顾客的购买明细及月购买总额</li><li>上述场景，将要cost按照日期进行累加</li><li>查询顾客上次购买时间</li><li>查询前20%的订单信息</li></ol><ul><li>数据准备</li></ul><pre><code class="hljs sql">name,orderdate,costjack,2017-01-01,10jack,2017-01-01,20jack,2017-04-01,50toms,2017-04-12,50toms,2017-04-12,20</code></pre><ul><li>sql</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-keyword">name</span>,<span class="hljs-keyword">count</span>(*) <span class="hljs-keyword">over</span>()<span class="hljs-keyword">from</span> bussiness<span class="hljs-keyword">where</span> <span class="hljs-keyword">substring</span>(orderdate,<span class="hljs-number">1</span>,<span class="hljs-number">7</span>)=<span class="hljs-string">&#x27;2017-04&#x27;</span><span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> <span class="hljs-keyword">name</span>;</code></pre><pre><code class="hljs sql"><span class="hljs-keyword">select</span>  *, <span class="hljs-comment">--消费明细</span> <span class="hljs-keyword">sum</span>(<span class="hljs-keyword">cost</span>) <span class="hljs-comment">--购买总额</span><span class="hljs-keyword">from</span> business;</code></pre><pre><code class="hljs sql"><span class="hljs-keyword">select</span> orderdate, <span class="hljs-keyword">cost</span>， <span class="hljs-keyword">sum</span>(<span class="hljs-keyword">cost</span>) <span class="hljs-keyword">over</span>(<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> orderdate) <span class="hljs-comment">--cost按月累加实现</span><span class="hljs-keyword">from</span> business<span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span> orderdate;</code></pre><ul><li>如下这个是难点</li><li>lag往下错位，lead往上错位</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-keyword">name</span>, orderdate, <span class="hljs-keyword">cost</span>, lag(orderdate,<span class="hljs-number">1</span>,<span class="hljs-string">&#x27;1970-01-01&#x27;</span>) <span class="hljs-keyword">over</span>(<span class="hljs-keyword">distribute</span> <span class="hljs-keyword">by</span> <span class="hljs-keyword">name</span> <span class="hljs-keyword">sort</span> <span class="hljs-keyword">by</span> orderdate) <span class="hljs-comment">--新的一列，1.每个窗口初始值是参数；2.orderdate是上一行的orderdate。（错一位）</span><span class="hljs-keyword">from</span> business;</code></pre><h2 id="case-when、if案例"><a href="#case-when、if案例" class="headerlink" title="case when、if案例"></a>case when、if案例</h2><ul><li>员工表，统计男女数量</li></ul><pre><code class="hljs sql">(name string,dept_id string,sex_string)</code></pre><pre><code class="hljs sql"><span class="hljs-keyword">select</span> dept_id, <span class="hljs-keyword">sum</span>(<span class="hljs-keyword">case</span> sex <span class="hljs-keyword">when</span> <span class="hljs-string">&#x27;男&#x27;</span> <span class="hljs-keyword">then</span> <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">end</span>) male_count, <span class="hljs-keyword">sum</span>(<span class="hljs-keyword">case</span> sex <span class="hljs-keyword">when</span> <span class="hljs-string">&#x27;女&#x27;</span> <span class="hljs-keyword">then</span> <span class="hljs-number">1</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0</span> <span class="hljs-keyword">end</span>) female_count<span class="hljs-keyword">from</span> emp_sex<span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> dept_id;</code></pre><pre><code class="hljs sql"><span class="hljs-keyword">select</span> dept_id, <span class="hljs-keyword">sum</span>(<span class="hljs-keyword">if</span>(sex=<span class="hljs-string">&#x27;男&#x27;</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)) male_count, <span class="hljs-keyword">sum</span>(<span class="hljs-keyword">if</span>(sex=<span class="hljs-string">&#x27;女&#x27;</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>)) female_count<span class="hljs-keyword">from</span> emp_sex<span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span> dept_id;</code></pre><h2 id="行转列、列转行"><a href="#行转列、列转行" class="headerlink" title="行转列、列转行"></a>行转列、列转行</h2><ul><li><p>注意：concat拼接一列要用聚合函数group by</p></li><li><p>多个列合并到一起</p></li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-keyword">concat</span>(deptno,<span class="hljs-string">&#x27;-&#x27;</span>,dname) <span class="hljs-keyword">from</span> dept;</code></pre><ul><li>注意，类型是数组，类型要相同</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> <span class="hljs-keyword">concat_ws</span>(<span class="hljs-string">&#x27;-&#x27;</span>,<span class="hljs-keyword">name</span>,age,sex) <span class="hljs-keyword">from</span> student;</code></pre><ul><li>把一列转化为一行，格式是[  ,  ,  ,  ,]</li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span> collect_set(<span class="hljs-keyword">id</span>) <span class="hljs-keyword">from</span> student;</code></pre><ul><li><p>explode(col)，将hive中一列中复杂的array或者map结构拆分成多行</p></li><li><p>lateral view</p></li></ul><pre><code class="hljs sql"><span class="hljs-keyword">select</span>  movie, categroy_name<span class="hljs-keyword">from</span> movie_info <span class="hljs-keyword">lateral</span> <span class="hljs-keyword">view</span> <span class="hljs-keyword">explode</span>(<span class="hljs-keyword">category</span>) table_tmp <span class="hljs-keyword">as</span> category_name;</code></pre><h2 id="写sql顺序"><a href="#写sql顺序" class="headerlink" title="写sql顺序"></a>写sql顺序</h2><pre><code class="hljs sql"><span class="hljs-keyword">select</span><span class="hljs-keyword">from</span><span class="hljs-keyword">join</span> <span class="hljs-keyword">on</span><span class="hljs-keyword">where</span><span class="hljs-keyword">group</span> <span class="hljs-keyword">by</span><span class="hljs-keyword">order</span> <span class="hljs-keyword">by</span><span class="hljs-keyword">having</span><span class="hljs-keyword">limit</span></code></pre>]]></content>
    
    
    
    <tags>
      
      <tag>hive</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo的安装以及常用命令</title>
    <link href="/2020/10/18/hexo/"/>
    <url>/2020/10/18/hexo/</url>
    
    <content type="html"><![CDATA[<h4 id="hexo常用命令"><a href="#hexo常用命令" class="headerlink" title="hexo常用命令"></a>hexo常用命令</h4><h5 id="新文章创建"><a href="#新文章创建" class="headerlink" title="新文章创建"></a>新文章创建</h5><pre><code class="hljs actionscript">hexo <span class="hljs-keyword">new</span> hexo</code></pre><h5 id="本地测试"><a href="#本地测试" class="headerlink" title="本地测试"></a>本地测试</h5><pre><code class="hljs sas">hexo clean <span class="hljs-variable">&amp;&amp;</span> hexo g <span class="hljs-variable">&amp;&amp;</span> hexo s</code></pre><h5 id="运行和部署-第一次应该提示用户名密码"><a href="#运行和部署-第一次应该提示用户名密码" class="headerlink" title="运行和部署(第一次应该提示用户名密码)"></a>运行和部署(第一次应该提示用户名密码)</h5><pre><code class="hljs 1c">hexo clean <span class="hljs-meta">&amp;&amp; hexo deploy</span></code></pre><h4 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h4><h5 id="安装node-js-、hexo"><a href="#安装node-js-、hexo" class="headerlink" title="安装node.js 、hexo"></a>安装node.js 、hexo</h5><h5 id="生成密钥，拷贝到github上"><a href="#生成密钥，拷贝到github上" class="headerlink" title="生成密钥，拷贝到github上"></a>生成密钥，拷贝到github上</h5><pre><code class="hljs apache"><span class="hljs-attribute">ssh</span>-keygen -t rsa -b <span class="hljs-number">4096</span> -C <span class="hljs-string">&quot;cocoacm_liyiming@163.com&quot;</span></code></pre><h5 id="使用这个命令查看下"><a href="#使用这个命令查看下" class="headerlink" title="使用这个命令查看下"></a>使用这个命令查看下</h5><pre><code class="hljs nginx"><span class="hljs-attribute">ssh</span> -T git<span class="hljs-variable">@github</span>.com</code></pre><h5 id="个人的环境变量配置"><a href="#个人的环境变量配置" class="headerlink" title="个人的环境变量配置"></a>个人的环境变量配置</h5><pre><code class="hljs routeros">git<span class="hljs-built_in"> config </span>--global user.name <span class="hljs-string">&quot;kskuangshao&quot;</span>git<span class="hljs-built_in"> config </span>--global user.email <span class="hljs-string">&quot;cocoacm_liyiming@163.com&quot;</span></code></pre><h5 id="个人的环境变量配置创建仓库"><a href="#个人的环境变量配置创建仓库" class="headerlink" title="个人的环境变量配置创建仓库"></a>个人的环境变量配置创建仓库</h5><pre><code class="hljs awk">https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/kskuangshao/</span>kskuangshao.github.io 这里一样  这里一样</code></pre><h5 id="安装deployer"><a href="#安装deployer" class="headerlink" title="安装deployer"></a>安装deployer</h5><pre><code class="hljs sql">npm <span class="hljs-keyword">install</span> hexo-deployer-git <span class="hljs-comment">--save</span></code></pre><h5 id="config-yml配置"><a href="#config-yml配置" class="headerlink" title="_config.yml配置"></a>_config.yml配置</h5><pre><code class="hljs less"><span class="hljs-attribute">deploy</span>:   <span class="hljs-attribute">type</span>: git   <span class="hljs-attribute">repo</span>: git<span class="hljs-variable">@github</span>.<span class="hljs-attribute">com</span>:kskuangshao/kskuangshao.github.io.git   <span class="hljs-attribute">branch</span>: master</code></pre><p><u>我觉得最大的坑就是配置文件，必须严格按照那特定的格式，可是官方文档也没特别提醒，必须是这个格式，type，repo，branch前两个空格，“：”后面一个空格，差一个都不行的：deploy:  type: git  repository: url  branch: master</u></p>]]></content>
    
    
    
    <tags>
      
      <tag>hexo</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2020/10/17/hello-world/"/>
    <url>/2020/10/17/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span></code></pre><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="hljs bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="hljs bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="hljs bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
